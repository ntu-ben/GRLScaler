#!/usr/bin/env python3
"""
å ´æ™¯å°æ¯”å¯è¦–åŒ–ç”Ÿæˆå™¨ - Redis vs OnlineBoutique
========================================
ç”Ÿæˆå…©å€‹å ´æ™¯å››ç¨®å£“æ¸¬æ¨¡å¼ä¸‹ä¸‰ç¨®æ–¹æ³•çš„podå’ŒRPSæ™‚é–“åºåˆ—å°æ¯”åœ–
ä¿®æ­£ç‰ˆï¼šæ­£ç¢ºå€åˆ†Rediså’ŒOnlineBoutiqueçš„å¯¦é©—æ•¸æ“š
"""

import os
import sys
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import re
import datetime
import json
from typing import Dict, List, Optional, Tuple
import seaborn as sns
from scipy import integrate

# è¨­ç½®ä¸­æ–‡å­—é«”æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class ScenarioComparisonGenerator:
    def __init__(self, logs_root: str = "logs"):
        self.logs_root = Path(logs_root)
        self.output_dir = Path("scenario_comparisons_fixed")
        self.output_dir.mkdir(exist_ok=True)
        
        # å ´æ™¯å®šç¾©
        self.scenarios = ["offpeak", "rushsale", "peak", "fluctuating"]
        self.applications = ["redis", "onlineboutique"]
        self.methods = ["GNNRL", "Gym-HPA"]
        self.k8s_hpa_configs = ["cpu-20", "cpu-40", "cpu-60", "cpu-80"]  # 4ç¨®CPUé…ç½®
        # æ“´å±•æ–¹æ³•åˆ—è¡¨ï¼ŒåŒ…å«4ç¨®K8s-HPAé…ç½®
        self.all_methods = self.methods + [f"K8s-HPA-{config}" for config in self.k8s_hpa_configs]
        
        # æ‡‰ç”¨ç‰¹å®šçš„æ–¹æ³•ç›®éŒ„æ˜ å°„
        self.app_method_mapping = {
            "redis": {
                "GNNRL": "gnnrl",  # éœ€è¦æ‰¾åˆ°Redisçš„GNNRLå¯¦é©—
                "Gym-HPA": "gym-hpa",
                "K8s-HPA": "k8s_hpa_redis"
            },
            "onlineboutique": {
                "GNNRL": "gnnrl", 
                "Gym-HPA": "gym-hpa",
                "K8s-HPA": "k8s-hpa"
            }
        }
        
        # OBå¾®æœå‹™åç¨±é›†åˆï¼ˆç”¨æ–¼è­˜åˆ¥OBå¯¦é©—ï¼‰
        self.ob_services = {
            'adservice', 'cartservice', 'checkoutservice', 'currencyservice',
            'emailservice', 'frontend', 'paymentservice', 'productcatalogservice',
            'recommendationservice', 'shippingservice', 'redis-cart'
        }
        
        print(f"ğŸ¯ å ´æ™¯å°æ¯”å¯è¦–åŒ–ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆï¼ˆä¿®æ­£ç‰ˆï¼‰")
        print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {self.output_dir}")

    def detect_experiment_application(self, experiment_dir: Path) -> str:
        """æª¢æ¸¬å¯¦é©—ç›®éŒ„æ˜¯é‡å°å“ªå€‹æ‡‰ç”¨"""
        # æª¢æŸ¥ç›®éŒ„åæ˜¯å¦åŒ…å«redis
        if "redis" in experiment_dir.name.lower():
            return "redis"
            
        # æª¢æŸ¥æ˜¯å¦æœ‰é‹è¡Œæ—¥èªŒåŒ…å«OBæœå‹™åç¨±
        run_log = experiment_dir.parent / "run.log" 
        if run_log.exists():
            try:
                with open(run_log, 'r') as f:
                    content = f.read()
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«OBæœå‹™åç¨±
                ob_service_mentions = sum(1 for service in self.ob_services 
                                        if service in content)
                
                if ob_service_mentions >= 3:  # é–¾å€¼ï¼šè‡³å°‘3å€‹OBæœå‹™
                    return "onlineboutique"
                    
            except Exception as e:
                print(f"âš ï¸ è®€å–æ—¥èªŒå¤±æ•—: {e}")
        
        # æª¢æŸ¥å­ç›®éŒ„ä¸­çš„å ´æ™¯æ–‡ä»¶
        for scenario_dir in experiment_dir.iterdir():
            if scenario_dir.is_dir():
                # æª¢æŸ¥statsæ–‡ä»¶å…§å®¹
                stats_file = scenario_dir / f"{scenario_dir.name.split('_')[0]}_stats_history.csv"
                if stats_file.exists():
                    try:
                        df = pd.read_csv(stats_file, nrows=5)
                        if 'Name' in df.columns:
                            # æª¢æŸ¥è«‹æ±‚URLè·¯å¾‘
                            name_values = df['Name'].dropna().astype(str)
                            if any('/cart' in name or '/checkout' in name for name in name_values):
                                return "onlineboutique"
                            elif any('redis' in name.lower() for name in name_values):
                                return "redis"
                    except:
                        continue
        
        # é»˜èªæ ¹æ“šæ™‚é–“æ¨æ¸¬ï¼ˆ7/12å‰ç‚ºredisï¼Œ7/12å¾Œç‚ºonlineboutiqueï¼‰
        timestamp_match = re.search(r'(\d{8})', experiment_dir.name)
        if timestamp_match:
            date_str = timestamp_match.group(1)
            if date_str <= "20250712":
                return "redis"
            else:
                return "onlineboutique"
        
        return "unknown"

    def _select_best_experiment_dir(self, test_dirs: List[Path]) -> Path:
        """é¸æ“‡æœ€ä½³å¯¦é©—ç›®éŒ„ï¼Œå„ªå…ˆé¸æ“‡testå¯¦é©—ï¼ˆå«Podç›£æ§ï¼‰ï¼Œç„¶å¾ŒæŒ‰æ™‚é–“æˆ³æ’åº"""
        # åˆ†é›¢testå’Œtrainå¯¦é©—
        test_experiments = [d for d in test_dirs if "_test_" in d.name]
        train_experiments = [d for d in test_dirs if "_train_" in d.name]
        
        def extract_timestamp(dir_path: Path):
            """å¾ç›®éŒ„åæå–æ™‚é–“æˆ³"""
            timestamp_match = re.search(r'(\d{8}_\d{6})', dir_path.name)
            if timestamp_match:
                timestamp_str = timestamp_match.group(1)
                return datetime.datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
            return datetime.datetime.min  # å¦‚æœç„¡æ³•è§£æï¼Œè¿”å›æœ€å°æ™‚é–“
        
        # å„ªå…ˆé¸æ“‡testå¯¦é©—ï¼ŒæŒ‰æ™‚é–“æˆ³æ’åº
        if test_experiments:
            latest_test = max(test_experiments, key=extract_timestamp)
            print(f"ğŸ¯ å„ªå…ˆé¸æ“‡testå¯¦é©—: {latest_test.name}")
            return latest_test
        
        # å¦‚æœæ²’æœ‰testå¯¦é©—ï¼Œé¸æ“‡æœ€æ–°çš„trainå¯¦é©—
        if train_experiments:
            latest_train = max(train_experiments, key=extract_timestamp)
            print(f"âš ï¸ ä½¿ç”¨trainå¯¦é©—: {latest_train.name} (æœªæ‰¾åˆ°testå¯¦é©—)")
            return latest_train
        
        # å…œåº•ï¼šå¦‚æœéƒ½ä¸ç¬¦åˆï¼Œä½¿ç”¨åŸå§‹é‚è¼¯
        return max(test_dirs, key=lambda x: x.name)

    def find_latest_experiment_data(self, method: str, application: str) -> Optional[Path]:
        """æ‰¾åˆ°æŒ‡å®šæ–¹æ³•å’Œæ‡‰ç”¨çš„æœ€æ–°å¯¦é©—æ•¸æ“š"""
        method_dir_name = self.app_method_mapping[application][method]
        method_dir = self.logs_root / method_dir_name
        
        if not method_dir.exists():
            print(f"âŒ æ–¹æ³•ç›®éŒ„ä¸å­˜åœ¨: {method_dir}")
            return None
            
        # æ ¹æ“šä¸åŒæ–¹æ³•å’Œæ‡‰ç”¨å°‹æ‰¾å¯¦é©—ç›®éŒ„
        if application == "redis":
            if method == "GNNRL":
                # Redis GNNRLå¯¦é©—éœ€è¦ç‰¹æ®Šè™•ç†ï¼Œå› ç‚ºç›®å‰æ²’æœ‰å¯¦éš›çš„Redis GNNRLæ¸¬è©¦æ•¸æ“š
                # æª¢æŸ¥æ˜¯å¦æœ‰Redisç›¸é—œçš„GNNRLå¯¦é©—
                redis_gnnrl_dirs = []
                for test_dir in method_dir.glob("gnnrl_*redis*"):
                    redis_gnnrl_dirs.append(test_dir)
                
                # å¦‚æœæ²’æœ‰å°ˆé–€çš„Redis GNNRLç›®éŒ„ï¼Œæª¢æŸ¥é€šç”¨ç›®éŒ„ä¸­çš„Rediså¯¦é©—
                if not redis_gnnrl_dirs:
                    for test_dir in method_dir.glob("gnnrl_*seed42_*"):
                        if self.detect_experiment_application(test_dir) == "redis":
                            redis_gnnrl_dirs.append(test_dir)
                
                if not redis_gnnrl_dirs:
                    print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° {method} Redis å¯¦é©—ç›®éŒ„ï¼Œå¯èƒ½éœ€è¦å…ˆé‹è¡ŒRedis GNNRLå¯¦é©—")
                    return None
                    
                test_dirs = redis_gnnrl_dirs
                    
            elif method == "Gym-HPA":
                # æŸ¥æ‰¾ gym_hpa_redis_* ç›®éŒ„
                test_dirs = list(method_dir.glob("gym_hpa_redis_*seed42_*"))
                if not test_dirs:
                    print(f"âŒ æœªæ‰¾åˆ° {method} Redis å¯¦é©—ç›®éŒ„")
                    return None
                    
            elif method == "K8s-HPA":
                # K8s-HPA Redisåœ¨ k8s_hpa_redis ç›®éŒ„ä¸‹
                test_dirs = list(method_dir.glob("redis_hpa_*"))
                if not test_dirs:
                    print(f"âŒ æœªæ‰¾åˆ° {method} Redis å¯¦é©—ç›®éŒ„")
                    return None
                    
        else:  # onlineboutique
            if method == "GNNRL":
                # æŸ¥æ‰¾OnlineBoutiqueçš„GNNRLå¯¦é©—
                test_dirs = []
                for test_dir in method_dir.glob("gnnrl_*seed42_*"):
                    if self.detect_experiment_application(test_dir) == "onlineboutique":
                        test_dirs.append(test_dir)
                        
                if not test_dirs:
                    print(f"âŒ æœªæ‰¾åˆ° {method} OnlineBoutique å¯¦é©—ç›®éŒ„")
                    return None
                    
            elif method == "Gym-HPA":
                # æŸ¥æ‰¾OnlineBoutiqueçš„Gym-HPAå¯¦é©—ï¼ˆéredisçš„ï¼‰
                test_dirs = []
                for test_dir in method_dir.glob("gym_hpa_*seed42_*"):
                    if "redis" not in test_dir.name and self.detect_experiment_application(test_dir) == "onlineboutique":
                        test_dirs.append(test_dir)
                        
                if not test_dirs:
                    print(f"âŒ æœªæ‰¾åˆ° {method} OnlineBoutique å¯¦é©—ç›®éŒ„")
                    return None
                    
            elif method == "K8s-HPA":
                # æŸ¥æ‰¾OnlineBoutiqueçš„K8s-HPAå¯¦é©—ï¼ŒåŒ…å«æ‰€æœ‰CPUé…ç½®
                test_dirs = []
                for test_dir in method_dir.glob("k8s_hpa_*_seed42_*"):
                    if self.detect_experiment_application(test_dir) == "onlineboutique":
                        test_dirs.append(test_dir)
                        
                if not test_dirs:
                    print(f"âŒ æœªæ‰¾åˆ° {method} OnlineBoutique å¯¦é©—ç›®éŒ„")
                    return None
            
        # é¸æ“‡æœ€æ–°çš„å¯¦é©—ç›®éŒ„ï¼Œå„ªå…ˆé¸æ“‡testå¯¦é©—ï¼ˆåŒ…å«Podç›£æ§æ•¸æ“šï¼‰
        latest_dir = self._select_best_experiment_dir(test_dirs)
        detected_app = self.detect_experiment_application(latest_dir)
        
        print(f"âœ… æ‰¾åˆ° {method} {application} å¯¦é©—ç›®éŒ„: {latest_dir.name} (æª¢æ¸¬åˆ°: {detected_app})")
        
        if detected_app != application:
            print(f"âš ï¸ è­¦å‘Š: æœŸæœ› {application} ä½†æª¢æ¸¬åˆ° {detected_app}")
            
        return latest_dir

    def extract_pod_data_from_kiali(self, scenario: str, experiment_timestamp: str) -> Optional[pd.DataFrame]:
        """å¾ Kiali æ•¸æ“šä¸­æå– pod ä¿¡æ¯"""
        kiali_dir = self.logs_root / "kiali"
        
        # æŸ¥æ‰¾å°æ‡‰æ™‚é–“æˆ³çš„ kiali æ–‡ä»¶
        kiali_files = [
            f"kiali_start_{experiment_timestamp}.json",
            f"kiali_mid_{experiment_timestamp}.json", 
            f"kiali_end_{experiment_timestamp}.json"
        ]
        
        pod_data = []
        for i, kiali_file in enumerate(kiali_files):
            file_path = kiali_dir / kiali_file
            if file_path.exists():
                try:
                    with open(file_path, 'r') as f:
                        data = json.load(f)
                    
                    # æå–podä¿¡æ¯
                    if 'workloads' in data:
                        total_pods = 0
                        for workload in data['workloads']:
                            if 'podCount' in workload:
                                total_pods += workload['podCount']
                        
                        # æ™‚é–“é»: 0åˆ†é˜(start), 7.5åˆ†é˜(mid), 15åˆ†é˜(end)
                        time_point = i * 7.5
                        pod_data.append({
                            'time_minutes': time_point,
                            'pods': total_pods
                        })
                        
                except Exception as e:
                    print(f"âš ï¸ è®€å– {kiali_file} å¤±æ•—: {e}")
        
        if pod_data:
            return pd.DataFrame(pod_data)
        return None

    def extract_rps_data(self, experiment_dir: Path, scenario: str, application: str) -> Optional[pd.DataFrame]:
        """å¾å¯¦é©—ç›®éŒ„ä¸­æå–RPSæ•¸æ“š"""
        
        # æ ¹æ“šæ‡‰ç”¨é¡å‹èª¿æ•´å ´æ™¯ç›®éŒ„æŸ¥æ‰¾æ¨¡å¼
        if application == "redis":
            # Rediså¯¦é©—å¯èƒ½ä½¿ç”¨ redis_scenario æ ¼å¼
            scenario_patterns = [
                f"{scenario}_*",
                f"redis_{scenario}*",
                f"redis_{scenario}",
                f"{scenario}"
            ]
        else:
            # OnlineBoutiqueä½¿ç”¨æ¨™æº–æ ¼å¼
            scenario_patterns = [f"{scenario}_*"]
        
        scenario_dir = None
        for pattern in scenario_patterns:
            scenario_dirs = list(experiment_dir.glob(pattern))
            if scenario_dirs:
                scenario_dir = scenario_dirs[0]
                break
        
        if not scenario_dir:
            print(f"âš ï¸ æœªæ‰¾åˆ° {application} {scenario} å ´æ™¯ç›®éŒ„åœ¨ {experiment_dir}")
            return None
            
        # æŸ¥æ‰¾statsæ–‡ä»¶
        stats_files = [
            scenario_dir / f"{scenario}_stats_history.csv",
            scenario_dir / f"redis_{scenario}_stats_history.csv",
            scenario_dir / "stats_history.csv"
        ]
        
        stats_file = None
        for file_path in stats_files:
            if file_path.exists():
                stats_file = file_path
                break
                
        if not stats_file:
            print(f"âš ï¸ æœªæ‰¾åˆ°statsæ–‡ä»¶åœ¨ {scenario_dir}")
            return None
            
        try:
            df = pd.read_csv(stats_file)
            
            # å¦‚æœæœ‰ Requests/s åˆ—
            if 'Requests/s' in df.columns:
                # è½‰æ›æ™‚é–“æˆ³ç‚ºç›¸å°æ™‚é–“(åˆ†é˜)
                if 'Timestamp' in df.columns:
                    start_time = df['Timestamp'].min()
                    df['time_minutes'] = (df['Timestamp'] - start_time) / 60
                else:
                    # å‡è¨­æ¯è¡Œä»£è¡¨1ç§’ï¼Œè½‰æ›ç‚ºåˆ†é˜
                    df['time_minutes'] = df.index / 60
                
                # åªä¿ç•™15åˆ†é˜å…§çš„æ•¸æ“š
                df = df[df['time_minutes'] <= 15]
                
                # é‡æ¡æ¨£åˆ°æ¯åˆ†é˜ä¸€å€‹æ•¸æ“šé»
                result_data = []
                for minute in range(16):  # 0-15åˆ†é˜
                    minute_data = df[(df['time_minutes'] >= minute) & 
                                   (df['time_minutes'] < minute + 1)]
                    if not minute_data.empty:
                        avg_rps = minute_data['Requests/s'].mean()
                        result_data.append({
                            'time_minutes': minute,
                            'rps': avg_rps
                        })
                    else:
                        result_data.append({
                            'time_minutes': minute,
                            'rps': 0
                        })
                
                print(f"âœ… æå–åˆ° {len(result_data)} å€‹RPSæ•¸æ“šé»å¾ {stats_file}")
                return pd.DataFrame(result_data)
                
        except Exception as e:
            print(f"âš ï¸ è®€å– RPS æ•¸æ“šå¤±æ•— {stats_file}: {e}")
            
        return None

    def extract_pod_data_from_logs(self, experiment_dir: Path, method: str, scenario: str = None) -> Optional[pd.DataFrame]:
        """å¾å¯¦é©—æ—¥èªŒä¸­æå–podæ•¸æ“šï¼Œå„ªå…ˆä½¿ç”¨æ–°çš„Podç›£æ§CSVæ–‡ä»¶"""
        
        # å„ªå…ˆæª¢æŸ¥æ–°çš„Podç›£æ§CSVæ–‡ä»¶ï¼Œå¦‚æœæœ‰scenarioå‰‡å…ˆæª¢æŸ¥scenarioç›®éŒ„
        if scenario:
            pod_csv_data = self._extract_from_scenario_pod_monitoring_csv(experiment_dir, scenario)
            if pod_csv_data is not None:
                return pod_csv_data
        
        # å…œåº•ï¼šæª¢æŸ¥å¯¦é©—ä¸»ç›®éŒ„çš„Podç›£æ§CSVæ–‡ä»¶
        pod_csv_data = self._extract_from_pod_monitoring_csv(experiment_dir)
        if pod_csv_data is not None:
            return pod_csv_data
        
        # å°æ–¼ K8s-HPAï¼Œpod æ•¸æ“šå¯èƒ½åœ¨ kiali ä¸­
        if method == "K8s-HPA":
            # å¾ç›®éŒ„åæå–æ™‚é–“æˆ³
            dir_name = experiment_dir.name
            timestamp_match = re.search(r'(\d{8}_\d{6})', dir_name)
            if timestamp_match:
                timestamp = timestamp_match.group(1)
                kiali_data = self.extract_pod_data_from_kiali("", timestamp)
                if kiali_data is not None:
                    return kiali_data
            
            # å¦‚æœkialiæ²’æœ‰æ•¸æ“šï¼Œå˜—è©¦å¾Redis HPAå ´æ™¯ç›®éŒ„æå–
            if "redis_hpa" in dir_name:
                # Redis HPAçš„å ´æ™¯ç›®éŒ„çµæ§‹: redis_hpa_cpu-XX_timestamp/scenario_name/
                scenario_dirs = [d for d in experiment_dir.iterdir() if d.is_dir()]
                if scenario_dirs:
                    # å¾ç¬¬ä¸€å€‹å ´æ™¯ç›®éŒ„å˜—è©¦æå–podæ•¸æ“š
                    return self.extract_redis_hpa_pod_data(scenario_dirs[0])
        
        # å°æ–¼å…¶ä»–æ–¹æ³•ï¼Œå˜—è©¦å¾é‹è¡Œæ—¥èªŒä¸­æå–
        run_log_paths = [
            experiment_dir.parent / "run.log",
            experiment_dir / "run.log",
            experiment_dir / "experiment.log"
        ]
        
        for run_log in run_log_paths:
            if run_log.exists():
                try:
                    with open(run_log, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                    
                    pod_data = []
                    step_count = 0
                    
                    for line in lines:
                        # æ”¹é€²podä¿¡æ¯åŒ¹é…é‚è¼¯
                        if any(keyword in line for keyword in [
                            "Number of pods:", "Desired Replicas:", 
                            "Current pods:", "Pod count:"
                        ]):
                            try:
                                # åŒ¹é…æ•¸å­—
                                number_match = re.search(r'(\d+)', line.split(':')[-1])
                                if number_match:
                                    pod_count = int(number_match.group(1))
                                    time_minutes = step_count * 0.6  # å‡è¨­æ¯æ­¥0.6åˆ†é˜
                                    if time_minutes <= 15:
                                        pod_data.append({
                                            'time_minutes': time_minutes,
                                            'pods': pod_count
                                        })
                                    step_count += 1
                            except Exception as e:
                                continue
                    
                    if pod_data:
                        return self.resample_pod_data(pod_data)
                        
                except Exception as e:
                    print(f"âš ï¸ è®€å–podæ•¸æ“šå¤±æ•— {run_log}: {e}")
                    continue
        
        # å¦‚æœç„¡æ³•ç²å–å¯¦éš›æ•¸æ“šï¼Œè¿”å›None
        print(f"âš ï¸ ç„¡æ³•å¾ {experiment_dir} æå–podæ•¸æ“š")
        return None
    
    def _extract_from_scenario_pod_monitoring_csv(self, experiment_dir: Path, scenario: str) -> Optional[pd.DataFrame]:
        """å¾scenarioç›®éŒ„ä¸­çš„Podç›£æ§CSVæ–‡ä»¶æå–æ•¸æ“š"""
        try:
            # æŸ¥æ‰¾scenarioç›®éŒ„
            scenario_dirs = list(experiment_dir.glob(f"{scenario}_*"))
            if not scenario_dirs:
                return None
            
            # ä½¿ç”¨ç¬¬ä¸€å€‹åŒ¹é…çš„scenarioç›®éŒ„
            scenario_dir = scenario_dirs[0]
            pod_metrics_dir = scenario_dir / "pod_metrics"
            
            if not pod_metrics_dir.exists():
                return None
            
            # æŸ¥æ‰¾æ‰€æœ‰namespaceçš„Podç›£æ§CSVæ–‡ä»¶
            csv_files = list(pod_metrics_dir.rglob("*_pod_counts.csv"))
            if not csv_files:
                return None
            
            # åˆä½µæ‰€æœ‰namespaceçš„Podæ•¸æ“š
            all_pod_data = []
            
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file)
                    if 'elapsed_minutes' in df.columns and 'pod_count' in df.columns:
                        all_pod_data.extend([{
                            'time_minutes': row['elapsed_minutes'],
                            'pods': row['pod_count']
                        } for _, row in df.iterrows() if row['elapsed_minutes'] <= 15])
                except Exception as e:
                    print(f"âš ï¸ è®€å–Podç›£æ§CSVå¤±æ•— {csv_file}: {e}")
                    continue
            
            if not all_pod_data:
                return None
            
            # æŒ‰æ™‚é–“èšåˆPodæ•¸æ“šï¼ˆåŒä¸€æ™‚é–“é»çš„ç¸½Podæ•¸ï¼‰
            df = pd.DataFrame(all_pod_data)
            aggregated_data = []
            
            for minute in range(16):
                minute_data = df[(df['time_minutes'] >= minute) & 
                               (df['time_minutes'] < minute + 1)]
                if not minute_data.empty:
                    total_pods = minute_data['pods'].sum()  # æ‰€æœ‰namespaceçš„Podç¸½æ•¸
                    aggregated_data.append({
                        'time_minutes': minute,
                        'pods': int(total_pods)
                    })
                else:
                    # ä½¿ç”¨å‰ä¸€åˆ†é˜çš„å€¼æˆ–é»˜èªå€¼
                    prev_pods = aggregated_data[-1]['pods'] if aggregated_data else 1
                    aggregated_data.append({
                        'time_minutes': minute,
                        'pods': prev_pods
                    })
            
            print(f"âœ… å¾scenario Podç›£æ§CSVæå–åˆ° {len(aggregated_data)} å€‹æ•¸æ“šé»")
            return pd.DataFrame(aggregated_data)
            
        except Exception as e:
            print(f"âš ï¸ scenario Podç›£æ§CSVæ•¸æ“šæå–å¤±æ•—: {e}")
            return None
    
    def _extract_from_pod_monitoring_csv(self, experiment_dir: Path) -> Optional[pd.DataFrame]:
        """å¾æ–°çš„Podç›£æ§CSVæ–‡ä»¶ä¸­æå–æ•¸æ“š"""
        try:
            # æŸ¥æ‰¾pod_metricsç›®éŒ„
            pod_metrics_dir = experiment_dir / "pod_metrics"
            if not pod_metrics_dir.exists():
                return None
            
            # æŸ¥æ‰¾æ‰€æœ‰namespaceçš„Podç›£æ§CSVæ–‡ä»¶
            csv_files = list(pod_metrics_dir.rglob("*_pod_counts.csv"))
            if not csv_files:
                return None
            
            # åˆä½µæ‰€æœ‰namespaceçš„Podæ•¸æ“š
            all_pod_data = []
            
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file)
                    if 'elapsed_minutes' in df.columns and 'pod_count' in df.columns:
                        all_pod_data.extend([{
                            'time_minutes': row['elapsed_minutes'],
                            'pods': row['pod_count']
                        } for _, row in df.iterrows() if row['elapsed_minutes'] <= 15])
                except Exception as e:
                    print(f"âš ï¸ è®€å–Podç›£æ§CSVå¤±æ•— {csv_file}: {e}")
                    continue
            
            if not all_pod_data:
                return None
            
            # æŒ‰æ™‚é–“èšåˆPodæ•¸æ“šï¼ˆåŒä¸€æ™‚é–“é»çš„ç¸½Podæ•¸ï¼‰
            df = pd.DataFrame(all_pod_data)
            aggregated_data = []
            
            for minute in range(16):
                minute_data = df[(df['time_minutes'] >= minute) & 
                               (df['time_minutes'] < minute + 1)]
                if not minute_data.empty:
                    total_pods = minute_data['pods'].sum()  # æ‰€æœ‰namespaceçš„Podç¸½æ•¸
                    aggregated_data.append({
                        'time_minutes': minute,
                        'pods': int(total_pods)
                    })
                else:
                    # ä½¿ç”¨å‰ä¸€åˆ†é˜çš„å€¼æˆ–é»˜èªå€¼
                    prev_pods = aggregated_data[-1]['pods'] if aggregated_data else 1
                    aggregated_data.append({
                        'time_minutes': minute,
                        'pods': prev_pods
                    })
            
            print(f"âœ… å¾Podç›£æ§CSVæå–åˆ° {len(aggregated_data)} å€‹æ•¸æ“šé»")
            return pd.DataFrame(aggregated_data)
            
        except Exception as e:
            print(f"âš ï¸ Podç›£æ§CSVæ•¸æ“šæå–å¤±æ•—: {e}")
            return None

    def extract_redis_hpa_pod_data(self, scenario_dir: Path) -> Optional[pd.DataFrame]:
        """å¾Redis HPAå ´æ™¯ç›®éŒ„æå–podæ•¸æ“š"""
        try:
            # æŸ¥æ‰¾å¯èƒ½çš„podæ•¸æ“šæ–‡ä»¶
            pod_files = list(scenario_dir.glob("*pod*.csv")) + list(scenario_dir.glob("*replica*.csv"))
            
            for pod_file in pod_files:
                try:
                    df = pd.read_csv(pod_file)
                    if 'pods' in df.columns or 'replicas' in df.columns:
                        pod_column = 'pods' if 'pods' in df.columns else 'replicas'
                        return self.resample_pod_data([{
                            'time_minutes': i * 0.5,  # å‡è¨­æ¯0.5åˆ†é˜ä¸€å€‹æ•¸æ“šé»
                            'pods': row[pod_column]
                        } for i, (_, row) in enumerate(df.iterrows())])
                except Exception as e:
                    continue
                    
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å°ˆé–€çš„podæ–‡ä»¶ï¼Œå˜—è©¦å¾locustçµ±è¨ˆæ–‡ä»¶æ¨æ¸¬
            stats_files = list(scenario_dir.glob("*_stats.csv"))
            if stats_files:
                # å‡è¨­Redis HPAåœ¨æ¸¬è©¦æœŸé–“podæ•¸ä¿æŒç›¸å°ç©©å®š
                return self.create_default_pod_data(2)  # å‡è¨­å¹³å‡2å€‹pod
                
        except Exception as e:
            print(f"âš ï¸ Redis HPA podæ•¸æ“šæå–å¤±æ•—: {e}")
            
        return None
    
    def resample_pod_data(self, pod_data: list) -> pd.DataFrame:
        """å°‡podæ•¸æ“šé‡æ¡æ¨£åˆ°æ¯åˆ†é˜"""
        df = pd.DataFrame(pod_data)
        result_data = []
        
        for minute in range(16):
            minute_data = df[(df['time_minutes'] >= minute) & 
                           (df['time_minutes'] < minute + 1)]
            if not minute_data.empty:
                avg_pods = minute_data['pods'].mean()
                result_data.append({
                    'time_minutes': minute,
                    'pods': int(round(avg_pods))
                })
            else:
                # å¦‚æœè©²åˆ†é˜æ²’æœ‰æ•¸æ“šï¼Œä½¿ç”¨å‰ä¸€åˆ†é˜çš„å€¼æˆ–é»˜èªå€¼
                prev_pods = result_data[-1]['pods'] if result_data else 1
                result_data.append({
                    'time_minutes': minute, 
                    'pods': prev_pods
                })
        
        return pd.DataFrame(result_data)
    
    def create_default_pod_data(self, default_pods: int = 1) -> pd.DataFrame:
        """å‰µå»ºé»˜èªçš„podæ•¸æ“šï¼ˆç•¶ç„¡æ³•æå–å¯¦éš›æ•¸æ“šæ™‚ä½¿ç”¨ï¼‰"""
        return pd.DataFrame([{
            'time_minutes': minute,
            'pods': default_pods
        } for minute in range(16)])


    def collect_scenario_data(self, application: str, scenario: str) -> Dict:
        """æ”¶é›†æŒ‡å®šæ‡‰ç”¨å’Œå ´æ™¯çš„æ‰€æœ‰æ–¹æ³•æ•¸æ“šï¼ŒåŒ…å«K8s-HPAå„é…ç½®"""
        scenario_data = {
            'application': application,
            'scenario': scenario,
            'methods': {}
        }
        
        # æ”¶é›†GNNRLå’ŒGym-HPAæ•¸æ“š
        for method in self.methods:
            print(f"ğŸ“Š æ”¶é›† {method} - {application} - {scenario} æ•¸æ“š...")
            
            experiment_dir = self.find_latest_experiment_data(method, application)
            if not experiment_dir:
                print(f"âŒ æœªæ‰¾åˆ° {method} {application} å¯¦é©—æ•¸æ“š")
                pod_data = None
                rps_data = None
            else:
                # æå–å¯¦éš›æ•¸æ“š
                pod_data = self.extract_pod_data_from_logs(experiment_dir, method, scenario)
                rps_data = self.extract_rps_data(experiment_dir, scenario, application)
                
                if pod_data is None:
                    print(f"âŒ æœªèƒ½æå– {method} {application} {scenario} podæ•¸æ“š")
                if rps_data is None:
                    print(f"âŒ æœªèƒ½æå– {method} {application} {scenario} RPSæ•¸æ“š")
            
            scenario_data['methods'][method] = {
                'pod_data': pod_data,
                'rps_data': rps_data,
                'has_data': pod_data is not None or rps_data is not None
            }
        
        # æ”¶é›†K8s-HPAå„é…ç½®æ•¸æ“š
        method_dir_name = self.app_method_mapping[application]["K8s-HPA"]
        method_dir = self.logs_root / method_dir_name
        
        for config in self.k8s_hpa_configs:
            method_name = f"K8s-HPA-{config}"
            print(f"ğŸ“Š æ”¶é›† {method_name} - {application} - {scenario} æ•¸æ“š...")
            
            # æŸ¥æ‰¾ç‰¹å®šé…ç½®çš„å¯¦é©—ç›®éŒ„
            config_dirs = []
            if application == "redis":
                pattern = f"redis_hpa_{config}_*"
                for test_dir in method_dir.glob(pattern):
                    if self.detect_experiment_application(test_dir) == application:
                        config_dirs.append(test_dir)
            else:
                # OnlineBoutique K8s-HPA: k8s_hpa_cpu_seed42_*/cpu-XX/
                for test_dir in method_dir.glob("k8s_hpa_cpu_seed42_*"):
                    cpu_config_dir = test_dir / config  # config is like "cpu-40"
                    if cpu_config_dir.exists() and self.detect_experiment_application(test_dir) == application:
                        config_dirs.append(cpu_config_dir)
            
            if not config_dirs:
                print(f"âŒ æœªæ‰¾åˆ° {method_name} {application} å¯¦é©—æ•¸æ“š")
                pod_data = None
                rps_data = None
            else:
                # é¸æ“‡æœ€æ–°çš„é…ç½®ç›®éŒ„
                latest_config_dir = max(config_dirs, key=lambda x: x.name)
                
                # æå–æ•¸æ“š
                pod_data = self.extract_pod_data_from_logs(latest_config_dir, "K8s-HPA", scenario)
                rps_data = self.extract_rps_data(latest_config_dir, scenario, application)
                
                print(f"âœ… æ‰¾åˆ° {method_name} {application} é…ç½®ç›®éŒ„: {latest_config_dir.name}")
                
                if pod_data is None:
                    print(f"âŒ æœªèƒ½æå– {method_name} {application} {scenario} podæ•¸æ“š")
                if rps_data is None:
                    print(f"âŒ æœªèƒ½æå– {method_name} {application} {scenario} RPSæ•¸æ“š")
            
            scenario_data['methods'][method_name] = {
                'pod_data': pod_data,
                'rps_data': rps_data,
                'has_data': pod_data is not None or rps_data is not None
            }
            
        return scenario_data

    def calculate_detailed_statistics(self, scenario_data: Dict) -> Dict:
        """è¨ˆç®—è©³ç´°çµ±è¨ˆæ•¸æ“š"""
        application = scenario_data['application']
        scenario = scenario_data['scenario']
        
        detailed_stats = {
            'application': application,
            'scenario': scenario,
            'microservices': [],
            'summary_statistics': {}
        }
        
        # é‡å°æ¯å€‹æ–¹æ³•è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        for method_name, method_data in scenario_data['methods'].items():
            if not method_data['has_data']:
                continue
                
            pod_data = method_data['pod_data']
            rps_data = method_data['rps_data']
            
            # è¨ˆç®—åŸºæœ¬çµ±è¨ˆæŒ‡æ¨™
            stats = self._calculate_method_statistics(method_name, pod_data, rps_data)
            
            # å¦‚æœæ˜¯å¾®æœå‹™æ¶æ§‹ï¼Œå˜—è©¦ç²å–å¾®æœå‹™ç´šåˆ¥çš„çµ±è¨ˆæ•¸æ“š
            if application == "onlineboutique":
                microservice_stats = self._calculate_microservice_statistics(method_name, method_data)
                detailed_stats['microservices'].extend(microservice_stats)
            
            detailed_stats['summary_statistics'][method_name] = stats
        
        return detailed_stats
    
    def _calculate_method_statistics(self, method_name: str, pod_data: pd.DataFrame, rps_data: pd.DataFrame) -> Dict:
        """è¨ˆç®—å–®å€‹æ–¹æ³•çš„çµ±è¨ˆæ•¸æ“š"""
        stats = {
            'method': method_name,
            'pod_time_area': 0,
            'total_requests': 0,
            'req_per_pod_time_area': 0,
            'avg_rps': 0,
            'avg_response_time': 0,
            'p95_response_time': 0,
            'p99_response_time': 0
        }
        
        # 1. è¨ˆç®—podè·Ÿæ™‚é–“çš„é¢ç© (Pod-Minutes)
        if pod_data is not None and not pod_data.empty:
            # ä½¿ç”¨æ¢¯å½¢æ³•å‰‡è¨ˆç®—é¢ç©
            time_minutes = pod_data['time_minutes'].values
            pod_counts = pod_data['pods'].values
            
            # ç¢ºä¿æ™‚é–“æ˜¯å¾0é–‹å§‹çš„é€£çºŒåºåˆ—
            if len(time_minutes) > 1:
                stats['pod_time_area'] = integrate.trapz(pod_counts, time_minutes)
            else:
                stats['pod_time_area'] = pod_counts[0] * 15  # å‡è¨­15åˆ†é˜æ¸¬è©¦
        
        # 2. è¨ˆç®—ç¸½Requestæ•¸å’Œå¹³å‡RPS
        if rps_data is not None and not rps_data.empty:
            time_minutes = rps_data['time_minutes'].values
            rps_values = rps_data['rps'].values
            
            # ç¸½è«‹æ±‚æ•¸ = RPS * æ™‚é–“é–“éš” (åˆ†é˜)
            if len(time_minutes) > 1:
                # è¨ˆç®—æ¯åˆ†é˜çš„è«‹æ±‚æ•¸ä¸¦æ±‚å’Œ
                total_requests = 0
                for i in range(len(time_minutes) - 1):
                    time_interval = (time_minutes[i+1] - time_minutes[i]) * 60  # è½‰æ›ç‚ºç§’
                    total_requests += rps_values[i] * time_interval
                stats['total_requests'] = total_requests
            else:
                stats['total_requests'] = rps_values[0] * 15 * 60  # å‡è¨­15åˆ†é˜æ¸¬è©¦
            
            # å¹³å‡RPS
            stats['avg_rps'] = np.mean(rps_values[rps_values > 0])  # æ’é™¤0å€¼
        
        # 3. è¨ˆç®—ç¸½REQ/podèˆ‡æ™‚é–“é¢ç©æ¯”ç‡
        if stats['pod_time_area'] > 0:
            stats['req_per_pod_time_area'] = stats['total_requests'] / stats['pod_time_area']
        
        return stats
    
    def _calculate_microservice_statistics(self, method_name: str, method_data: Dict) -> List[Dict]:
        """è¨ˆç®—å¾®æœå‹™ç´šåˆ¥çš„çµ±è¨ˆæ•¸æ“š"""
        microservice_stats = []
        
        # å°æ–¼OnlineBoutiqueï¼Œæˆ‘å€‘æœ‰11å€‹å¾®æœå‹™
        ob_services = [
            'adservice', 'cartservice', 'checkoutservice', 'currencyservice',
            'emailservice', 'frontend', 'paymentservice', 'productcatalogservice',
            'recommendationservice', 'shippingservice', 'redis-cart'
        ]
        
        # å˜—è©¦å¾pod monitoring CSVæ–‡ä»¶ä¸­ç²å–å¾®æœå‹™ç´šåˆ¥çš„Podæ•¸æ“š
        pod_data_per_service = self._extract_microservice_pod_data(method_data)
        
        # å˜—è©¦å¾statsæ–‡ä»¶ä¸­ç²å–å¾®æœå‹™ç´šåˆ¥çš„éŸ¿æ‡‰æ™‚é–“æ•¸æ“š
        response_data_per_service = self._extract_microservice_response_data(method_data)
        
        for service in ob_services:
            service_stats = {
                'method': method_name,
                'microservice': service,
                'pod_time_area': 0,
                'total_requests': 0,
                'req_per_pod_time_area': 0,
                'avg_rps': 0,
                'avg_response_time': 0,
                'p95_response_time': 0,
                'p99_response_time': 0
            }
            
            # è¨ˆç®—æœå‹™ç´šåˆ¥çš„Podæ™‚é–“é¢ç©
            if service in pod_data_per_service:
                service_pod_data = pod_data_per_service[service]
                if len(service_pod_data) > 1:
                    time_values = [entry['time_minutes'] for entry in service_pod_data]
                    pod_values = [entry['pods'] for entry in service_pod_data]
                    service_stats['pod_time_area'] = integrate.trapz(pod_values, time_values)
            
            # è¨ˆç®—æœå‹™ç´šåˆ¥çš„éŸ¿æ‡‰æ™‚é–“çµ±è¨ˆ
            if service in response_data_per_service:
                service_response_data = response_data_per_service[service]
                service_stats['total_requests'] = service_response_data.get('request_count', 0)
                service_stats['avg_response_time'] = service_response_data.get('avg_response_time', 0)
                service_stats['p95_response_time'] = service_response_data.get('p95_response_time', 0)
                service_stats['p99_response_time'] = service_response_data.get('p99_response_time', 0)
                
                # è¨ˆç®—RPSï¼ˆå‡è¨­15åˆ†é˜æ¸¬è©¦ï¼‰
                if service_stats['total_requests'] > 0:
                    service_stats['avg_rps'] = service_stats['total_requests'] / (15 * 60)
                
                # è¨ˆç®—è«‹æ±‚/Podæ™‚é–“é¢ç©æ¯”ç‡
                if service_stats['pod_time_area'] > 0:
                    service_stats['req_per_pod_time_area'] = service_stats['total_requests'] / service_stats['pod_time_area']
            
            microservice_stats.append(service_stats)
        
        return microservice_stats
    
    def _extract_microservice_pod_data(self, method_data: Dict) -> Dict:
        """æå–å¾®æœå‹™ç´šåˆ¥çš„Podæ•¸æ“š"""
        # é€™å€‹å‡½æ•¸éœ€è¦æ ¹æ“šå¯¦éš›çš„Podç›£æ§æ•¸æ“šæ ¼å¼ä¾†å¯¦ç¾
        # ç›®å‰è¿”å›ç©ºå­—å…¸ï¼Œå¯¦éš›ä½¿ç”¨æ™‚éœ€è¦è§£æpod_metricsç›®éŒ„ä¸­çš„å…·é«”æ–‡ä»¶
        return {}
    
    def _extract_microservice_response_data(self, method_data: Dict) -> Dict:
        """æå–å¾®æœå‹™ç´šåˆ¥çš„éŸ¿æ‡‰æ•¸æ“š"""
        # é€™å€‹å‡½æ•¸éœ€è¦æ ¹æ“šå¯¦éš›çš„statsæ–‡ä»¶æ ¼å¼ä¾†å¯¦ç¾
        # ç›®å‰è¿”å›ç©ºå­—å…¸ï¼Œå¯¦éš›ä½¿ç”¨æ™‚éœ€è¦è§£æstats.csvæ–‡ä»¶ä¸­çš„å¾®æœå‹™ç´šåˆ¥æ•¸æ“š
        return {}
    
    def extract_response_time_data(self, experiment_dir: Path, scenario: str, application: str) -> Optional[pd.DataFrame]:
        """æå–éŸ¿æ‡‰æ™‚é–“æ•¸æ“š"""
        
        # æ ¹æ“šæ‡‰ç”¨é¡å‹èª¿æ•´å ´æ™¯ç›®éŒ„æŸ¥æ‰¾æ¨¡å¼
        if application == "redis":
            scenario_patterns = [
                f"{scenario}_*",
                f"redis_{scenario}*",
                f"redis_{scenario}",
                f"{scenario}"
            ]
        else:
            scenario_patterns = [f"{scenario}_*"]
        
        scenario_dir = None
        for pattern in scenario_patterns:
            scenario_dirs = list(experiment_dir.glob(pattern))
            if scenario_dirs:
                scenario_dir = scenario_dirs[0]
                break
        
        if not scenario_dir:
            return None
        
        # æŸ¥æ‰¾statsæ–‡ä»¶
        stats_files = [
            scenario_dir / f"{scenario}_stats.csv",
            scenario_dir / f"redis_{scenario}_stats.csv",
            scenario_dir / "stats.csv"
        ]
        
        stats_file = None
        for file_path in stats_files:
            if file_path.exists():
                stats_file = file_path
                break
        
        if not stats_file:
            return None
        
        try:
            df = pd.read_csv(stats_file)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰éŸ¿æ‡‰æ™‚é–“ç›¸é—œçš„åˆ—
            response_time_cols = [
                'Average Response Time', 'Min Response Time', 'Max Response Time',
                '50%', '66%', '75%', '80%', '90%', '95%', '98%', '99%', '99.9%', '99.99%', '100%'
            ]
            
            available_cols = [col for col in response_time_cols if col in df.columns]
            if not available_cols:
                return None
            
            # æ•´ç†éŸ¿æ‡‰æ™‚é–“æ•¸æ“š
            result_data = []
            for _, row in df.iterrows():
                entry = {
                    'name': row.get('Name', 'Unknown'),
                    'type': row.get('Type', 'Unknown'),
                    'request_count': row.get('Request Count', 0),
                    'avg_response_time': row.get('Average Response Time', 0),
                    'p95_response_time': row.get('95%', 0),
                    'p99_response_time': row.get('99%', 0)
                }
                result_data.append(entry)
            
            return pd.DataFrame(result_data)
            
        except Exception as e:
            print(f"âš ï¸ è®€å–éŸ¿æ‡‰æ™‚é–“æ•¸æ“šå¤±æ•— {stats_file}: {e}")
            return None
    
    def generate_detailed_statistics_report(self, application: str = None) -> Dict:
        """ç”Ÿæˆè©³ç´°çš„çµ±è¨ˆæ•¸æ“šå ±å‘Š"""
        print(f"ğŸ“Š ç”Ÿæˆè©³ç´°çµ±è¨ˆæ•¸æ“šå ±å‘Š...")
        
        all_statistics = {
            'generation_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'applications': {}
        }
        
        applications_to_process = [application] if application else self.applications
        
        for app in applications_to_process:
            app_statistics = {
                'application': app,
                'scenarios': {}
            }
            
            # ç²å–è©²æ‡‰ç”¨çš„å¯ç”¨å ´æ™¯
            available_scenarios = self.get_available_scenarios(app)
            
            if not available_scenarios:
                print(f"âš ï¸ è­¦å‘Š: {app} æ²’æœ‰å¯ç”¨çš„å ´æ™¯æ•¸æ“š")
                continue
            
            for scenario in available_scenarios:
                print(f"ğŸ“ˆ åˆ†æ {app} - {scenario} å ´æ™¯...")
                
                # æ”¶é›†å ´æ™¯æ•¸æ“š
                scenario_data = self.collect_scenario_data(app, scenario)
                
                # è¨ˆç®—è©³ç´°çµ±è¨ˆ
                detailed_stats = self.calculate_detailed_statistics(scenario_data)
                
                # å¢å¼·çµ±è¨ˆæ•¸æ“š - æ·»åŠ éŸ¿æ‡‰æ™‚é–“ä¿¡æ¯
                self._enhance_statistics_with_response_times(detailed_stats, app, scenario)
                
                app_statistics['scenarios'][scenario] = detailed_stats
            
            all_statistics['applications'][app] = app_statistics
        
        # ä¿å­˜çµ±è¨ˆå ±å‘Š
        stats_file = self.output_dir / "detailed_statistics.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(all_statistics, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ è©³ç´°çµ±è¨ˆå ±å‘Šå·²ä¿å­˜: {stats_file}")
        
        # ç”Ÿæˆè¡¨æ ¼æ ¼å¼çš„å ±å‘Š
        self._generate_statistics_table(all_statistics)
        
        return all_statistics
    
    def _enhance_statistics_with_response_times(self, detailed_stats: Dict, application: str, scenario: str):
        """å¢å¼·çµ±è¨ˆæ•¸æ“šï¼Œæ·»åŠ éŸ¿æ‡‰æ™‚é–“ä¿¡æ¯"""
        
        for method_name, method_stats in detailed_stats['summary_statistics'].items():
            # å˜—è©¦å¾å°æ‡‰çš„å¯¦é©—ç›®éŒ„ä¸­ç²å–éŸ¿æ‡‰æ™‚é–“æ•¸æ“š
            # å°‡K8s-HPA-cpu-XXæ ¼å¼è½‰æ›ç‚ºK8s-HPA
            base_method_name = method_name
            if method_name.startswith('K8s-HPA-'):
                base_method_name = 'K8s-HPA'
            
            experiment_dir = self.find_latest_experiment_data(base_method_name, application)
            
            if experiment_dir:
                response_time_data = self.extract_response_time_data(experiment_dir, scenario, application)
                
                if response_time_data is not None and not response_time_data.empty:
                    # è¨ˆç®—åŠ æ¬Šå¹³å‡éŸ¿æ‡‰æ™‚é–“
                    total_requests = response_time_data['request_count'].sum()
                    if total_requests > 0:
                        weighted_avg_rt = (response_time_data['avg_response_time'] * 
                                         response_time_data['request_count']).sum() / total_requests
                        weighted_p95_rt = (response_time_data['p95_response_time'] * 
                                         response_time_data['request_count']).sum() / total_requests
                        weighted_p99_rt = (response_time_data['p99_response_time'] * 
                                         response_time_data['request_count']).sum() / total_requests
                        
                        method_stats['avg_response_time'] = weighted_avg_rt
                        method_stats['p95_response_time'] = weighted_p95_rt
                        method_stats['p99_response_time'] = weighted_p99_rt
                        
                        # æ›´æ–°ç¸½è«‹æ±‚æ•¸ï¼ˆå¦‚æœstatsæ–‡ä»¶æœ‰æ›´å‡†ç¢ºçš„æ•¸æ“šï¼‰
                        if total_requests > method_stats['total_requests']:
                            method_stats['total_requests'] = total_requests
                            
                            # é‡æ–°è¨ˆç®— req_per_pod_time_area
                            if method_stats['pod_time_area'] > 0:
                                method_stats['req_per_pod_time_area'] = total_requests / method_stats['pod_time_area']
    
    def _generate_statistics_table(self, all_statistics: Dict):
        """ç”Ÿæˆè¡¨æ ¼æ ¼å¼çš„çµ±è¨ˆå ±å‘Š"""
        
        # å‰µå»ºä¸»è¦çµ±è¨ˆè¡¨æ ¼
        table_data = []
        microservice_data = []
        
        for app_name, app_data in all_statistics['applications'].items():
            for scenario_name, scenario_data in app_data['scenarios'].items():
                # ç”Ÿæˆæ–¹æ³•ç´šåˆ¥çš„çµ±è¨ˆ
                for method_name, method_stats in scenario_data['summary_statistics'].items():
                    row = {
                        'æ‡‰ç”¨': app_name,
                        'å ´æ™¯': scenario_name,
                        'å¾®æœå‹™': 'ç¸½è¨ˆ',
                        'æ–¹æ³•': method_name,
                        'Podæ™‚é–“é¢ç©': f"{method_stats['pod_time_area']:.2f}",
                        'ç¸½è«‹æ±‚æ•¸': f"{method_stats['total_requests']:.0f}",
                        'è«‹æ±‚/Podæ™‚é–“é¢ç©': f"{method_stats['req_per_pod_time_area']:.2f}",
                        'å¹³å‡RPS': f"{method_stats['avg_rps']:.2f}",
                        'å¹³å‡éŸ¿æ‡‰æ™‚é–“(ms)': f"{method_stats['avg_response_time']:.2f}",
                        '95%éŸ¿æ‡‰æ™‚é–“(ms)': f"{method_stats['p95_response_time']:.2f}",
                        '99%éŸ¿æ‡‰æ™‚é–“(ms)': f"{method_stats['p99_response_time']:.2f}"
                    }
                    table_data.append(row)
                
                # ç”Ÿæˆå¾®æœå‹™ç´šåˆ¥çš„çµ±è¨ˆï¼ˆåƒ…é‡å°OnlineBoutiqueï¼‰
                if app_name == 'onlineboutique' and scenario_data.get('microservices'):
                    for microservice_stats in scenario_data['microservices']:
                        row = {
                            'æ‡‰ç”¨': app_name,
                            'å ´æ™¯': scenario_name,
                            'å¾®æœå‹™': microservice_stats['microservice'],
                            'æ–¹æ³•': microservice_stats['method'],
                            'Podæ™‚é–“é¢ç©': f"{microservice_stats['pod_time_area']:.2f}",
                            'ç¸½è«‹æ±‚æ•¸': f"{microservice_stats['total_requests']:.0f}",
                            'è«‹æ±‚/Podæ™‚é–“é¢ç©': f"{microservice_stats['req_per_pod_time_area']:.2f}",
                            'å¹³å‡RPS': f"{microservice_stats['avg_rps']:.2f}",
                            'å¹³å‡éŸ¿æ‡‰æ™‚é–“(ms)': f"{microservice_stats['avg_response_time']:.2f}",
                            '95%éŸ¿æ‡‰æ™‚é–“(ms)': f"{microservice_stats['p95_response_time']:.2f}",
                            '99%éŸ¿æ‡‰æ™‚é–“(ms)': f"{microservice_stats['p99_response_time']:.2f}"
                        }
                        microservice_data.append(row)
        
        # è½‰æ›ç‚ºDataFrameä¸¦ä¿å­˜
        df = pd.DataFrame(table_data)
        
        # ä¿å­˜ä¸»è¦çµ±è¨ˆè¡¨æ ¼
        csv_file = self.output_dir / "statistics_summary.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ“Š çµ±è¨ˆè¡¨æ ¼å·²ä¿å­˜: {csv_file}")
        
        # ä¿å­˜å¾®æœå‹™ç´šåˆ¥çµ±è¨ˆè¡¨æ ¼ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if microservice_data:
            microservice_df = pd.DataFrame(microservice_data)
            microservice_csv_file = self.output_dir / "microservices_statistics.csv"
            microservice_df.to_csv(microservice_csv_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ“Š å¾®æœå‹™çµ±è¨ˆè¡¨æ ¼å·²ä¿å­˜: {microservice_csv_file}")
        
        # ä¿å­˜ç‚ºExcelï¼ˆå¦‚æœå¯èƒ½ï¼‰
        try:
            excel_file = self.output_dir / "statistics_summary.xlsx"
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='ç¸½é«”çµ±è¨ˆ', index=False)
                if microservice_data:
                    microservice_df.to_excel(writer, sheet_name='å¾®æœå‹™çµ±è¨ˆ', index=False)
            print(f"ğŸ“Š çµ±è¨ˆè¡¨æ ¼å·²ä¿å­˜: {excel_file}")
        except ImportError:
            print("ğŸ“ æç¤º: å®‰è£openpyxlå¯ä»¥ç”ŸæˆExcelæ ¼å¼çš„çµ±è¨ˆè¡¨æ ¼")
        
        # æ‰“å°æ‘˜è¦åˆ°æ§åˆ¶å°
        print("\n" + "="*100)
        print("ğŸ“Š çµ±è¨ˆæ•¸æ“šæ‘˜è¦")
        print("="*100)
        print(df.to_string(index=False))
        print("="*100)
        
        if microservice_data:
            print("\n" + "="*100)
            print("ğŸ“Š å¾®æœå‹™çµ±è¨ˆæ•¸æ“šæ‘˜è¦")
            print("="*100)
            print(microservice_df.to_string(index=False))
            print("="*100)
        
        return df

    def create_comparison_plot(self, application: str, scenario: str, metric: str):
        """å‰µå»ºå°æ¯”åœ–"""
        print(f"ğŸ¨ ç”Ÿæˆ {application} - {scenario} - {metric} å°æ¯”åœ–...")
        
        scenario_data = self.collect_scenario_data(application, scenario)
        
        plt.figure(figsize=(15, 8))
        
        # è¨­ç½®é¡è‰² - 6ç¨®æ–¹æ³•çš„é¡è‰²
        colors = ['#1f77b4', '#ff7f0e', '#e74c3c', '#f39c12', '#2ecc71', '#3498db']
        method_colors = dict(zip(self.all_methods, colors))
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ•¸æ“š
        has_any_data = False
        missing_data_methods = []
        
        ylabel = 'Pod æ•¸é‡' if metric == 'pods' else 'RPS (æ¯ç§’è«‹æ±‚æ•¸)'
        
        for method in self.all_methods:
            if method in scenario_data['methods']:
                method_data = scenario_data['methods'][method]
                
                # é¸æ“‡å°æ‡‰çš„æ•¸æ“š
                if metric == 'pods':
                    df = method_data['pod_data']
                else:  # rps
                    df = method_data['rps_data']
                
                if df is not None:
                    # æœ‰æ•¸æ“šï¼Œç¹ªè£½ç·šæ¢
                    x_data = df['time_minutes']
                    y_data = df['pods'] if metric == 'pods' else df['rps']
                    
                    plt.plot(x_data, y_data, 
                            label=method, 
                            color=method_colors[method],
                            linewidth=2,
                            marker='o',
                            markersize=4)
                    has_any_data = True
                else:
                    # æ²’æœ‰æ•¸æ“šï¼Œè¨˜éŒ„ä¸‹ä¾†
                    missing_data_methods.append(method)
        
        # è¨­ç½®åœ–è¡¨åŸºæœ¬å±¬æ€§
        plt.xlabel('æ™‚é–“ (åˆ†é˜)', fontsize=12)
        plt.ylabel(ylabel, fontsize=12)
        plt.title(f'{application.title()} - {scenario.title()} å ´æ™¯ - {ylabel}å°æ¯” (å«K8s-HPAå„é…ç½®)', 
                 fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        plt.xlim(0, 15)
        
        if has_any_data:
            plt.legend(loc='best')
        
        # å¦‚æœæœ‰ç¼ºå¤±æ•¸æ“šçš„æ–¹æ³•ï¼Œåœ¨åœ–ä¸Šé¡¯ç¤ºè­¦å‘Š
        if missing_data_methods:
            warning_text = f"ç¼ºå¤±æ•¸æ“š: {', '.join(missing_data_methods)}"
            plt.text(0.02, 0.98, warning_text, 
                    transform=plt.gca().transAxes,
                    fontsize=10, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7),
                    verticalalignment='top')
        
        # å¦‚æœå®Œå…¨æ²’æœ‰æ•¸æ“šï¼Œé¡¯ç¤ºå¤§è­¦å‘Š
        if not has_any_data:
            plt.text(0.5, 0.5, f'âŒ æ•¸æ“šä¸è¶³\n\nç„¡æ³•æ‰¾åˆ° {application} {scenario} å ´æ™¯çš„ {ylabel} æ•¸æ“š\n\nè«‹æª¢æŸ¥å¯¦é©—æ—¥èªŒå’Œæ•¸æ“šæ–‡ä»¶', 
                    transform=plt.gca().transAxes,
                    fontsize=16, 
                    ha='center', va='center',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="red", alpha=0.8, edgecolor='darkred'),
                    color='white', weight='bold')
            
            # è¨­ç½®åŸºæœ¬çš„Yè»¸ç¯„åœ
            if metric == 'pods':
                plt.ylim(0, 10)
            else:
                plt.ylim(0, 100)
        
        # ä¿å­˜åœ–ç‰‡
        filename = f"{application}_{scenario}_{metric}.png"
        filepath = self.output_dir / filename
        plt.savefig(filepath, dpi=300, bbox_inches='tight')
        plt.close()
        
        if has_any_data:
            print(f"âœ… å·²ä¿å­˜: {filename}")
        else:
            print(f"âš ï¸ å·²ä¿å­˜ (æ•¸æ“šä¸è¶³): {filename}")
        
        return filepath


    def get_available_scenarios(self, application: str) -> List[str]:
        """ç²å–æŒ‡å®šæ‡‰ç”¨çš„å¯ç”¨å ´æ™¯åˆ—è¡¨"""
        available_scenarios = []
        
        # æª¢æŸ¥æ¯å€‹æ–¹æ³•çš„æ‰€æœ‰å¯¦é©—ç›®éŒ„ï¼Œæ‰¾å‡ºå¯¦éš›å­˜åœ¨çš„å ´æ™¯
        for method in self.methods:
            method_dir_name = self.app_method_mapping[application][method]
            method_dir = self.logs_root / method_dir_name
            
            if not method_dir.exists():
                continue
                
            # æª¢æŸ¥æ‰€æœ‰å¯¦é©—ç›®éŒ„ï¼Œä¸åªæ˜¯æœ€æ–°çš„
            if application == "redis":
                if method == "GNNRL":
                    # æª¢æŸ¥æ‰€æœ‰ GNNRL Redis å¯¦é©—ç›®éŒ„
                    for test_dir in method_dir.glob("gnnrl_*redis*"):
                        self._extract_scenarios_from_dir(test_dir, available_scenarios)
                    for test_dir in method_dir.glob("gnnrl_*seed42_*"):
                        if self.detect_experiment_application(test_dir) == "redis":
                            self._extract_scenarios_from_dir(test_dir, available_scenarios)
                elif method == "Gym-HPA":
                    # æª¢æŸ¥æ‰€æœ‰ Gym-HPA Redis å¯¦é©—ç›®éŒ„
                    for test_dir in method_dir.glob("gym_hpa_redis_*seed42_*"):
                        self._extract_scenarios_from_dir(test_dir, available_scenarios)
            else:  # onlineboutique
                if method == "GNNRL":
                    for test_dir in method_dir.glob("gnnrl_*seed42_*"):
                        if self.detect_experiment_application(test_dir) == "onlineboutique":
                            self._extract_scenarios_from_dir(test_dir, available_scenarios)
                elif method == "Gym-HPA":
                    for test_dir in method_dir.glob("gym_hpa_*seed42_*"):
                        if "redis" not in test_dir.name and self.detect_experiment_application(test_dir) == "onlineboutique":
                            self._extract_scenarios_from_dir(test_dir, available_scenarios)
        
        # æª¢æŸ¥ K8s-HPA æ•¸æ“šï¼ˆæ‰€æœ‰å¯¦é©—ç›®éŒ„ï¼‰
        method_dir_name = self.app_method_mapping[application]["K8s-HPA"]
        method_dir = self.logs_root / method_dir_name
        
        if method_dir.exists():
            if application == "redis":
                # Redis K8s-HPA: redis_hpa_cpu-XX_timestamp/scenario/
                for config_dir in method_dir.glob("redis_hpa_*"):
                    scenario_dirs = [d for d in config_dir.iterdir() if d.is_dir()]
                    for scenario_dir in scenario_dirs:
                        scenario_name = scenario_dir.name.split('_')[0]
                        if scenario_name in self.scenarios and scenario_name not in available_scenarios:
                            available_scenarios.append(scenario_name)
        
        print(f"ğŸ“‹ {application} å¯ç”¨å ´æ™¯: {available_scenarios}")
        return available_scenarios
    
    def _extract_scenarios_from_dir(self, experiment_dir: Path, available_scenarios: list):
        """å¾å¯¦é©—ç›®éŒ„ä¸­æå–å ´æ™¯åç¨±"""
        scenario_dirs = [d for d in experiment_dir.iterdir() if d.is_dir()]
        for scenario_dir in scenario_dirs:
            # æå–å ´æ™¯åç¨±ï¼ˆå»æ‰ç·¨è™Ÿå¾Œç¶´ï¼‰
            scenario_name = scenario_dir.name.split('_')[0]
            if scenario_name in self.scenarios and scenario_name not in available_scenarios:
                available_scenarios.append(scenario_name)

    def generate_all_comparisons(self):
        """ç”Ÿæˆæ‰€æœ‰å°æ¯”åœ–"""
        print(f"ğŸš€ é–‹å§‹ç”Ÿæˆæ‰€æœ‰å ´æ™¯å°æ¯”åœ–...")
        
        generated_files = []
        
        # ç”ŸæˆåŒ…å«æ‰€æœ‰æ–¹æ³•çš„å°æ¯”åœ– (å«K8s-HPAå„é…ç½®)
        for application in self.applications:
            # ç²å–è©²æ‡‰ç”¨çš„å¯ç”¨å ´æ™¯
            available_scenarios = self.get_available_scenarios(application)
            
            if not available_scenarios:
                print(f"âš ï¸ è­¦å‘Š: {application} æ²’æœ‰å¯ç”¨çš„å ´æ™¯æ•¸æ“š")
                continue
            
            for scenario in available_scenarios:
                for metric in ['pods', 'rps']:
                    try:
                        filepath = self.create_comparison_plot(application, scenario, metric)
                        generated_files.append(filepath)
                    except Exception as e:
                        print(f"âŒ ç”Ÿæˆ {application}_{scenario}_{metric} å¤±æ•—: {e}")
        
        # ç”Ÿæˆç¸½çµå ±å‘Š
        self.generate_summary_report(generated_files)
        
        # ç”Ÿæˆè©³ç´°çµ±è¨ˆæ•¸æ“šå ±å‘Š
        print(f"\nğŸ“Š ç”Ÿæˆè©³ç´°çµ±è¨ˆæ•¸æ“šå ±å‘Š...")
        self.generate_detailed_statistics_report()
        
        print(f"\nğŸ‰ å®Œæˆï¼å…±ç”Ÿæˆ {len(generated_files)} å€‹å°æ¯”åœ–")
        print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        
        return generated_files

    def generate_summary_report(self, generated_files: List[Path]):
        """ç”Ÿæˆç¸½çµå ±å‘Š"""
        summary = {
            'ç”Ÿæˆæ™‚é–“': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'ç”Ÿæˆæ–‡ä»¶æ•¸é‡': len(generated_files),
            'æ‡‰ç”¨å ´æ™¯': self.applications,
            'å£“æ¸¬å ´æ™¯': self.scenarios,
            'å°æ¯”æ–¹æ³•': self.methods,
            'ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨': [f.name for f in generated_files]
        }
        
        summary_file = self.output_dir / "comparison_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ ç¸½çµå ±å‘Šå·²ä¿å­˜: {summary_file}")

def main():
    """ä¸»å‡½æ•¸"""
    import sys
    
    print("ğŸ¯ å ´æ™¯å°æ¯”å¯è¦–åŒ–ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # æª¢æŸ¥å‘½ä»¤è¡Œåƒæ•¸
    if len(sys.argv) > 1:
        specified_app = sys.argv[1].lower()
        if specified_app not in ["redis", "onlineboutique"]:
            print(f"âŒ ä¸æ”¯æ´çš„æ‡‰ç”¨: {specified_app}")
            print("ğŸ’¡ æ”¯æ´çš„æ‡‰ç”¨: redis, onlineboutique")
            return
        print(f"ğŸ¯ æŒ‡å®šæ‡‰ç”¨: {specified_app}")
    else:
        specified_app = None
        print("ğŸ¯ ç”Ÿæˆæ‰€æœ‰æ‡‰ç”¨çš„å°æ¯”åœ–")
    
    # å‰µå»ºç”Ÿæˆå™¨å¯¦ä¾‹
    generator = ScenarioComparisonGenerator()
    
    # å¦‚æœæŒ‡å®šäº†æ‡‰ç”¨ï¼Œåªè™•ç†è©²æ‡‰ç”¨
    if specified_app:
        generator.applications = [specified_app]
    
    # ç”Ÿæˆæ‰€æœ‰å°æ¯”åœ–
    generated_files = generator.generate_all_comparisons()
    
    print("\n" + "=" * 50)
    print("ğŸ’¡ ä½¿ç”¨èªªæ˜:")
    print("   ğŸ“Š å°æ¯”åœ–æ–‡ä»¶:")
    print("      â€¢ æŸ¥çœ‹ç”Ÿæˆçš„åœ–ç‰‡æ–‡ä»¶åœ¨ scenario_comparisons_fixed/ ç›®éŒ„")
    print("      â€¢ å°æ¯”åœ–å‘½åæ ¼å¼: {æ‡‰ç”¨}_{å ´æ™¯}_{æŒ‡æ¨™}.png")
    print("      â€¢ ä¾‹å¦‚: redis_offpeak_rps.png, onlineboutique_fluctuating_pods.png")
    print("      â€¢ æ¯å€‹åœ–åŒ…å«æœ€å¤š6æ¢ç·š: GNNRL, Gym-HPA, K8s-HPA-cpu-20, K8s-HPA-cpu-40, K8s-HPA-cpu-60, K8s-HPA-cpu-80")
    print("      â€¢ å¯ä»¥ç›´æ¥å°æ¯”ä¸åŒK8s-HPA CPUé–¾å€¼è¨­ç½®çš„æ€§èƒ½å·®ç•°")
    print("      â€¢ åªæœƒç”Ÿæˆæœ‰å¯¦éš›æ•¸æ“šçš„å ´æ™¯å°æ¯”åœ–")
    print("   ")
    print("   ğŸ“ˆ çµ±è¨ˆæ•¸æ“šå ±å‘Š:")
    print("      â€¢ detailed_statistics.json - å®Œæ•´çš„JSONæ ¼å¼çµ±è¨ˆæ•¸æ“š")
    print("      â€¢ statistics_summary.csv - è¡¨æ ¼æ ¼å¼çµ±è¨ˆæ•¸æ“šï¼ˆå¯ç”¨Excelæ‰“é–‹ï¼‰")
    print("      â€¢ statistics_summary.xlsx - Excelæ ¼å¼çµ±è¨ˆæ•¸æ“šï¼ˆå¦‚æœå®‰è£äº†openpyxlï¼‰")
    print("   ")
    print("   ğŸ“‹ çµ±è¨ˆæŒ‡æ¨™åŒ…å«:")
    print("      â€¢ Podæ™‚é–“é¢ç© (Pod-Minutes)")
    print("      â€¢ ç¸½è«‹æ±‚æ•¸")
    print("      â€¢ è«‹æ±‚/Podæ™‚é–“é¢ç©æ¯”ç‡")
    print("      â€¢ å¹³å‡RPS")
    print("      â€¢ å¹³å‡éŸ¿æ‡‰æ™‚é–“(ms)")
    print("      â€¢ 95%éŸ¿æ‡‰æ™‚é–“(ms)")
    print("      â€¢ 99%éŸ¿æ‡‰æ™‚é–“(ms)")
    print("   ")
    print("   ğŸ¯ æ•¸æ“šæŒ‰ç…§ï¼šå ´æ™¯ â†’ æ–¹æ³• â†’ çµ±è¨ˆæŒ‡æ¨™ çš„å±¤æ¬¡çµæ§‹çµ„ç¹”")

if __name__ == "__main__":
    main()