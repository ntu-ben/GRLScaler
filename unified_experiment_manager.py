#!/usr/bin/env python3
"""
çµ±ä¸€å¯¦é©—ç®¡ç†å™¨ (Unified Experiment Manager)
================================================

æ•´åˆ gym_hpa, k8s_hpa, gnnrl ä¸‰å€‹å¯¦é©—ï¼Œæ”¯æ´åˆ†æ•£å¼ Locust æ¸¬è©¦ç’°å¢ƒã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- çµ±ä¸€çš„å‘½ä»¤è¡Œä»‹é¢
- è‡ªå‹•å¯¦é©—ç’°å¢ƒé©—è­‰
- åˆ†æ•£å¼è² è¼‰æ¸¬è©¦å”èª¿
- å¯¦é©—çµæœèšåˆèˆ‡æ¯”è¼ƒ
- æ”¯æ´æ‰¹æ¬¡å¯¦é©—åŸ·è¡Œ

ä½¿ç”¨æ–¹å¼ï¼š
    # åŸ·è¡Œå–®ä¸€å¯¦é©—
    python unified_experiment_manager.py --experiment gnnrl --steps 5000
    
    # æ‰¹æ¬¡åŸ·è¡Œæ‰€æœ‰å¯¦é©—
    python unified_experiment_manager.py --batch-all --steps 3000
    
    # åƒ…åŸ·è¡Œè² è¼‰æ¸¬è©¦ (ä¸è¨“ç·´)
    python unified_experiment_manager.py --loadtest-only
    
    # æ¯”è¼ƒå¯¦é©—çµæœ
    python unified_experiment_manager.py --compare logs/gym_hpa/run1 logs/gnnrl/run2
"""

import os
import sys
from pod_monitor import MultiPodMonitor, create_pod_monitor_for_experiment
import yaml
import argparse
import logging
import subprocess
import time
import random
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import pandas as pd
import requests

# è¼‰å…¥å¯¦é©—é…ç½®
CONFIG_FILE = Path(__file__).parent / "experiment_config.yaml"

class UnifiedExperimentManager:
    def __init__(self, config_path: Path = CONFIG_FILE, stable_loadtest: bool = False, 
                 target_rps: int = None, loadtest_timeout: int = 30):
        """åˆå§‹åŒ–çµ±ä¸€å¯¦é©—ç®¡ç†å™¨"""
        self.repo_root = Path(__file__).parent
        self.config = self._load_config(config_path)
        self.logger = self._setup_logging()
        self._load_environment()
        
        # Stable loadtest é…ç½®
        self.stable_loadtest = stable_loadtest
        self.target_rps = target_rps
        self.loadtest_timeout = loadtest_timeout
        
        self._setup_locust_scenarios()
        self._setup_hpa_configurations()
        
        # åˆå§‹åŒ– timestamp å±¬æ€§
        from datetime import datetime
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
    def _setup_locust_scenarios(self):
        """è¨­å®š Locust æ¸¬è©¦å ´æ™¯"""
        # ç¾åœ¨æ‰€æœ‰è…³æœ¬éƒ½æ˜¯ç©©å®šç‰ˆæœ¬ï¼Œç›´æ¥ä½¿ç”¨åŸæœ¬å‘½å
        self.scenarios = {
            "offpeak": "locust_offpeak.py",
            "rushsale": "locust_rushsale.py", 
            "peak": "locust_peak.py",
            "fluctuating": "locust_fluctuating.py"
        }
        
        # å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥è¨­å®š
        self.target_host = os.getenv("TARGET_HOST", "http://k8s.orb.local:8080")
        self.locust_run_time = os.getenv("LOCUST_RUN_TIME", "15m")
        self.m1_host = os.getenv("M1_HOST")
        self.kiali_url = os.getenv("KIALI_URL", "http://localhost:20001/kiali")
        self.namespace = os.getenv("NAMESPACE_ONLINEBOUTIQUE", "onlineboutique")
        self.redis_namespace = os.getenv("NAMESPACE_REDIS", "redis")
        
        # è¨ˆç®—é‹è¡Œæ™‚é–“ï¼ˆç§’ï¼‰
        self._parse_run_time()
        
    def _parse_run_time(self):
        """è§£æé‹è¡Œæ™‚é–“å­—ä¸²"""
        import re
        mult = {"s": 1, "m": 60, "h": 3600}
        match = re.match(r"(\d+)([smh])", self.locust_run_time)
        if match:
            self.run_time_sec = int(match.group(1)) * mult[match.group(2)]
            self.half_run_sec = self.run_time_sec // 2
        else:
            self.run_time_sec = 900  # é è¨­ 15 åˆ†é˜
            self.half_run_sec = 450
    
    def _setup_hpa_configurations(self):
        """è¨­å®š HPA é…ç½®é¸é …"""
        self.hpa_configs = {
            'cpu': ['cpu-20', 'cpu-40', 'cpu-60', 'cpu-80'],  # æ¸¬è©¦4ç¨®CPUé…ç½®
            'mem': ['mem-40', 'mem-80'],
            'hybrid': [
                'cpu-20-mem-40', 'cpu-20-mem-80',
                'cpu-40-mem-40', 'cpu-40-mem-80', 
                'cpu-60-mem-40', 'cpu-60-mem-80',
                'cpu-80-mem-40', 'cpu-80-mem-80'
            ]
        }
        
        # Redis HPA é…ç½® (ç°¡åŒ–ç‚ºåªæ¸¬è©¦ CPU)
        self.redis_hpa_configs = {
            'cpu': ['cpu-20', 'cpu-40', 'cpu-60', 'cpu-80']
        }
        
        # HPA é…ç½®æ ¹ç›®éŒ„
        self.hpa_root = self.repo_root / "macK8S" / "HPA" / "onlineboutique"
        self.redis_hpa_root = self.repo_root / "macK8S" / "HPA" / "redis"
        
    def _load_config(self, config_path: Path) -> dict:
        """è¼‰å…¥å¯¦é©—é…ç½®æª”æ¡ˆ"""
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æª”æ¡ˆä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _setup_logging(self) -> logging.Logger:
        """è¨­å®šæ—¥èªŒç³»çµ±"""
        # ç¢ºä¿ runtime ç›®éŒ„å­˜åœ¨
        runtime_dir = Path("logs/runtime")
        runtime_dir.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨æ™‚é–“æˆ³å‰µå»ºå”¯ä¸€çš„æ—¥èªŒæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = runtime_dir / f"unified_experiment_{timestamp}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler(log_file, encoding='utf-8')
            ]
        )
        return logging.getLogger('UnifiedExperimentManager')
    
    def _load_environment(self):
        """è¼‰å…¥ç’°å¢ƒè®Šæ•¸"""
        env_file = self.repo_root / '.env'
        if env_file.exists():
            try:
                from dotenv import load_dotenv
                load_dotenv(env_file)
                self.logger.info(f"âœ… å·²è¼‰å…¥ç’°å¢ƒé…ç½®: {env_file}")
            except ImportError:
                self.logger.warning("python-dotenv æœªå®‰è£ï¼Œæ‰‹å‹•è§£æ .env æª”æ¡ˆ")
                self._manual_load_env(env_file)
        else:
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ° .env æª”æ¡ˆ")
    
    def _manual_load_env(self, env_file: Path):
        """æ‰‹å‹•è§£æ .env æª”æ¡ˆ"""
        with open(env_file) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value
    
    def validate_environment(self, use_case: str = "online_boutique") -> bool:
        """é©—è­‰å¯¦é©—ç’°å¢ƒ"""
        self.logger.info("ğŸ” é©—è­‰å¯¦é©—ç’°å¢ƒ...")
        
        # æª¢æŸ¥ Kubernetes ç’°å¢ƒ
        if not self._check_k8s_environment(use_case):
            return False
        
        # æª¢æŸ¥åˆ†æ•£å¼æ¸¬è©¦ç’°å¢ƒ
        if not self._check_distributed_testing():
            self.logger.warning("âš ï¸ åˆ†æ•£å¼æ¸¬è©¦ç’°å¢ƒæœªé…ç½®ï¼Œå°‡ä½¿ç”¨æœ¬åœ°æ¸¬è©¦")
        
        # æª¢æŸ¥å¯¦é©—è…³æœ¬
        if not self._check_experiment_scripts():
            return False
        
        self.logger.info("âœ… ç’°å¢ƒé©—è­‰é€šé")
        return True
    
    def _check_k8s_environment(self, use_case: str = "online_boutique") -> bool:
        """æª¢æŸ¥ Kubernetes ç’°å¢ƒ"""
        try:
            # æª¢æŸ¥ kubectl å‘½ä»¤
            subprocess.run(['kubectl', 'version', '--client'], 
                         capture_output=True, check=True)
            
            # æ ¹æ“š use_case é¸æ“‡è¦æª¢æŸ¥çš„ namespace å’ŒæœŸæœ›çš„ Pod æ•¸é‡
            if use_case == "redis":
                namespace = self.redis_namespace
                min_pods = 2  # redis-master, redis-slave (redis-exporter æ˜¯å¯é¸çš„)
                env_name = "Redis"
            else:
                namespace = self.namespace
                min_pods = 10  # OnlineBoutique çš„ 10 å€‹å¾®æœå‹™
                env_name = "OnlineBoutique"
            
            # æª¢æŸ¥æŒ‡å®š namespace çš„ Pod
            result = subprocess.run(
                ['kubectl', 'get', 'pods', '-n', namespace, '--no-headers'],
                capture_output=True, text=True, check=True
            )
            
            if not result.stdout.strip():
                self.logger.error(f"âŒ {env_name} namespace ({namespace}) ä¸­æ²’æœ‰ Pod")
                return False
            
            running_pods = [p for p in result.stdout.strip().split('\n') if 'Running' in p]
            
            # å°æ–¼ Redisï¼Œåªæª¢æŸ¥æ ¸å¿ƒæœå‹™
            if use_case == "redis":
                core_pods = [p for p in running_pods if 'redis-master' in p or 'redis-slave' in p]
                if len(core_pods) < min_pods:
                    self.logger.error(f"âŒ {env_name} æ ¸å¿ƒæœå‹™ä¸å®Œæ•´ï¼Œåƒ… {len(core_pods)} å€‹æ ¸å¿ƒ Pod é‹è¡Œ")
                    return False
            else:
                if len(running_pods) < min_pods:
                    self.logger.error(f"âŒ {env_name} ç’°å¢ƒä¸å®Œæ•´ï¼Œåƒ… {len(running_pods)} å€‹ Pod é‹è¡Œ")
                    return False
            
            self.logger.info(f"âœ… {env_name} ç’°å¢ƒæ­£å¸¸ï¼Œ{len(running_pods)} å€‹æœå‹™é‹è¡Œä¸­")
            return True
            
        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            self.logger.error(f"âŒ Kubernetes ç’°å¢ƒæª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _check_distributed_testing(self) -> bool:
        """æª¢æŸ¥åˆ†æ•£å¼æ¸¬è©¦ç’°å¢ƒ"""
        m1_host = os.getenv('M1_HOST')
        if not m1_host:
            return False
        
        try:
            import requests
            response = requests.get(f"{m1_host.rstrip('/')}/", timeout=5)
            self.logger.info(f"âœ… åˆ†æ•£å¼æ¸¬è©¦ä»£ç†é€£æ¥æ­£å¸¸: {m1_host}")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ åˆ†æ•£å¼æ¸¬è©¦ä»£ç†é€£æ¥å¤±æ•—: {e}")
            return False
    
    def _check_experiment_scripts(self) -> bool:
        """æª¢æŸ¥å¯¦é©—è…³æœ¬å­˜åœ¨æ€§"""
        for exp_name, exp_config in self.config['experiments'].items():
            script_path = self.repo_root / exp_config['script_path']
            if not script_path.exists():
                self.logger.error(f"âŒ å¯¦é©—è…³æœ¬ä¸å­˜åœ¨: {script_path}")
                return False
        
        self.logger.info("âœ… å¯¦é©—è…³æœ¬æª¢æŸ¥é€šé")
        return True
    
    def run_experiment(self, experiment: str, **kwargs) -> bool:
        """åŸ·è¡ŒæŒ‡å®šå¯¦é©—"""
        if experiment not in self.config['experiments']:
            self.logger.error(f"âŒ æœªçŸ¥å¯¦é©—: {experiment}")
            return False
        
        exp_config = self.config['experiments'][experiment]
        self.logger.info(f"ğŸš€ é–‹å§‹åŸ·è¡Œå¯¦é©—: {exp_config['name']}")
        
        # æ ¹æ“š use_case è¨­ç½®æ­£ç¢ºçš„ namespace
        use_case = kwargs.get('use_case', 'online_boutique')
        if use_case == 'redis':
            self.namespace = self.redis_namespace
            self.target_host = "redis-master.redis.svc.cluster.local"
        else:
            self.namespace = os.getenv("NAMESPACE_ONLINEBOUTIQUE", "onlineboutique")
            self.target_host = os.getenv("TARGET_HOST", "http://k8s.orb.local:8080")
        
        self.logger.info(f"ğŸ“ è¨­ç½®ç’°å¢ƒ: use_case={use_case}, namespace={self.namespace}")
        
        # ç”Ÿæˆé‹è¡Œæ¨™ç±¤ - ä½¿ç”¨æ–°çš„çµ±ä¸€æ ¼å¼
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        algorithm = kwargs.get('alg', 'ppo')
        model = kwargs.get('model', 'gat') if experiment == 'gnnrl' else 'baseline'
        goal = kwargs.get('goal', 'latency')
        steps = kwargs.get('steps', 5000)
        
        unified_tag = f"{timestamp}_{experiment}_{algorithm}_{model}_{goal}_{steps}"
        run_tag = kwargs.pop('run_tag', unified_tag)
        
        # æº–å‚™å‘½ä»¤
        script_path = self.repo_root / exp_config['script_path']
        
        if experiment == 'gym_hpa':
            return self._run_gym_hpa_experiment(script_path, run_tag, **kwargs)
        elif experiment == 'k8s_hpa':
            return self._run_k8s_hpa_experiment(script_path, run_tag, **kwargs)
        elif experiment == 'gnnrl':
            return self._run_gnnrl_experiment(script_path, run_tag, **kwargs)
        else:
            self.logger.error(f"âŒ å¯¦é©—åŸ·è¡Œå™¨æœªå¯¦ç¾: {experiment}")
            return False
    
    def _run_gym_hpa_experiment(self, script_path: Path, run_tag: str, **kwargs) -> bool:
        """åŸ·è¡Œ gym_hpa å¯¦é©—"""
        use_case = kwargs.get('use_case', 'online_boutique')
        self.logger.info(f"ğŸ¯ åŸ·è¡Œ Gym-HPA å¯¦é©— (æ‡‰ç”¨å ´æ™¯: {use_case})")
        
        # ç›´æ¥èª¿ç”¨ gym-hpa è…³æœ¬ï¼Œä¸ä¾è³´ rl_batch_loadtest.py
        gym_hpa_script = self.repo_root / "gym-hpa" / "policies" / "run" / "run.py"
        
        cmd = [
            sys.executable, str(gym_hpa_script),
            "--alg", str(kwargs.get('alg', 'ppo')),
            "--use_case", str(use_case),
            "--goal", str(kwargs.get('goal', 'latency')),
            "--steps", str(kwargs.get('steps', 1000)),
            "--total_steps", str(kwargs.get('steps', 5000))
        ]
        
        # æ¸¬è©¦æ¨¡å¼æˆ–è¨“ç·´æ¨¡å¼
        if kwargs.get('testing', False):
            cmd.append("--testing")
            cmd.extend(["--test_path", kwargs.get('load_path')])
            self.logger.info("ğŸ§ª ä½¿ç”¨æ¸¬è©¦æ¨¡å¼")
            training_proc = None
        else:
            cmd.append("--training")
            self.logger.info("ğŸ¯ ä½¿ç”¨è¨“ç·´æ¨¡å¼")
            
        if kwargs.get('k8s', False):
            cmd.append("--k8s")
            self.logger.info("âœ… å•Ÿç”¨ K8s é›†ç¾¤æ¨¡å¼")
        else:
            self.logger.info("ğŸ”„ ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        
        # é–‹å§‹è¨“ç·´/æ¸¬è©¦é€²ç¨‹
        if not kwargs.get('testing', False):
            # è¨“ç·´æ¨¡å¼ï¼šä¸¦è¡ŒåŸ·è¡Œ
            training_proc = subprocess.Popen(cmd, cwd=self.repo_root / "gym-hpa")
            self.logger.info(f"ğŸ”„ Gym-HPA è¨“ç·´å·²é–‹å§‹ï¼Œç«‹å³é–‹å§‹ä¸¦è¡Œè² è¼‰æ¸¬è©¦...")
        else:
            # æ¸¬è©¦æ¨¡å¼ï¼šä¹Ÿéœ€è¦ä¸¦è¡ŒåŸ·è¡Œï¼Œè®“æ¸¬è©¦éç¨‹ä¸­æœ‰æµé‡
            training_proc = subprocess.Popen(cmd, cwd=self.repo_root / "gym-hpa")
            self.logger.info(f"ğŸ§ª Gym-HPA æ¸¬è©¦å·²é–‹å§‹ï¼Œç«‹å³é–‹å§‹ä¸¦è¡Œè² è¼‰æ¸¬è©¦...")
        
        # æ ¹æ“šæ¸¬è©¦/è¨“ç·´æ¨¡å¼é¸æ“‡è² è¼‰æ¸¬è©¦ç­–ç•¥
        if kwargs.get('testing', False):
            # æ¸¬è©¦æ¨¡å¼ï¼šä½¿ç”¨å›ºå®š4å ´æ™¯è©•ä¼°æ€§èƒ½
            self.logger.info("ğŸ§ª æ¸¬è©¦æ¨¡å¼ï¼šåŸ·è¡Œå›ºå®š4å€‹å ´æ™¯")
            scenario_dirs = self.run_fixed_hpa_loadtest(
                "gym-hpa", run_tag, kwargs.get('seed', 42)
            )
        else:
            # è¨“ç·´æ¨¡å¼ï¼šä½¿ç”¨éš¨æ©Ÿå ´æ™¯æé«˜æ³›åŒ–èƒ½åŠ›
            self.logger.info("ğŸ¯ è¨“ç·´æ¨¡å¼ï¼šä½¿ç”¨éš¨æ©Ÿå ´æ™¯å£“æ¸¬")
            scenario_dirs = self.run_continuous_loadtest(
                "gym-hpa", run_tag, kwargs.get('seed', 42), training_proc
            )
        
        return len(scenario_dirs) > 0
    
    def _run_k8s_hpa_experiment(self, script_path: Path, run_tag: str, **kwargs) -> bool:
        """åŸ·è¡Œ k8s_hpa åŸºæº–æ¸¬è©¦"""
        self.logger.info("ğŸ“Š åŸ·è¡Œ K8s HPA åŸºæº–æ¸¬è©¦")
        
        # HPA åŸºæº–æ¸¬è©¦åªåŸ·è¡Œè² è¼‰æ¸¬è©¦ï¼Œä¸éœ€è¦è¨“ç·´é€²ç¨‹
        self.logger.info("âœ… ä½¿ç”¨çœŸå¯¦ K8s é›†ç¾¤é€²è¡Œ HPA åŸºæº–æ¸¬è©¦")
        
        # ç²å–HPAé…ç½®é¡å‹é¸æ“‡
        hpa_type = kwargs.get('hpa_type', 'all')  # all, cpu, mem, hybrid
        seed = kwargs.get('seed', 42)
        
        # åŸ·è¡Œå¤šé…ç½®HPAæ¸¬è©¦
        total_results = self.run_multi_hpa_experiment(
            "k8s-hpa", run_tag, seed, hpa_type
        )
        
        return len(total_results) > 0
    
    def _run_gnnrl_experiment(self, script_path: Path, run_tag: str, **kwargs) -> bool:
        """åŸ·è¡Œ GNNRL å¯¦é©—"""
        use_case = kwargs.get('use_case', 'online_boutique')
        self.logger.info(f"ğŸ§  åŸ·è¡Œ GNNRL å¯¦é©— (æ‡‰ç”¨å ´æ™¯: {use_case})")
        
        # GNNRL æ”¯æŒå…©ç¨®ç’°å¢ƒ
        if use_case == 'redis':
            self.logger.info("ğŸ“Š GNNRL Redis ç’°å¢ƒå¯¦é©—")
        else:
            self.logger.info("ğŸ“Š GNNRL OnlineBoutique ç’°å¢ƒå¯¦é©—")
        
        # ç›´æ¥èª¿ç”¨ GNNRL è…³æœ¬
        gnnrl_script = self.repo_root / "gnnrl" / "training" / "run_gnnrl_experiment.py"
        
        cmd = [
            sys.executable, str(gnnrl_script),
            "--steps", str(kwargs.get('steps', 5000)),
            "--goal", str(kwargs.get('goal', 'latency')),
            "--alg", str(kwargs.get('alg', 'ppo')),
            "--model", str(kwargs.get('model', 'gat')),
            "--env-step-interval", str(kwargs.get('env_step_interval', 15.0)),
            "--use-case", str(use_case)
        ]
        
        if kwargs.get('k8s', False):
            cmd.append("--k8s")
            self.logger.info("âœ… å•Ÿç”¨ K8s é›†ç¾¤æ¨¡å¼")
        else:
            self.logger.info("ğŸ”„ ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        
        # GNNRL æ¸¬è©¦æ¨¡å¼è™•ç†
        if kwargs.get('testing', False):
            self.logger.info("ğŸ§ª GNNRL æ¸¬è©¦æ¨¡å¼ï¼šè¼‰å…¥å·²è¨“ç·´æ¨¡å‹é€²è¡Œè©•ä¼°")
            load_path = kwargs.get('load_path')
            if not load_path or not Path(load_path).exists():
                self.logger.error(f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {load_path}")
                return False
            
            cmd.extend([
                "--testing",
                "--load-path", str(load_path)
            ])
            
            self.logger.info(f"ğŸ“‚ è¼‰å…¥æ¨¡å‹æª”æ¡ˆ: {load_path}")
            # æ¸¬è©¦æ¨¡å¼ï¼šåŒæ­¥åŸ·è¡ŒGNNRLæ¸¬è©¦å’Œè² è¼‰æ¸¬è©¦
            self.logger.info("ğŸ§ª GNNRL æ¸¬è©¦æ¨¡å¼ï¼šåŸ·è¡Œå›ºå®š4å€‹å ´æ™¯æ¸¬è©¦")
            
            # å…ˆå•Ÿå‹•è² è¼‰æ¸¬è©¦ï¼Œå†å•Ÿå‹•GNNRLæ¸¬è©¦é€²ç¨‹
            import threading
            
            def run_gnnrl_testing():
                training_proc = subprocess.Popen(cmd, cwd=self.repo_root / "gnnrl")
                self.logger.info(f"ğŸ”„ GNNRL æ¸¬è©¦é€²ç¨‹å·²é–‹å§‹...")
                training_proc.wait()
                self.logger.info(f"âœ… GNNRL æ¸¬è©¦é€²ç¨‹å·²å®Œæˆ")
            
            # åœ¨åå°å¯åŠ¨GNNRLæµ‹è¯•
            gnnrl_thread = threading.Thread(target=run_gnnrl_testing)
            gnnrl_thread.daemon = True
            gnnrl_thread.start()
            
            # ç­‰å¾…GNNRLè¿›ç¨‹åˆå§‹åŒ–ï¼ˆ3ç§’ï¼‰
            time.sleep(3)
            
            # ç«‹å³å¼€å§‹è´Ÿè½½æµ‹è¯•åœºæ™¯
            selected_scenarios = kwargs.get('test_scenarios')
            if selected_scenarios:
                # ä½¿ç”¨é¸å®šå ´æ™¯é€²è¡Œæ¸¬è©¦
                scenario_dirs = self.run_selected_scenarios_loadtest(
                    "gnnrl", run_tag, kwargs.get('seed', 42), selected_scenarios
                )
            else:
                # ä½¿ç”¨æ‰€æœ‰å ´æ™¯é€²è¡Œæ¸¬è©¦ï¼ˆåŸä¾†çš„è¡Œç‚ºï¼‰
                scenario_dirs = self.run_fixed_hpa_loadtest(
                    "gnnrl", run_tag, kwargs.get('seed', 42)
                )
            
            # ç­‰å¾…GNNRLæµ‹è¯•å®Œå…¨ç»“æŸ
            gnnrl_thread.join()
        else:
            # è¨“ç·´æ¨¡å¼ï¼šå•Ÿå‹• GNNRL è¨“ç·´é€²ç¨‹
            self.logger.info("ğŸ¯ ä½¿ç”¨è¨“ç·´æ¨¡å¼")
            training_proc = subprocess.Popen(cmd, cwd=self.repo_root / "gnnrl")
            self.logger.info(f"ğŸ”„ GNNRL è¨“ç·´å·²é–‹å§‹ï¼Œé–‹å§‹éš¨æ©Ÿå ´æ™¯å£“æ¸¬...")
            
            # è¨“ç·´æ¨¡å¼ï¼šå§‹çµ‚ä½¿ç”¨éš¨æ©Ÿå ´æ™¯å£“æ¸¬ç›´åˆ°è¨“ç·´å®Œæˆ
            # å¿½ç•¥ stable_loadtest åƒæ•¸ï¼Œå› ç‚ºè¨“ç·´éœ€è¦éš¨æ©Ÿå ´æ™¯ä¾†å­¸ç¿’ä¸åŒè² è¼‰æ¨¡å¼
            scenario_dirs = self.run_continuous_loadtest(
                "gnnrl", run_tag, kwargs.get('seed', 42), training_proc
            )
        
        return len(scenario_dirs) > 0
    
    def run_batch_experiments(self, experiments: List[str], **kwargs) -> Dict[str, bool]:
        """æ‰¹æ¬¡åŸ·è¡Œå¤šå€‹å¯¦é©—"""
        self.logger.info(f"ğŸ”„ æ‰¹æ¬¡åŸ·è¡Œå¯¦é©—: {', '.join(experiments)}")
        
        results = {}
        for experiment in experiments:
            self.logger.info(f"{'='*60}")
            success = self.run_experiment(experiment, **kwargs)
            results[experiment] = success
            
            if success:
                self.logger.info(f"âœ… {experiment} å¯¦é©—æˆåŠŸ")
            else:
                self.logger.error(f"âŒ {experiment} å¯¦é©—å¤±æ•—")
            
            # å¯¦é©—é–“å†·å»
            if experiment != experiments[-1]:
                cooldown = 120  # 2åˆ†é˜
                self.logger.info(f"â¸ï¸ å¯¦é©—é–“å†·å» {cooldown} ç§’...")
                time.sleep(cooldown)
        
        # ç”Ÿæˆæ‰¹æ¬¡æ‘˜è¦
        self._generate_batch_summary(results)
        return results
    
    def _generate_batch_summary(self, results: Dict[str, bool]):
        """ç”Ÿæˆæ‰¹æ¬¡å¯¦é©—æ‘˜è¦"""
        summary_file = self.repo_root / "logs" / "batch_summary.txt"
        summary_file.parent.mkdir(exist_ok=True)
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("æ‰¹æ¬¡å¯¦é©—åŸ·è¡Œæ‘˜è¦\n")
            f.write("="*50 + "\n")
            f.write(f"åŸ·è¡Œæ™‚é–“: {datetime.now()}\n\n")
            
            for experiment, success in results.items():
                status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
                f.write(f"{experiment}: {status}\n")
            
            success_count = sum(results.values())
            total_count = len(results)
            f.write(f"\nç¸½è¨ˆ: {success_count}/{total_count} å€‹å¯¦é©—æˆåŠŸ\n")
        
        self.logger.info(f"ğŸ“„ æ‰¹æ¬¡æ‘˜è¦å·²ä¿å­˜: {summary_file}")
    
    def record_kiali_graph(self, stage: str) -> None:
        """è¨˜éŒ„ Kiali æœå‹™åœ–"""
        self.logger.info(f"ğŸ” è¨˜éŒ„ Kiali åœ–è¡¨ ({stage})")
        url = f"{self.kiali_url}/api/namespaces/graph?namespaces={self.namespace}&duration=600s&graphType=workload"
        try:
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()
            # ç¢ºä¿ kiali ç›®éŒ„å­˜åœ¨
            kiali_dir = Path("logs/kiali")
            kiali_dir.mkdir(parents=True, exist_ok=True)
            kiali_file = kiali_dir / f"kiali_{stage}_{self.timestamp}.json"
            kiali_file.write_text(resp.text, encoding="utf-8")
            self.logger.info(f"âœ… Kiali åœ–è¡¨å·²ä¿å­˜: {kiali_file}")
        except Exception as err:
            self.logger.warning(f"âš ï¸ Kiali åœ–è¡¨è¨˜éŒ„å¤±æ•—: {err}")
    
    def _setup_pod_monitoring(self, scenario: str, out_dir: Path) -> Optional[MultiPodMonitor]:
        """è¨­ç½®Podç›£æ§
        
        Args:
            scenario: ç•¶å‰å ´æ™¯åç¨±
            out_dir: è¼¸å‡ºç›®éŒ„
            
        Returns:
            é…ç½®å¥½çš„Podç›£æ§å™¨ï¼Œå¦‚æœè¨­ç½®å¤±æ•—å‰‡è¿”å›None
        """
        try:
            # ç¢ºå®šå¯¦é©—é¡å‹ (å¾è¼¸å‡ºè·¯å¾‘æ¨æ–·)
            experiment_type = "unknown"
            if "gnnrl" in str(out_dir):
                experiment_type = "gnnrl"
            elif "gym-hpa" in str(out_dir) or "gym_hpa" in str(out_dir):
                experiment_type = "gym-hpa"
            elif "k8s-hpa" in str(out_dir) or "k8s_hpa" in str(out_dir):
                experiment_type = "k8s-hpa"
            
            # è¨­ç½®Podç›£æ§è¼¸å‡ºç›®éŒ„
            pod_monitoring_dir = out_dir / "pod_metrics"
            
            # ç¢ºå®šè¦ç›£æ§çš„namespaceåˆ—è¡¨
            namespaces_to_monitor = []
            
            # æ ¹æ“šç•¶å‰ä½¿ç”¨çš„namespaceæ·»åŠ ç›£æ§
            if self.namespace:
                namespaces_to_monitor.append(self.namespace)
            
            # å¦‚æœæ˜¯OnlineBoutiqueç’°å¢ƒï¼Œä¹Ÿç›£æ§rediså’Œdefault namespaceï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if self.namespace == 'onlineboutique':
                # æª¢æŸ¥redis namespaceæ˜¯å¦å­˜åœ¨
                try:
                    result = subprocess.run([
                        'kubectl', 'get', 'namespace', 'redis'
                    ], capture_output=True, text=True)
                    if result.returncode == 0:
                        namespaces_to_monitor.append('redis')
                except Exception:
                    pass
            
            # å¦‚æœæ˜¯Redisç’°å¢ƒï¼Œä¹Ÿç›£æ§onlineboutique namespaceï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            elif self.namespace == 'redis':
                try:
                    result = subprocess.run([
                        'kubectl', 'get', 'namespace', 'onlineboutique'
                    ], capture_output=True, text=True)
                    if result.returncode == 0:
                        namespaces_to_monitor.append('onlineboutique')
                except Exception:
                    pass
            
            if not namespaces_to_monitor:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°å¯ç›£æ§çš„namespace")
                return None
            
            # å‰µå»ºPodç›£æ§å™¨
            pod_monitor = create_pod_monitor_for_experiment(
                experiment_type=experiment_type,
                scenario=scenario,
                namespaces=namespaces_to_monitor,
                output_dir=pod_monitoring_dir
            )
            
            self.logger.info(f"âœ… Podç›£æ§å·²è¨­ç½® - å¯¦é©—é¡å‹: {experiment_type}, å ´æ™¯: {scenario}, Namespaces: {namespaces_to_monitor}")
            return pod_monitor
            
        except Exception as e:
            self.logger.error(f"âŒ Podç›£æ§è¨­ç½®å¤±æ•—: {e}")
            return None

    def run_distributed_locust(self, scenario: str, tag: str, out_dir: Path) -> bool:
        """é‹è¡Œåˆ†æ•£å¼ Locust æ¸¬è©¦"""
        out_dir.mkdir(parents=True, exist_ok=True)
        
        # åœ¨è² è¼‰æ¸¬è©¦å‰é‡ç½® Pod æ•¸é‡
        self.logger.info(f"ğŸ”„ å ´æ™¯ {scenario} æ¸¬è©¦å‰é‡ç½® Pod æ•¸é‡")
        if not self._reset_all_namespaces_pods():
            self.logger.warning("âš ï¸ Pod é‡ç½®å¤±æ•—ï¼Œä½†ç¹¼çºŒé€²è¡Œè² è¼‰æ¸¬è©¦")
        
        if self.m1_host:
            return self._run_remote_locust(scenario, tag, out_dir)
        else:
            return self._run_local_locust(scenario, out_dir)
    
    def _run_remote_locust(self, scenario: str, tag: str, out_dir: Path) -> bool:
        """é‹è¡Œé ç«¯ Locust æ¸¬è©¦"""
        host = self.m1_host.rstrip("/")
        self.logger.info(f"ğŸ”— åˆ†æ•£å¼æ¸¬è©¦: M1_HOST={host}")
        self.logger.info(f"ğŸš€ è§¸ç™¼é ç«¯ Locust {scenario}")
        
        # è‡ªå‹•åˆ¤æ–·ç’°å¢ƒé¡å‹
        environment = 'onlineboutique' if self.namespace == 'onlineboutique' else 'redis'
        
        # é‡å°Redisç’°å¢ƒï¼Œèª¿æ•´target_host
        target_host = self.target_host
        if environment == 'redis':
            # å°æ–¼Redisç’°å¢ƒï¼Œä½¿ç”¨NodePort 30379
            target_host = "redis://10.0.0.1:30379"
            self.logger.info(f"ğŸ”§ Redisç’°å¢ƒdetectedï¼Œä½¿ç”¨ target_host: {target_host}")
        
        payload = {
            "tag": tag,
            "scenario": scenario,
            "target_host": target_host,
            "run_time": self.locust_run_time,
            "environment": environment,
            "namespace": self.namespace,
            "stable_mode": self.stable_loadtest,
            "max_rps": self.target_rps,
            "timeout": self.loadtest_timeout,
        }
        
        try:
            # é–‹å§‹é ç«¯æ¸¬è©¦
            r = requests.post(f"{host}/start", json=payload, timeout=10)
            r.raise_for_status()
            job_id = r.json()["job_id"]
            self.logger.info(f"ğŸ“‹ é ç«¯ä»»å‹™ ID: {job_id}")
            
            # è¨˜éŒ„é–‹å§‹ç‹€æ…‹
            self.record_kiali_graph("start")
            
            # å•Ÿå‹•Podç›£æ§
            pod_monitor = self._setup_pod_monitoring(scenario, out_dir)
            if pod_monitor:
                pod_monitor.start_all_monitoring(15)  # 15åˆ†é˜ç›£æ§
            
            # ä¸­é€”æª¢æŸ¥é»
            time.sleep(self.half_run_sec)
            self.record_kiali_graph("mid")
            
            # ç­‰å¾…å®Œæˆ
            max_checks = int(os.getenv("MAX_STATUS_CHECKS", "720"))
            for check_count in range(max_checks):
                time.sleep(5)
                
                st = requests.get(f"{host}/status/{job_id}", timeout=10)
                st.raise_for_status()
                data = st.json()
                
                if data.get("finished"):
                    self.logger.info(f"âœ… é ç«¯æ¸¬è©¦ {scenario} å®Œæˆ")
                    break
                    
                if check_count % 10 == 0:
                    self.logger.debug(f"â³ é ç«¯æ¸¬è©¦ç‹€æ…‹ [{check_count+1}/{max_checks}]: running")
            else:
                self.logger.warning("â° é ç«¯æ¸¬è©¦è¶…æ™‚")
                return False
                
            self.record_kiali_graph("end")
            
            # åœæ­¢Podç›£æ§
            if pod_monitor:
                pod_monitor.stop_all_monitoring()
            
            # ä¸‹è¼‰çµæœæª”æ¡ˆ
            downloaded_files = []
            for fname in [f"{scenario}_stats.csv", f"{scenario}_stats_history.csv", f"{scenario}.html"]:
                resp = requests.get(f"{host}/download/{tag}/{fname}", timeout=10)
                if resp.status_code == 200:
                    (out_dir / fname).write_bytes(resp.content)
                    downloaded_files.append(fname)
                else:
                    self.logger.warning(f"âŒ ä¸‹è¼‰å¤±æ•—: {fname}")
            
            self.logger.info(f"ğŸ“Š é ç«¯æ¸¬è©¦çµæœ: å·²ä¸‹è¼‰ {len(downloaded_files)}/3 æª”æ¡ˆ")
            return len(downloaded_files) > 0
            
        except requests.RequestException as exc:
            self.logger.error(f"âŒ é ç«¯æ¸¬è©¦å¤±æ•—: {exc}")
            self.logger.info("ğŸ”„ åˆ‡æ›åˆ°æœ¬åœ°æ¸¬è©¦")
            return self._run_local_locust(scenario, out_dir)
    
    def _run_local_locust(self, scenario: str, out_dir: Path) -> bool:
        """é‹è¡Œæœ¬åœ° Locust æ¸¬è©¦ - æ”¯æŒå…©ç¨®ç’°å¢ƒå’Œ stable æ¨¡å¼"""
        # æª¢æŸ¥ç’°å¢ƒé¡å‹
        environment = 'onlineboutique' if self.namespace == 'onlineboutique' else 'redis'
        
        # æ ¹æ“šç’°å¢ƒé¸æ“‡è…³æœ¬ï¼ˆç¾åœ¨éƒ½æ˜¯ç©©å®šç‰ˆæœ¬ï¼‰
        if environment == 'redis':
            script_name = f"locust_redis_{scenario}.py"
        else:
            script_name = f"locust_{scenario}.py"
        
        # å„ªå…ˆå˜—è©¦ç’°å¢ƒå°ˆç”¨è…³æœ¬
        script_path = self.repo_root / "loadtest" / environment / script_name
        
        # å¦‚æœç’°å¢ƒå°ˆç”¨è…³æœ¬ä¸å­˜åœ¨ï¼Œå˜—è©¦fallback
        if not script_path.exists():
            if environment == 'redis':
                # Redis ç’°å¢ƒï¼Œä½†è…³æœ¬ä¸å­˜åœ¨
                self.logger.error(f"âŒ Redis æ¸¬è©¦è…³æœ¬ä¸å­˜åœ¨: {script_name}")
                return False
            else:
                # OnlineBoutique é€šç”¨è…³æœ¬
                script_path = self.repo_root / "loadtest" / "onlineboutique" / script_name
            
        if not script_path.exists():
            self.logger.error(f"âŒ æ¸¬è©¦è…³æœ¬ä¸å­˜åœ¨: {script_path}")
            return False
            
        self.logger.info(f"ğŸ  é‹è¡Œæœ¬åœ° Locust {scenario} (ç’°å¢ƒ: {environment})")
        
        # æº–å‚™ç’°å¢ƒè®Šæ•¸
        env = os.environ.copy()
        
        # è¨­å®šç›®æ¨™ RPSï¼ˆå¦‚æœæŒ‡å®šçš„è©±ï¼‰
        if self.target_rps:
            env['LOCUST_TARGET_RPS'] = str(self.target_rps)
            self.logger.info(f"ğŸ¯ ç›®æ¨™ RPS = {self.target_rps}")
        
        # è¨­å®šå…¶ä»–ç’°å¢ƒè®Šæ•¸
        env['LOCUST_RUN_TIME'] = self.locust_run_time
        if hasattr(self, 'loadtest_timeout'):
            env['LOCUST_REQUEST_TIMEOUT'] = str(self.loadtest_timeout)
        
        cmd = [
            "locust", "-f", str(script_path), "--headless", "--run-time", self.locust_run_time,
            "--host", self.target_host,
            "--csv", str(out_dir / scenario), "--csv-full-history",
            "--html", str(out_dir / f"{scenario}.html"),
        ]
        
        proc = subprocess.Popen(cmd, env=env)
        
        self.record_kiali_graph("start")
        
        # å•Ÿå‹•Podç›£æ§
        pod_monitor = self._setup_pod_monitoring(scenario, out_dir)
        if pod_monitor:
            pod_monitor.start_all_monitoring(15)  # 15åˆ†é˜ç›£æ§
        
        time.sleep(self.half_run_sec)
        self.record_kiali_graph("mid")
        
        # ç­‰å¾…æ¸¬è©¦å®Œæˆ
        proc.wait()
        
        self.record_kiali_graph("end")
        
        # åœæ­¢Podç›£æ§
        if pod_monitor:
            pod_monitor.stop_all_monitoring()
        
        if proc.returncode:
            self.logger.warning(f"âš ï¸ æœ¬åœ°æ¸¬è©¦ {scenario} çµæŸç¢¼: {proc.returncode}")
            return False
        else:
            self.logger.info(f"âœ… æœ¬åœ°æ¸¬è©¦ {scenario} å®Œæˆ")
            return True

    def run_continuous_loadtest(self, experiment_type: str, run_tag: str, seed: int, training_proc: subprocess.Popen = None) -> List[Path]:
        """æŒçºŒé‹è¡Œéš¨æ©Ÿ Locust æ¸¬è©¦ç›´åˆ°è¨“ç·´å®Œæˆ"""
        random.seed(seed)
        scenario_list = list(self.scenarios.keys())
        scenario_dirs = []
        scenario_count = 0
        
        # å‰µå»ºåŸºç¤è¼¸å‡ºç›®éŒ„
        base_output_dir = self.repo_root / "logs" / experiment_type / run_tag
        base_output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"ğŸ² ä½¿ç”¨éš¨æ©Ÿç¨®å­ {seed}ï¼Œå¯ç”¨æƒ…å¢ƒ: {', '.join(scenario_list)}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è¨“ç·´é€²ç¨‹éœ€è¦ç­‰å¾…
        has_training_proc = training_proc is not None
        
        # æŒçºŒéš¨æ©ŸåŸ·è¡Œå ´æ™¯ç›´åˆ°è¨“ç·´å®Œæˆæˆ–è‡³å°‘åŸ·è¡Œä¸€å€‹å ´æ™¯
        while True:
            # æª¢æŸ¥è¨“ç·´æ˜¯å¦å®Œæˆ
            if has_training_proc and training_proc.poll() is not None:
                self.logger.info("âœ… è¨“ç·´é€²ç¨‹å·²å®Œæˆ")
                break
            
            # éš¨æ©Ÿé¸æ“‡å ´æ™¯
            scenario = random.choice(scenario_list)
            scenario_count += 1
            
            # å‰µå»ºå”¯ä¸€çš„è¼¸å‡ºç›®éŒ„
            out_dir = base_output_dir / f"{scenario}_{scenario_count:03d}"
            self.logger.info(f"ğŸ“Š åŸ·è¡Œéš¨æ©Ÿæ¸¬è©¦æƒ…å¢ƒ [ç¬¬{scenario_count}å€‹]: {scenario}")
            
            # æ§‹å»ºé ç«¯æ¨™ç±¤
            remote_tag = f"{experiment_type}/{run_tag}" if self.m1_host else run_tag
            
            # åŸ·è¡Œ Locust æ¸¬è©¦
            success = self.run_distributed_locust(scenario, remote_tag, out_dir)
            if success:
                scenario_dirs.append(out_dir)
            
            # æƒ…å¢ƒé–“å†·å»æ™‚é–“
            if has_training_proc and training_proc.poll() is None:
                cooldown = int(os.getenv("COOLDOWN_BETWEEN_SCENARIOS", "60"))
                self.logger.info(f"â¸ï¸ æƒ…å¢ƒé–“å†·å» {cooldown} ç§’...")
                time.sleep(cooldown)
            elif not has_training_proc:
                # å¦‚æœæ²’æœ‰è¨“ç·´é€²ç¨‹ï¼ŒåŸ·è¡Œä¸€å€‹å ´æ™¯å¾ŒçµæŸ
                break
        
        # æœ€çµ‚ç­‰å¾…è¨“ç·´å®Œæˆ
        if has_training_proc and training_proc.poll() is None:
            self.logger.info("â³ æœ€çµ‚ç­‰å¾…è¨“ç·´é€²ç¨‹å®Œæˆ...")
            training_proc.wait()
        
        self.logger.info(f"ğŸ ç¸½å…±åŸ·è¡Œäº† {len(scenario_dirs)} å€‹éš¨æ©Ÿå ´æ™¯æ¸¬è©¦")
        return scenario_dirs

    def run_fixed_hpa_loadtest(self, experiment_type: str, run_tag: str, seed: int) -> List[Path]:
        """é‹è¡Œå›ºå®šçš„ 4 å€‹å ´æ™¯åºåˆ—ï¼ˆç”¨æ–¼åŸºæº–æ¸¬è©¦å’Œå…¬å¹³æ¯”è¼ƒï¼‰"""
        # æ¸¬è©¦æ¨¡å¼ï¼šåŸ·è¡Œæ‰€æœ‰ 4 å€‹å ´æ™¯ï¼Œä½¿ç”¨ seed ä¾†æ±ºå®šåŸ·è¡Œé †åº
        random.seed(seed)
        scenario_list = list(self.scenarios.keys())
        
        # æ¸¬è©¦æ¨¡å¼æ‡‰è©²åŸ·è¡Œæ‰€æœ‰å ´æ™¯ï¼Œåªæ˜¯é †åºæ ¹æ“š seed æ±ºå®š
        if len(scenario_list) >= 4:
            fixed_sequence = scenario_list.copy()
            random.shuffle(fixed_sequence)  # é †åºéš¨æ©ŸåŒ–ï¼Œä½†åŒ…å«æ‰€æœ‰å ´æ™¯
        else:
            # å¦‚æœå ´æ™¯å°‘æ–¼4å€‹ï¼Œå°±å…¨éƒ¨ä½¿ç”¨
            fixed_sequence = scenario_list
        
        self.logger.info(f"ğŸ“‹ æ¸¬è©¦æ¨¡å¼ï¼šåŸ·è¡Œæ‰€æœ‰ {len(fixed_sequence)} å€‹å ´æ™¯ (é †åº seed {seed}): {', '.join(fixed_sequence)}")
        
        # å‰µå»ºåŸºç¤è¼¸å‡ºç›®éŒ„
        base_output_dir = self.repo_root / "logs" / experiment_type / run_tag
        base_output_dir.mkdir(parents=True, exist_ok=True)
        
        scenario_dirs = []
        
        # åŸ·è¡Œå›ºå®šåºåˆ—çš„ 4 å€‹å ´æ™¯
        for i, scenario in enumerate(fixed_sequence, 1):
            out_dir = base_output_dir / f"{scenario}_{i:03d}"
            self.logger.info(f"ğŸ“Š åŸ·è¡Œå›ºå®šæ¸¬è©¦æƒ…å¢ƒ [{i}/4]: {scenario}")
            
            # æ§‹å»ºé ç«¯æ¨™ç±¤
            remote_tag = f"{experiment_type}/{run_tag}" if self.m1_host else run_tag
            
            # åŸ·è¡Œ Locust æ¸¬è©¦
            success = self.run_distributed_locust(scenario, remote_tag, out_dir)
            if success:
                scenario_dirs.append(out_dir)
            
            # å ´æ™¯é–“çŸ­æš«å†·å»
            if i < len(fixed_sequence):
                cooldown = 60  # å›ºå®šæ¸¬è©¦é–“çš„æ¨™æº–å†·å»æ™‚é–“
                self.logger.info(f"â¸ï¸ å›ºå®šå ´æ™¯é–“å†·å» {cooldown} ç§’...")
                time.sleep(cooldown)
        
        self.logger.info(f"ğŸ å›ºå®šå ´æ™¯æ¸¬è©¦å®Œæˆï¼ŒåŸ·è¡Œäº† {len(scenario_dirs)} å€‹å ´æ™¯")
        return scenario_dirs
    
    def run_selected_scenarios_loadtest(self, experiment_type: str, run_tag: str, seed: int, selected_scenarios: list) -> List[Path]:
        """åŸ·è¡Œé¸å®šå ´æ™¯çš„è² è¼‰æ¸¬è©¦
        
        Args:
            experiment_type: å¯¦é©—é¡å‹
            run_tag: é‹è¡Œæ¨™ç±¤
            seed: éš¨æ©Ÿç¨®å­ï¼ˆç”¨æ–¼ç”Ÿæˆå ´æ™¯é †åºï¼‰
            selected_scenarios: é¸å®šçš„å ´æ™¯åˆ—è¡¨ï¼Œä¾‹å¦‚ ['peak', 'rushsale']
        
        Returns:
            åŸ·è¡ŒæˆåŠŸçš„å ´æ™¯ç›®éŒ„åˆ—è¡¨
        """
        # é©—è­‰é¸å®šå ´æ™¯
        available_scenarios = list(self.scenarios.keys())
        valid_scenarios = [s for s in selected_scenarios if s in available_scenarios]
        
        if not valid_scenarios:
            self.logger.error(f"âŒ æ²’æœ‰æœ‰æ•ˆçš„å ´æ™¯ã€‚å¯ç”¨å ´æ™¯: {', '.join(available_scenarios)}")
            return []
        
        if len(valid_scenarios) < len(selected_scenarios):
            invalid_scenarios = [s for s in selected_scenarios if s not in available_scenarios]
            self.logger.warning(f"âš ï¸ å¿½ç•¥ç„¡æ•ˆå ´æ™¯: {', '.join(invalid_scenarios)}")
        
        # ä½¿ç”¨ç¨®å­æ±ºå®šå ´æ™¯é †åº
        random.seed(seed)
        test_sequence = valid_scenarios.copy()
        random.shuffle(test_sequence)  # æ‰“äº‚é †åºä½†ä¿æŒé¸å®šå ´æ™¯
        
        self.logger.info(f"ğŸ“‹ é¸å®šå ´æ™¯æ¸¬è©¦ï¼šåŸ·è¡Œ {len(test_sequence)} å€‹å ´æ™¯ (seed {seed}): {', '.join(test_sequence)}")
        
        # å‰µå»ºåŸºç¤è¼¸å‡ºç›®éŒ„
        base_output_dir = self.repo_root / "logs" / experiment_type / run_tag
        base_output_dir.mkdir(parents=True, exist_ok=True)
        
        scenario_dirs = []
        
        # åŸ·è¡Œé¸å®šå ´æ™¯
        for i, scenario in enumerate(test_sequence, 1):
            out_dir = base_output_dir / f"{scenario}_{i:03d}"
            self.logger.info(f"ğŸ“Š åŸ·è¡Œé¸å®šæ¸¬è©¦æƒ…å¢ƒ [{i}/{len(test_sequence)}]: {scenario}")
            
            # æ§‹å»ºé ç«¯æ¨™ç±¤
            remote_tag = f"{experiment_type}/{run_tag}" if self.m1_host else run_tag
            
            # åŸ·è¡Œ Locust æ¸¬è©¦
            success = self.run_distributed_locust(scenario, remote_tag, out_dir)
            if success:
                scenario_dirs.append(out_dir)
            
            # å ´æ™¯é–“çŸ­æš«å†·å»
            if i < len(test_sequence):
                cooldown = 60  # å›ºå®šæ¸¬è©¦é–“çš„æ¨™æº–å†·å»æ™‚é–“
                self.logger.info(f"â¸ï¸ å ´æ™¯é–“å†·å» {cooldown} ç§’...")
                time.sleep(cooldown)
        
        self.logger.info(f"ğŸ é¸å®šå ´æ™¯æ¸¬è©¦å®Œæˆï¼ŒåŸ·è¡Œäº† {len(scenario_dirs)} å€‹å ´æ™¯")
        return scenario_dirs
    
    def run_multi_hpa_experiment(self, experiment_type: str, run_tag: str, seed: int, hpa_type: str = 'all') -> List[Path]:
        """åŸ·è¡Œå¤šé…ç½®HPAæ¸¬è©¦
        
        Args:
            experiment_type: å¯¦é©—é¡å‹
            run_tag: é‹è¡Œæ¨™ç±¤ 
            seed: éš¨æ©Ÿç¨®å­ï¼ˆç”¨æ–¼ç”Ÿæˆå›ºå®šå ´æ™¯åºåˆ—ï¼‰
            hpa_type: HPAé…ç½®é¡å‹ ('all', 'cpu', 'mem', 'hybrid')
        
        Returns:
            æ‰€æœ‰æ¸¬è©¦çµæœç›®éŒ„åˆ—è¡¨
        """
        
        # ç²å–è¦æ¸¬è©¦çš„HPAé…ç½®
        if hpa_type == 'all':
            configs_to_test = []
            for config_type in self.hpa_configs:
                configs_to_test.extend(self.hpa_configs[config_type])
        elif hpa_type in self.hpa_configs:
            configs_to_test = self.hpa_configs[hpa_type]
        else:
            self.logger.error(f"âŒ ä¸æ”¯æ´çš„HPAé¡å‹: {hpa_type}. å¯ç”¨é¡å‹: all, cpu, mem, hybrid")
            return []
        
        self.logger.info(f"ğŸ“ˆ æ¸¬è©¦HPAé¡å‹: {hpa_type}, å…± {len(configs_to_test)} ç¨®é…ç½®")
        self.logger.info(f"ğŸ“‹ é…ç½®åˆ—è¡¨: {', '.join(configs_to_test)}")
        
        # ç”Ÿæˆå›ºå®šçš„å ´æ™¯åºåˆ—ï¼ˆæ‰€æœ‰HPAé…ç½®éƒ½ç”¨ç›¸åŒåºåˆ—ï¼‰
        test_sequence = self._generate_hpa_test_sequence(seed)
        self.logger.info(f"ğŸ² ä½¿ç”¨å›ºå®šæ¸¬è©¦åºåˆ— (seed {seed}): {', '.join(test_sequence)}")
        
        all_results = []
        
        for i, config_name in enumerate(configs_to_test, 1):
            self.logger.info(f"\nğŸ”„ [{i}/{len(configs_to_test)}] æ¸¬è©¦HPAé…ç½®: {config_name}")
            
            try:
                # æ‡‰ç”¨HPAé…ç½®
                if self._apply_hpa_config(config_name):
                    # ç­‰å¾…HPAç”Ÿæ•ˆ
                    self.logger.info(f"â³ ç­‰å¾…HPAé…ç½®ç”Ÿæ•ˆ (30ç§’)...")
                    time.sleep(30)
                    
                    # åŸ·è¡Œå›ºå®šåºåˆ—æ¸¬è©¦
                    config_results = self._run_hpa_config_test(
                        config_name, test_sequence, run_tag, experiment_type
                    )
                    all_results.extend(config_results)
                    
                    self.logger.info(f"âœ… {config_name} æ¸¬è©¦å®Œæˆï¼Œç”¢ç”Ÿ {len(config_results)} å€‹çµæœ")
                else:
                    self.logger.error(f"âŒ {config_name} HPAé…ç½®æ‡‰ç”¨å¤±æ•—")
                    
            except Exception as e:
                self.logger.error(f"âŒ {config_name} æ¸¬è©¦ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        self.logger.info(f"\nğŸ† æ‰€æœ‰HPAæ¸¬è©¦å®Œæˆ! å…±ç”¢ç”Ÿ {len(all_results)} å€‹çµæœ")
        return all_results
    
    def _generate_hpa_test_sequence(self, seed: int) -> List[str]:
        """ç”ŸæˆHPAæ¸¬è©¦çš„å›ºå®šå ´æ™¯åºåˆ—"""
        # ç”Ÿæˆå›ºå®šçš„å ´æ™¯åºåˆ—ï¼ˆåŸºæ–¼ seedï¼‰
        random.seed(seed)
        scenario_list = list(self.scenarios.keys())
        
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰ä¿å­˜çš„åºåˆ—
        sequence_file = self.repo_root / "logs" / "hpa_scenario_sequence.txt"
        
        if sequence_file.exists():
            # è®€å–å·²ä¿å­˜çš„åºåˆ—
            with open(sequence_file, 'r') as f:
                saved_sequences = {}
                for line in f:
                    if line.strip():
                        parts = line.strip().split(':')
                        if len(parts) == 2:
                            saved_seed, saved_sequence = parts
                            saved_sequences[int(saved_seed)] = saved_sequence.split(',')
            
            if seed in saved_sequences:
                return saved_sequences[seed]
                
        # ç”Ÿæˆæ–°åºåˆ—ï¼ˆç¢ºä¿å››å€‹å ´æ™¯ä¸é‡è¤‡ï¼‰
        if len(scenario_list) >= 4:
            fixed_sequence = random.sample(scenario_list, 4)
        else:
            # å¦‚æœå ´æ™¯å°‘æ–¼4å€‹ï¼Œå°±å…¨éƒ¨ä½¿ç”¨
            fixed_sequence = scenario_list
                
        return fixed_sequence
    
    def _reset_pod_replicas(self, target_namespace: str = None) -> bool:
        """é‡ç½®æŒ‡å®š namespace æ‰€æœ‰ deployment çš„ replica æ•¸é‡ç‚º 1
        
        Args:
            target_namespace: ç›®æ¨™ namespaceï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨ç•¶å‰ namespace
        """
        namespace = target_namespace or self.namespace
        self.logger.info(f"ğŸ”„ é‡ç½® {namespace} namespace æ‰€æœ‰ Pod æ•¸é‡åˆ°é è¨­å€¼ (1 replica)")
        
        try:
            # ç²å–æ‰€æœ‰ deployment
            result = subprocess.run(
                ["kubectl", "get", "deployments", "-n", namespace, "-o", "name"],
                capture_output=True, text=True, timeout=30
            )
            
            if result.returncode != 0:
                self.logger.error(f"âŒ ç²å– {namespace} deployment åˆ—è¡¨å¤±æ•—: {result.stderr}")
                return False
            
            deployments = [line.strip() for line in result.stdout.split('\n') if line.strip()]
            
            if not deployments:
                self.logger.warning(f"âš ï¸ åœ¨ namespace {namespace} ä¸­æœªæ‰¾åˆ° deployment")
                return True
            
            # é‡ç½®æ¯å€‹ deployment çš„ replicas ç‚º 1
            reset_count = 0
            for deployment in deployments:
                scale_result = subprocess.run(
                    ["kubectl", "scale", deployment, "--replicas=1", "-n", namespace],
                    capture_output=True, text=True, timeout=30
                )
                
                if scale_result.returncode == 0:
                    reset_count += 1
                    deployment_name = deployment.replace('deployment.apps/', '')
                    self.logger.info(f"âœ… é‡ç½® {namespace}/{deployment_name} ç‚º 1 replica")
                else:
                    deployment_name = deployment.replace('deployment.apps/', '')
                    self.logger.warning(f"âš ï¸ é‡ç½® {namespace}/{deployment_name} å¤±æ•—: {scale_result.stderr}")
            
            self.logger.info(f"ğŸ å®Œæˆ {namespace} Pod é‡ç½®ï¼ŒæˆåŠŸé‡ç½® {reset_count}/{len(deployments)} å€‹ deployment")
            
            # ç­‰å¾… Pod èª¿æ•´å®Œæˆ
            self.logger.info("â³ ç­‰å¾… Pod é‡ç½®ç”Ÿæ•ˆ (30ç§’)...")
            time.sleep(30)
            
            return reset_count > 0
            
        except subprocess.TimeoutExpired:
            self.logger.error(f"âŒ {namespace} Pod é‡ç½®æ“ä½œè¶…æ™‚")
            return False
        except Exception as e:
            self.logger.error(f"âŒ {namespace} Pod é‡ç½®ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def _reset_all_namespaces_pods(self) -> bool:
        """é‡ç½®æ‰€æœ‰ç›¸é—œ namespace çš„ Pod æ•¸é‡"""
        self.logger.info("ğŸ”„ é‡ç½®æ‰€æœ‰ namespace çš„ Pod æ•¸é‡")
        
        namespaces_to_reset = []
        
        # æ ¹æ“šç•¶å‰æ‡‰ç”¨å ´æ™¯ç¢ºå®šè¦é‡ç½®çš„ namespace
        if hasattr(self, 'use_case'):
            if self.use_case == 'redis':
                namespaces_to_reset.append(self.redis_namespace)
            elif self.use_case == 'online_boutique':
                namespaces_to_reset.append(self.namespace)
            else:
                # æœªçŸ¥å ´æ™¯ï¼Œé‡ç½®å…©å€‹éƒ½é‡ç½®
                namespaces_to_reset.extend([self.namespace, self.redis_namespace])
        else:
            # æ²’æœ‰ use_case è³‡è¨Šï¼Œæ ¹æ“šç•¶å‰ namespace åˆ¤æ–·
            if self.namespace == 'redis':
                namespaces_to_reset.append(self.redis_namespace)
            else:
                namespaces_to_reset.append(self.namespace)
        
        reset_success = True
        for ns in namespaces_to_reset:
            if not self._reset_pod_replicas(ns):
                reset_success = False
                
        return reset_success

    def _apply_hpa_config(self, config_name: str) -> bool:
        """æ‡‰ç”¨æŒ‡å®šHPAé…ç½®"""
        config_dir = self.hpa_root / config_name
        
        if not config_dir.exists():
            self.logger.error(f"âŒ HPAé…ç½®ç›®éŒ„ä¸å­˜åœ¨: {config_dir}")
            return False
        
        self.logger.info(f"ğŸ”§ æ‡‰ç”¨HPAé…ç½®: {config_name}")
        
        try:
            # å…ˆæ¸…é™¤æ‰€æœ‰ç¾æœ‰HPA
            result = subprocess.run(
                ["kubectl", "delete", "hpa", "--all", "-n", self.namespace],
                capture_output=True, text=True, timeout=30
            )
            
            # é‡ç½®æ‰€æœ‰ Pod æ•¸é‡ç‚º 1
            if not self._reset_all_namespaces_pods():
                self.logger.warning("âš ï¸ Pod é‡ç½®å¤±æ•—ï¼Œä½†ç¹¼çºŒæ‡‰ç”¨ HPA é…ç½®")
            
            # æ‡‰ç”¨æ–°çš„HPAé…ç½®
            for hpa_file in config_dir.glob("*.yaml"):
                result = subprocess.run(
                    ["kubectl", "apply", "-f", str(hpa_file)],
                    capture_output=True, text=True, timeout=30
                )
                
                if result.returncode != 0:
                    self.logger.error(f"âŒ æ‡‰ç”¨HPAæª”æ¡ˆå¤±æ•—: {hpa_file}")
                    self.logger.error(f"éŒ¯èª¤è¨Šæ¯: {result.stderr}")
                    return False
            
            self.logger.info(f"âœ… HPAé…ç½® {config_name} æ‡‰ç”¨æˆåŠŸ")
            return True
            
        except subprocess.TimeoutExpired:
            self.logger.error(f"âŒ HPAé…ç½®æ‡‰ç”¨è¶…æ™‚: {config_name}")
            return False
        except Exception as e:
            self.logger.error(f"âŒ HPAé…ç½®æ‡‰ç”¨ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def _run_hpa_config_test(self, config_name: str, test_sequence: List[str], 
                            run_tag: str, experiment_type: str) -> List[Path]:
        """åŸ·è¡Œå–®å€‹HPAé…ç½®çš„æ¸¬è©¦"""
        results = []
        
        # å‰µå»ºé…ç½®ç‰¹å®šçš„è¼¸å‡ºç›®éŒ„
        config_output_dir = self.repo_root / "logs" / experiment_type / run_tag / config_name
        config_output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"ğŸ“‹ åŸ·è¡Œ {config_name} æ¸¬è©¦åºåˆ—: {', '.join(test_sequence)}")
        
        for i, scenario in enumerate(test_sequence, 1):
            self.logger.info(f"\nğŸ“Š [{i}/4] åŸ·è¡Œå ´æ™¯: {scenario}")
            
            # ç‚ºæ¯å€‹å ´æ™¯å‰µå»ºç›®éŒ„
            scenario_dir = config_output_dir / f"{scenario}_{i:03d}"
            scenario_dir.mkdir(parents=True, exist_ok=True)
            
            # åŸ·è¡Œå–®å€‹å ´æ™¯æ¸¬è©¦
            remote_tag = f"{experiment_type}/{run_tag}/{config_name}" if self.m1_host else f"{run_tag}_{config_name}"
            if self.run_distributed_locust(scenario, remote_tag, scenario_dir):
                results.append(scenario_dir)
                self.logger.info(f"âœ… {scenario} æ¸¬è©¦å®Œæˆ")
            else:
                self.logger.error(f"âŒ {scenario} æ¸¬è©¦å¤±æ•—")
            
            # å ´æ™¯é–“é—œéš”æ™‚é–“
            if i < len(test_sequence):
                self.logger.info(f"â³ å ´æ™¯é–“é—œéš”æ™‚é–“ 5 åˆ†é˜...")
                time.sleep(300)  # 5åˆ†é˜é—œéš”
        
        return results
    
    def compare_experiments(self, result_paths: List[str]):
        """æ¯”è¼ƒå¯¦é©—çµæœ"""
        self.logger.info("ğŸ“Š æ¯”è¼ƒå¯¦é©—çµæœ...")
        
        # å¯¦ç¾å¯¦é©—çµæœæ¯”è¼ƒé‚è¼¯
        # é€™è£¡å¯ä»¥æ·»åŠ æ›´è©³ç´°çš„æ¯”è¼ƒåˆ†æ
        pass

def main():
    parser = argparse.ArgumentParser(description="çµ±ä¸€å¯¦é©—ç®¡ç†å™¨")
    
    # å¯¦é©—é¸æ“‡
    parser.add_argument('--experiment', choices=['gym_hpa', 'k8s_hpa', 'gnnrl'], 
                       help='åŸ·è¡ŒæŒ‡å®šå¯¦é©—')
    parser.add_argument('--batch-all', action='store_true',
                       help='æ‰¹æ¬¡åŸ·è¡Œæ‰€æœ‰å¯¦é©—')
    parser.add_argument('--experiments', nargs='+', 
                       choices=['gym_hpa', 'k8s_hpa', 'gnnrl'],
                       help='æ‰¹æ¬¡åŸ·è¡ŒæŒ‡å®šå¯¦é©—')
    
    # å¯¦é©—åƒæ•¸
    parser.add_argument('--steps', type=int, 
                       default=int(os.getenv('DEFAULT_STEPS', '5000')),
                       help='è¨“ç·´æ­¥æ•¸')
    parser.add_argument('--goal', choices=['latency', 'cost'], 
                       default=os.getenv('DEFAULT_GOAL', 'latency'),
                       help='å„ªåŒ–ç›®æ¨™')
    parser.add_argument('--use-case', choices=['redis', 'online_boutique'], 
                       default=os.getenv('DEFAULT_USE_CASE', 'online_boutique'), 
                       help='æ‡‰ç”¨å ´æ™¯')
    parser.add_argument('--alg', choices=['ppo', 'recurrent_ppo', 'a2c'], 
                       default='ppo',
                       help='å¼·åŒ–å­¸ç¿’ç®—æ³•')
    parser.add_argument('--model', choices=['gat', 'gcn', 'tgn'], 
                       default='gat',
                       help='GNN æ¨¡å‹é¡å‹ (åƒ…é©ç”¨æ–¼ gnnrl å¯¦é©—)')
    parser.add_argument('--seed', type=int, default=42,
                       help='éš¨æ©Ÿç¨®å­ (ç”¨æ–¼æ§åˆ¶ Locust æƒ…å¢ƒåŸ·è¡Œé †åº)')
    parser.add_argument('--env-step-interval', type=float, default=15.0,
                       help='ç’°å¢ƒæ­¥é©Ÿé–“éš”ç§’æ•¸ (æ¨¡å‹æ¥æ”¶æ–°æ•¸æ“šçš„é »ç‡)')
    parser.add_argument('--run-tag', help='é‹è¡Œæ¨™ç±¤')
    parser.add_argument('--hpa-type', choices=['all', 'cpu', 'mem', 'hybrid'], default='all',
                       help='K8s-HPA æ¸¬è©¦é…ç½®é¡å‹ (all=æ‰€æœ‰, cpu=åƒ…CPU, mem=åƒ…è¨˜æ†¶é«”, hybrid=æ··åˆ)')
    parser.add_argument('--k8s', action='store_true',
                       help='å•Ÿç”¨çœŸå¯¦ K8s é›†ç¾¤æ¨¡å¼ (é è¨­: æ¨¡æ“¬æ¨¡å¼)')
    parser.add_argument('--simulation', action='store_true',
                       help='å¼·åˆ¶ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼ (è¦†è“‹ --k8s)')
    
    # æ¸¬è©¦æ¨¡å¼åƒæ•¸
    parser.add_argument('--testing', action='store_true',
                       help='ä½¿ç”¨å·²è¨“ç·´æ¨¡å‹é€²è¡Œæ¸¬è©¦ (éœ€æ­é… --load-path)')
    parser.add_argument('--load-path', type=str,
                       help='å·²è¨“ç·´æ¨¡å‹çš„è·¯å¾‘ (ç”¨æ–¼æ¸¬è©¦æ¨¡å¼)')
    parser.add_argument('--test-scenarios', nargs='+',
                       choices=['offpeak', 'peak', 'rushsale', 'fluctuating'],
                       help='é¸å®šè¦æ¸¬è©¦çš„å ´æ™¯ï¼Œä¾‹å¦‚ --test-scenarios peak rushsale')
    
    # å…¶ä»–åŠŸèƒ½
    parser.add_argument('--validate-only', action='store_true',
                       help='åƒ…é©—è­‰ç’°å¢ƒ')
    parser.add_argument('--loadtest-only', action='store_true',
                       help='åƒ…åŸ·è¡Œè² è¼‰æ¸¬è©¦')
    parser.add_argument('--enable-loadtest', action='store_true',
                       help='å¼·åˆ¶å•Ÿç”¨è² è¼‰æ¸¬è©¦ï¼ˆé©ç”¨æ–¼æ¸¬è©¦æ¨¡å¼ï¼‰')
    parser.add_argument('--stable-loadtest', action='store_true',
                       help='ä½¿ç”¨ç©©å®šloadtestæ¨¡å¼ï¼ˆå¤±æ•—æ™‚ç¶­æŒRPSç¹¼çºŒæ¸¬è©¦ï¼‰')
    parser.add_argument('--target-rps', type=int,
                       help='è¨­å®šç›®æ¨™RPSæ•¸å€¼ï¼ˆä½¿ç”¨ç©©å®šloadtestæ¨¡å¼æ™‚ï¼‰')
    parser.add_argument('--loadtest-timeout', type=int, default=30,
                       help='Loadtestè«‹æ±‚è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰')
    parser.add_argument('--compare', nargs='+',
                       help='æ¯”è¼ƒå¯¦é©—çµæœè·¯å¾‘')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    manager = UnifiedExperimentManager(
        stable_loadtest=args.stable_loadtest,
        target_rps=args.target_rps,
        loadtest_timeout=args.loadtest_timeout
    )
    
    # ç’°å¢ƒé©—è­‰
    if not manager.validate_environment(args.use_case):
        if not args.validate_only:
            sys.exit(1)
        else:
            return
    
    if args.validate_only:
        return
    
    # åŸ·è¡Œå¯¦é©—
    if args.experiment:
        success = manager.run_experiment(
            args.experiment,
            steps=args.steps,
            goal=args.goal,
            use_case=args.use_case,
            alg=args.alg,
            model=args.model,
            seed=args.seed,
            env_step_interval=args.env_step_interval,
            run_tag=args.run_tag,
            k8s=args.k8s and not args.simulation,
            testing=args.testing,
            load_path=args.load_path,
            hpa_type=args.hpa_type,
            test_scenarios=args.test_scenarios
        )
        sys.exit(0 if success else 1)
    
    elif args.batch_all:
        experiments = ['gym_hpa', 'k8s_hpa', 'gnnrl']
        results = manager.run_batch_experiments(
            experiments,
            steps=args.steps,
            goal=args.goal,
            use_case=args.use_case,
            alg=args.alg,
            model=args.model,
            seed=args.seed,
            env_step_interval=args.env_step_interval,
            k8s=args.k8s and not args.simulation,
            hpa_type=args.hpa_type
        )
        sys.exit(0 if all(results.values()) else 1)
    
    elif args.experiments:
        results = manager.run_batch_experiments(
            args.experiments,
            steps=args.steps,
            goal=args.goal,
            use_case=args.use_case,
            alg=args.alg,
            model=args.model,
            seed=args.seed,
            env_step_interval=args.env_step_interval,
            k8s=args.k8s and not args.simulation,
            hpa_type=args.hpa_type
        )
        sys.exit(0 if all(results.values()) else 1)
    
    elif args.compare:
        manager.compare_experiments(args.compare)
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main()