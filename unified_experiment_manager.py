#!/usr/bin/env python3
"""
çµ±ä¸€å¯¦é©—ç®¡ç†å™¨ (Unified Experiment Manager)
================================================

æ•´åˆ gym_hpa, k8s_hpa, gnnrl ä¸‰å€‹å¯¦é©—ï¼Œæ”¯æ´åˆ†æ•£å¼ Locust æ¸¬è©¦ç’°å¢ƒã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- çµ±ä¸€çš„å‘½ä»¤è¡Œä»‹é¢
- è‡ªå‹•å¯¦é©—ç’°å¢ƒé©—è­‰
- åˆ†æ•£å¼è² è¼‰æ¸¬è©¦å”èª¿
- å¯¦é©—çµæœèšåˆèˆ‡æ¯”è¼ƒ
- æ”¯æ´æ‰¹æ¬¡å¯¦é©—åŸ·è¡Œ

ä½¿ç”¨æ–¹å¼ï¼š
    # åŸ·è¡Œå–®ä¸€å¯¦é©—
    python unified_experiment_manager.py --experiment gnnrl --steps 5000
    
    # æ‰¹æ¬¡åŸ·è¡Œæ‰€æœ‰å¯¦é©—
    python unified_experiment_manager.py --batch-all --steps 3000
    
    # åƒ…åŸ·è¡Œè² è¼‰æ¸¬è©¦ (ä¸è¨“ç·´)
    python unified_experiment_manager.py --loadtest-only
    
    # æ¯”è¼ƒå¯¦é©—çµæœ
    python unified_experiment_manager.py --compare logs/gym_hpa/run1 logs/gnnrl/run2
"""

import os
import sys
import yaml
import argparse
import logging
import subprocess
import time
import random
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import pandas as pd
import requests

# è¼‰å…¥å¯¦é©—é…ç½®
CONFIG_FILE = Path(__file__).parent / "experiment_config.yaml"

class UnifiedExperimentManager:
    def __init__(self, config_path: Path = CONFIG_FILE):
        """åˆå§‹åŒ–çµ±ä¸€å¯¦é©—ç®¡ç†å™¨"""
        self.repo_root = Path(__file__).parent
        self.config = self._load_config(config_path)
        self.logger = self._setup_logging()
        self._load_environment()
        self._setup_locust_scenarios()
        self._setup_hpa_configurations()
        
        # åˆå§‹åŒ– timestamp å±¬æ€§
        from datetime import datetime
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
    def _setup_locust_scenarios(self):
        """è¨­å®š Locust æ¸¬è©¦å ´æ™¯"""
        self.scenarios = {
            "offpeak": "locust_offpeak.py",
            "rushsale": "locust_rushsale.py", 
            "peak": "locust_peak.py",
            "fluctuating": "locust_fluctuating.py"
        }
        
        # å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥è¨­å®š
        self.target_host = os.getenv("TARGET_HOST", "http://k8s.orb.local:8080")
        self.locust_run_time = os.getenv("LOCUST_RUN_TIME", "15m")
        self.m1_host = os.getenv("M1_HOST")
        self.kiali_url = os.getenv("KIALI_URL", "http://localhost:20001/kiali")
        self.namespace = os.getenv("NAMESPACE_ONLINEBOUTIQUE", "onlineboutique")
        self.redis_namespace = os.getenv("NAMESPACE_REDIS", "redis")
        
        # è¨ˆç®—é‹è¡Œæ™‚é–“ï¼ˆç§’ï¼‰
        self._parse_run_time()
        
    def _parse_run_time(self):
        """è§£æé‹è¡Œæ™‚é–“å­—ä¸²"""
        import re
        mult = {"s": 1, "m": 60, "h": 3600}
        match = re.match(r"(\d+)([smh])", self.locust_run_time)
        if match:
            self.run_time_sec = int(match.group(1)) * mult[match.group(2)]
            self.half_run_sec = self.run_time_sec // 2
        else:
            self.run_time_sec = 900  # é è¨­ 15 åˆ†é˜
            self.half_run_sec = 450
    
    def _setup_hpa_configurations(self):
        """è¨­å®š HPA é…ç½®é¸é …"""
        self.hpa_configs = {
            'cpu': ['cpu-40'],  # åªæ¸¬è©¦ CPU-40% é…ç½®
            'mem': ['mem-40', 'mem-80'],
            'hybrid': [
                'cpu-20-mem-40', 'cpu-20-mem-80',
                'cpu-40-mem-40', 'cpu-40-mem-80', 
                'cpu-60-mem-40', 'cpu-60-mem-80',
                'cpu-80-mem-40', 'cpu-80-mem-80'
            ]
        }
        
        # Redis HPA é…ç½® (ç°¡åŒ–ç‚ºåªæ¸¬è©¦ CPU)
        self.redis_hpa_configs = {
            'cpu': ['cpu-20', 'cpu-40', 'cpu-60', 'cpu-80']
        }
        
        # HPA é…ç½®æ ¹ç›®éŒ„
        self.hpa_root = self.repo_root / "macK8S" / "HPA" / "onlineboutique"
        self.redis_hpa_root = self.repo_root / "macK8S" / "HPA" / "redis"
        
    def _load_config(self, config_path: Path) -> dict:
        """è¼‰å…¥å¯¦é©—é…ç½®æª”æ¡ˆ"""
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æª”æ¡ˆä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _setup_logging(self) -> logging.Logger:
        """è¨­å®šæ—¥èªŒç³»çµ±"""
        # ç¢ºä¿ runtime ç›®éŒ„å­˜åœ¨
        runtime_dir = Path("logs/runtime")
        runtime_dir.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨æ™‚é–“æˆ³å‰µå»ºå”¯ä¸€çš„æ—¥èªŒæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = runtime_dir / f"unified_experiment_{timestamp}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler(log_file, encoding='utf-8')
            ]
        )
        return logging.getLogger('UnifiedExperimentManager')
    
    def _load_environment(self):
        """è¼‰å…¥ç’°å¢ƒè®Šæ•¸"""
        env_file = self.repo_root / '.env'
        if env_file.exists():
            try:
                from dotenv import load_dotenv
                load_dotenv(env_file)
                self.logger.info(f"âœ… å·²è¼‰å…¥ç’°å¢ƒé…ç½®: {env_file}")
            except ImportError:
                self.logger.warning("python-dotenv æœªå®‰è£ï¼Œæ‰‹å‹•è§£æ .env æª”æ¡ˆ")
                self._manual_load_env(env_file)
        else:
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ° .env æª”æ¡ˆ")
    
    def _manual_load_env(self, env_file: Path):
        """æ‰‹å‹•è§£æ .env æª”æ¡ˆ"""
        with open(env_file) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value
    
    def validate_environment(self, use_case: str = "online_boutique") -> bool:
        """é©—è­‰å¯¦é©—ç’°å¢ƒ"""
        self.logger.info("ğŸ” é©—è­‰å¯¦é©—ç’°å¢ƒ...")
        
        # æª¢æŸ¥ Kubernetes ç’°å¢ƒ
        if not self._check_k8s_environment(use_case):
            return False
        
        # æª¢æŸ¥åˆ†æ•£å¼æ¸¬è©¦ç’°å¢ƒ
        if not self._check_distributed_testing():
            self.logger.warning("âš ï¸ åˆ†æ•£å¼æ¸¬è©¦ç’°å¢ƒæœªé…ç½®ï¼Œå°‡ä½¿ç”¨æœ¬åœ°æ¸¬è©¦")
        
        # æª¢æŸ¥å¯¦é©—è…³æœ¬
        if not self._check_experiment_scripts():
            return False
        
        self.logger.info("âœ… ç’°å¢ƒé©—è­‰é€šé")
        return True
    
    def _check_k8s_environment(self, use_case: str = "online_boutique") -> bool:
        """æª¢æŸ¥ Kubernetes ç’°å¢ƒ"""
        try:
            # æª¢æŸ¥ kubectl å‘½ä»¤
            subprocess.run(['kubectl', 'version', '--client'], 
                         capture_output=True, check=True)
            
            # æ ¹æ“š use_case é¸æ“‡è¦æª¢æŸ¥çš„ namespace å’ŒæœŸæœ›çš„ Pod æ•¸é‡
            if use_case == "redis":
                namespace = self.redis_namespace
                min_pods = 2  # redis-master, redis-slave (redis-exporter æ˜¯å¯é¸çš„)
                env_name = "Redis"
            else:
                namespace = self.namespace
                min_pods = 10  # OnlineBoutique çš„ 10 å€‹å¾®æœå‹™
                env_name = "OnlineBoutique"
            
            # æª¢æŸ¥æŒ‡å®š namespace çš„ Pod
            result = subprocess.run(
                ['kubectl', 'get', 'pods', '-n', namespace, '--no-headers'],
                capture_output=True, text=True, check=True
            )
            
            if not result.stdout.strip():
                self.logger.error(f"âŒ {env_name} namespace ({namespace}) ä¸­æ²’æœ‰ Pod")
                return False
            
            running_pods = [p for p in result.stdout.strip().split('\n') if 'Running' in p]
            
            # å°æ–¼ Redisï¼Œåªæª¢æŸ¥æ ¸å¿ƒæœå‹™
            if use_case == "redis":
                core_pods = [p for p in running_pods if 'redis-master' in p or 'redis-slave' in p]
                if len(core_pods) < min_pods:
                    self.logger.error(f"âŒ {env_name} æ ¸å¿ƒæœå‹™ä¸å®Œæ•´ï¼Œåƒ… {len(core_pods)} å€‹æ ¸å¿ƒ Pod é‹è¡Œ")
                    return False
            else:
                if len(running_pods) < min_pods:
                    self.logger.error(f"âŒ {env_name} ç’°å¢ƒä¸å®Œæ•´ï¼Œåƒ… {len(running_pods)} å€‹ Pod é‹è¡Œ")
                    return False
            
            self.logger.info(f"âœ… {env_name} ç’°å¢ƒæ­£å¸¸ï¼Œ{len(running_pods)} å€‹æœå‹™é‹è¡Œä¸­")
            return True
            
        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            self.logger.error(f"âŒ Kubernetes ç’°å¢ƒæª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _check_distributed_testing(self) -> bool:
        """æª¢æŸ¥åˆ†æ•£å¼æ¸¬è©¦ç’°å¢ƒ"""
        m1_host = os.getenv('M1_HOST')
        if not m1_host:
            return False
        
        try:
            import requests
            response = requests.get(f"{m1_host.rstrip('/')}/", timeout=5)
            self.logger.info(f"âœ… åˆ†æ•£å¼æ¸¬è©¦ä»£ç†é€£æ¥æ­£å¸¸: {m1_host}")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ åˆ†æ•£å¼æ¸¬è©¦ä»£ç†é€£æ¥å¤±æ•—: {e}")
            return False
    
    def _check_experiment_scripts(self) -> bool:
        """æª¢æŸ¥å¯¦é©—è…³æœ¬å­˜åœ¨æ€§"""
        for exp_name, exp_config in self.config['experiments'].items():
            script_path = self.repo_root / exp_config['script_path']
            if not script_path.exists():
                self.logger.error(f"âŒ å¯¦é©—è…³æœ¬ä¸å­˜åœ¨: {script_path}")
                return False
        
        self.logger.info("âœ… å¯¦é©—è…³æœ¬æª¢æŸ¥é€šé")
        return True
    
    def run_experiment(self, experiment: str, **kwargs) -> bool:
        """åŸ·è¡ŒæŒ‡å®šå¯¦é©—"""
        if experiment not in self.config['experiments']:
            self.logger.error(f"âŒ æœªçŸ¥å¯¦é©—: {experiment}")
            return False
        
        exp_config = self.config['experiments'][experiment]
        self.logger.info(f"ğŸš€ é–‹å§‹åŸ·è¡Œå¯¦é©—: {exp_config['name']}")
        
        # ç”Ÿæˆé‹è¡Œæ¨™ç±¤ - ä½¿ç”¨æ–°çš„çµ±ä¸€æ ¼å¼
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        algorithm = kwargs.get('alg', 'ppo')
        model = kwargs.get('model', 'gat') if experiment == 'gnnrl' else 'baseline'
        goal = kwargs.get('goal', 'latency')
        steps = kwargs.get('steps', 5000)
        
        unified_tag = f"{timestamp}_{experiment}_{algorithm}_{model}_{goal}_{steps}"
        run_tag = kwargs.pop('run_tag', unified_tag)
        
        # æº–å‚™å‘½ä»¤
        script_path = self.repo_root / exp_config['script_path']
        
        if experiment == 'gym_hpa':
            return self._run_gym_hpa_experiment(script_path, run_tag, **kwargs)
        elif experiment == 'k8s_hpa':
            return self._run_k8s_hpa_experiment(script_path, run_tag, **kwargs)
        elif experiment == 'gnnrl':
            return self._run_gnnrl_experiment(script_path, run_tag, **kwargs)
        else:
            self.logger.error(f"âŒ å¯¦é©—åŸ·è¡Œå™¨æœªå¯¦ç¾: {experiment}")
            return False
    
    def _run_gym_hpa_experiment(self, script_path: Path, run_tag: str, **kwargs) -> bool:
        """åŸ·è¡Œ gym_hpa å¯¦é©—"""
        use_case = kwargs.get('use_case', 'online_boutique')
        self.logger.info(f"ğŸ¯ åŸ·è¡Œ Gym-HPA å¯¦é©— (æ‡‰ç”¨å ´æ™¯: {use_case})")
        
        # ç›´æ¥èª¿ç”¨ gym-hpa è…³æœ¬ï¼Œä¸ä¾è³´ rl_batch_loadtest.py
        gym_hpa_script = self.repo_root / "gym-hpa" / "policies" / "run" / "run.py"
        
        cmd = [
            sys.executable, str(gym_hpa_script),
            "--alg", str(kwargs.get('alg', 'ppo')),
            "--use_case", str(use_case),
            "--goal", str(kwargs.get('goal', 'latency')),
            "--steps", str(kwargs.get('steps', 1000)),
            "--total_steps", str(kwargs.get('steps', 5000))
        ]
        
        # æ¸¬è©¦æ¨¡å¼æˆ–è¨“ç·´æ¨¡å¼
        if kwargs.get('testing', False):
            cmd.append("--testing")
            cmd.extend(["--test_path", kwargs.get('load_path')])
            self.logger.info("ğŸ§ª ä½¿ç”¨æ¸¬è©¦æ¨¡å¼")
            training_proc = None
        else:
            cmd.append("--training")
            self.logger.info("ğŸ¯ ä½¿ç”¨è¨“ç·´æ¨¡å¼")
            
        if kwargs.get('k8s', False):
            cmd.append("--k8s")
            self.logger.info("âœ… å•Ÿç”¨ K8s é›†ç¾¤æ¨¡å¼")
        else:
            self.logger.info("ğŸ”„ ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        
        # é–‹å§‹è¨“ç·´/æ¸¬è©¦é€²ç¨‹
        if not kwargs.get('testing', False):
            # è¨“ç·´æ¨¡å¼ï¼šä¸¦è¡ŒåŸ·è¡Œ
            training_proc = subprocess.Popen(cmd, cwd=self.repo_root / "gym-hpa")
            self.logger.info(f"ğŸ”„ Gym-HPA è¨“ç·´å·²é–‹å§‹ï¼Œç«‹å³é–‹å§‹ä¸¦è¡Œè² è¼‰æ¸¬è©¦...")
        else:
            # æ¸¬è©¦æ¨¡å¼ï¼šä¹Ÿéœ€è¦ä¸¦è¡ŒåŸ·è¡Œï¼Œè®“æ¸¬è©¦éç¨‹ä¸­æœ‰æµé‡
            training_proc = subprocess.Popen(cmd, cwd=self.repo_root / "gym-hpa")
            self.logger.info(f"ğŸ§ª Gym-HPA æ¸¬è©¦å·²é–‹å§‹ï¼Œç«‹å³é–‹å§‹ä¸¦è¡Œè² è¼‰æ¸¬è©¦...")
        
        # é‹è¡ŒæŒçºŒè² è¼‰æ¸¬è©¦
        scenario_dirs = self.run_continuous_loadtest(
            "gym-hpa", run_tag, kwargs.get('seed', 42), training_proc
        )
        
        return len(scenario_dirs) > 0
    
    def _run_k8s_hpa_experiment(self, script_path: Path, run_tag: str, **kwargs) -> bool:
        """åŸ·è¡Œ k8s_hpa åŸºæº–æ¸¬è©¦"""
        self.logger.info("ğŸ“Š åŸ·è¡Œ K8s HPA åŸºæº–æ¸¬è©¦")
        
        # HPA åŸºæº–æ¸¬è©¦åªåŸ·è¡Œè² è¼‰æ¸¬è©¦ï¼Œä¸éœ€è¦è¨“ç·´é€²ç¨‹
        self.logger.info("âœ… ä½¿ç”¨çœŸå¯¦ K8s é›†ç¾¤é€²è¡Œ HPA åŸºæº–æ¸¬è©¦")
        
        # ç²å–HPAé…ç½®é¡å‹é¸æ“‡
        hpa_type = kwargs.get('hpa_type', 'all')  # all, cpu, mem, hybrid
        seed = kwargs.get('seed', 42)
        
        # åŸ·è¡Œå¤šé…ç½®HPAæ¸¬è©¦
        total_results = self.run_multi_hpa_experiment(
            "k8s-hpa", run_tag, seed, hpa_type
        )
        
        return len(total_results) > 0
    
    def _run_gnnrl_experiment(self, script_path: Path, run_tag: str, **kwargs) -> bool:
        """åŸ·è¡Œ GNNRL å¯¦é©—"""
        use_case = kwargs.get('use_case', 'online_boutique')
        self.logger.info(f"ğŸ§  åŸ·è¡Œ GNNRL å¯¦é©— (æ‡‰ç”¨å ´æ™¯: {use_case})")
        
        # GNNRL æ”¯æŒå…©ç¨®ç’°å¢ƒ
        if use_case == 'redis':
            self.logger.info("ğŸ“Š GNNRL Redis ç’°å¢ƒå¯¦é©—")
        else:
            self.logger.info("ğŸ“Š GNNRL OnlineBoutique ç’°å¢ƒå¯¦é©—")
        
        # ç›´æ¥èª¿ç”¨ GNNRL è…³æœ¬
        gnnrl_script = self.repo_root / "gnnrl" / "training" / "run_gnnrl_experiment.py"
        
        cmd = [
            sys.executable, str(gnnrl_script),
            "--steps", str(kwargs.get('steps', 5000)),
            "--goal", str(kwargs.get('goal', 'latency')),
            "--alg", str(kwargs.get('alg', 'ppo')),
            "--model", str(kwargs.get('model', 'gat')),
            "--env-step-interval", str(kwargs.get('env_step_interval', 15.0)),
            "--use-case", str(use_case)
        ]
        
        if kwargs.get('k8s', False):
            cmd.append("--k8s")
            self.logger.info("âœ… å•Ÿç”¨ K8s é›†ç¾¤æ¨¡å¼")
        else:
            self.logger.info("ğŸ”„ ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
        
        # GNNRL æ¸¬è©¦æ¨¡å¼è™•ç†
        if kwargs.get('testing', False):
            self.logger.info("ğŸ§ª GNNRL æ¸¬è©¦æ¨¡å¼ï¼šè¼‰å…¥å·²è¨“ç·´æ¨¡å‹é€²è¡Œè©•ä¼°")
            load_path = kwargs.get('load_path')
            if not load_path or not Path(load_path).exists():
                self.logger.error(f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {load_path}")
                return False
            
            cmd.extend([
                "--testing",
                "--load-path", str(load_path)
            ])
            
            self.logger.info(f"ğŸ“‚ è¼‰å…¥æ¨¡å‹æª”æ¡ˆ: {load_path}")
            # æ¸¬è©¦æ¨¡å¼ï¼šåŸ·è¡Œæ¸¬è©¦è…³æœ¬å¾Œé€²è¡Œè² è¼‰æ¸¬è©¦
            training_proc = subprocess.Popen(cmd, cwd=self.repo_root / "gnnrl")
            self.logger.info(f"ğŸ”„ GNNRL æ¸¬è©¦é€²ç¨‹å·²é–‹å§‹...")
            
            # ç­‰å¾…æ¸¬è©¦å®Œæˆå¾Œå†åŸ·è¡Œè² è¼‰æ¸¬è©¦
            training_proc.wait()
            training_proc = None  # è¨­ç‚º None ä»¥åŸ·è¡Œå–®æ¬¡è² è¼‰æ¸¬è©¦
        else:
            # è¨“ç·´æ¨¡å¼ï¼šå•Ÿå‹• GNNRL è¨“ç·´é€²ç¨‹
            self.logger.info("ğŸ¯ ä½¿ç”¨è¨“ç·´æ¨¡å¼")
            training_proc = subprocess.Popen(cmd, cwd=self.repo_root / "gnnrl")
            self.logger.info(f"ğŸ”„ GNNRL è¨“ç·´å·²é–‹å§‹ï¼Œç¹¼çºŒè² è¼‰æ¸¬è©¦...")
        
        # é‹è¡ŒæŒçºŒè² è¼‰æ¸¬è©¦
        scenario_dirs = self.run_continuous_loadtest(
            "gnnrl", run_tag, kwargs.get('seed', 42), training_proc
        )
        
        return len(scenario_dirs) > 0
    
    def run_batch_experiments(self, experiments: List[str], **kwargs) -> Dict[str, bool]:
        """æ‰¹æ¬¡åŸ·è¡Œå¤šå€‹å¯¦é©—"""
        self.logger.info(f"ğŸ”„ æ‰¹æ¬¡åŸ·è¡Œå¯¦é©—: {', '.join(experiments)}")
        
        results = {}
        for experiment in experiments:
            self.logger.info(f"{'='*60}")
            success = self.run_experiment(experiment, **kwargs)
            results[experiment] = success
            
            if success:
                self.logger.info(f"âœ… {experiment} å¯¦é©—æˆåŠŸ")
            else:
                self.logger.error(f"âŒ {experiment} å¯¦é©—å¤±æ•—")
            
            # å¯¦é©—é–“å†·å»
            if experiment != experiments[-1]:
                cooldown = 120  # 2åˆ†é˜
                self.logger.info(f"â¸ï¸ å¯¦é©—é–“å†·å» {cooldown} ç§’...")
                time.sleep(cooldown)
        
        # ç”Ÿæˆæ‰¹æ¬¡æ‘˜è¦
        self._generate_batch_summary(results)
        return results
    
    def _generate_batch_summary(self, results: Dict[str, bool]):
        """ç”Ÿæˆæ‰¹æ¬¡å¯¦é©—æ‘˜è¦"""
        summary_file = self.repo_root / "logs" / "batch_summary.txt"
        summary_file.parent.mkdir(exist_ok=True)
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("æ‰¹æ¬¡å¯¦é©—åŸ·è¡Œæ‘˜è¦\n")
            f.write("="*50 + "\n")
            f.write(f"åŸ·è¡Œæ™‚é–“: {datetime.now()}\n\n")
            
            for experiment, success in results.items():
                status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
                f.write(f"{experiment}: {status}\n")
            
            success_count = sum(results.values())
            total_count = len(results)
            f.write(f"\nç¸½è¨ˆ: {success_count}/{total_count} å€‹å¯¦é©—æˆåŠŸ\n")
        
        self.logger.info(f"ğŸ“„ æ‰¹æ¬¡æ‘˜è¦å·²ä¿å­˜: {summary_file}")
    
    def record_kiali_graph(self, stage: str) -> None:
        """è¨˜éŒ„ Kiali æœå‹™åœ–"""
        self.logger.info(f"ğŸ” è¨˜éŒ„ Kiali åœ–è¡¨ ({stage})")
        url = f"{self.kiali_url}/api/namespaces/graph?namespaces={self.namespace}&duration=600s&graphType=workload"
        try:
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()
            # ç¢ºä¿ kiali ç›®éŒ„å­˜åœ¨
            kiali_dir = Path("logs/kiali")
            kiali_dir.mkdir(parents=True, exist_ok=True)
            kiali_file = kiali_dir / f"kiali_{stage}_{self.timestamp}.json"
            kiali_file.write_text(resp.text, encoding="utf-8")
            self.logger.info(f"âœ… Kiali åœ–è¡¨å·²ä¿å­˜: {kiali_file}")
        except Exception as err:
            self.logger.warning(f"âš ï¸ Kiali åœ–è¡¨è¨˜éŒ„å¤±æ•—: {err}")

    def run_distributed_locust(self, scenario: str, tag: str, out_dir: Path) -> bool:
        """é‹è¡Œåˆ†æ•£å¼ Locust æ¸¬è©¦"""
        out_dir.mkdir(parents=True, exist_ok=True)
        
        if self.m1_host:
            return self._run_remote_locust(scenario, tag, out_dir)
        else:
            return self._run_local_locust(scenario, out_dir)
    
    def _run_remote_locust(self, scenario: str, tag: str, out_dir: Path) -> bool:
        """é‹è¡Œé ç«¯ Locust æ¸¬è©¦"""
        host = self.m1_host.rstrip("/")
        self.logger.info(f"ğŸ”— åˆ†æ•£å¼æ¸¬è©¦: M1_HOST={host}")
        self.logger.info(f"ğŸš€ è§¸ç™¼é ç«¯ Locust {scenario}")
        
        payload = {
            "tag": tag,
            "scenario": scenario,
            "target_host": self.target_host,
            "run_time": self.locust_run_time,
        }
        
        try:
            # é–‹å§‹é ç«¯æ¸¬è©¦
            r = requests.post(f"{host}/start", json=payload, timeout=10)
            r.raise_for_status()
            job_id = r.json()["job_id"]
            self.logger.info(f"ğŸ“‹ é ç«¯ä»»å‹™ ID: {job_id}")
            
            # è¨˜éŒ„é–‹å§‹ç‹€æ…‹
            self.record_kiali_graph("start")
            
            # ä¸­é€”æª¢æŸ¥é»
            time.sleep(self.half_run_sec)
            self.record_kiali_graph("mid")
            
            # ç­‰å¾…å®Œæˆ
            max_checks = int(os.getenv("MAX_STATUS_CHECKS", "720"))
            for check_count in range(max_checks):
                time.sleep(5)
                
                st = requests.get(f"{host}/status/{job_id}", timeout=10)
                st.raise_for_status()
                data = st.json()
                
                if data.get("finished"):
                    self.logger.info(f"âœ… é ç«¯æ¸¬è©¦ {scenario} å®Œæˆ")
                    break
                    
                if check_count % 10 == 0:
                    self.logger.debug(f"â³ é ç«¯æ¸¬è©¦ç‹€æ…‹ [{check_count+1}/{max_checks}]: running")
            else:
                self.logger.warning("â° é ç«¯æ¸¬è©¦è¶…æ™‚")
                return False
                
            self.record_kiali_graph("end")
            
            # ä¸‹è¼‰çµæœæª”æ¡ˆ
            downloaded_files = []
            for fname in [f"{scenario}_stats.csv", f"{scenario}_stats_history.csv", f"{scenario}.html"]:
                resp = requests.get(f"{host}/download/{tag}/{fname}", timeout=10)
                if resp.status_code == 200:
                    (out_dir / fname).write_bytes(resp.content)
                    downloaded_files.append(fname)
                else:
                    self.logger.warning(f"âŒ ä¸‹è¼‰å¤±æ•—: {fname}")
            
            self.logger.info(f"ğŸ“Š é ç«¯æ¸¬è©¦çµæœ: å·²ä¸‹è¼‰ {len(downloaded_files)}/3 æª”æ¡ˆ")
            return len(downloaded_files) > 0
            
        except requests.RequestException as exc:
            self.logger.error(f"âŒ é ç«¯æ¸¬è©¦å¤±æ•—: {exc}")
            self.logger.info("ğŸ”„ åˆ‡æ›åˆ°æœ¬åœ°æ¸¬è©¦")
            return self._run_local_locust(scenario, out_dir)
    
    def _run_local_locust(self, scenario: str, out_dir: Path) -> bool:
        """é‹è¡Œæœ¬åœ° Locust æ¸¬è©¦ - æ”¯æŒå…©ç¨®ç’°å¢ƒ"""
        # æª¢æŸ¥ç’°å¢ƒé¡å‹
        environment = 'onlineboutique' if self.namespace == 'onlineboutique' else 'redis'
        
        # å„ªå…ˆå˜—è©¦ç’°å¢ƒå°ˆç”¨è…³æœ¬
        script_path = self.repo_root / "loadtest" / environment / f"locust_{scenario}.py"
        
        # å¦‚æœç’°å¢ƒå°ˆç”¨è…³æœ¬ä¸å­˜åœ¨ï¼Œå˜—è©¦OnlineBoutiqueé€šç”¨è…³æœ¬
        if not script_path.exists():
            script_path = self.repo_root / "loadtest" / "onlineboutique" / f"locust_{scenario}.py"
            
        if not script_path.exists():
            self.logger.error(f"âŒ æ¸¬è©¦è…³æœ¬ä¸å­˜åœ¨: {script_path}")
            return False
            
        self.logger.info(f"ğŸ  é‹è¡Œæœ¬åœ° Locust {scenario} (ç’°å¢ƒ: {environment})")
        cmd = [
            "locust", "-f", str(script_path), "--headless", "--run-time", self.locust_run_time,
            "--host", self.target_host,
            "--csv", str(out_dir / scenario), "--csv-full-history",
            "--html", str(out_dir / f"{scenario}.html"),
        ]
        
        proc = subprocess.Popen(cmd)
        
        self.record_kiali_graph("start")
        time.sleep(self.half_run_sec)
        self.record_kiali_graph("mid")
        
        # ç­‰å¾…æ¸¬è©¦å®Œæˆ
        proc.wait()
        
        self.record_kiali_graph("end")
        
        if proc.returncode:
            self.logger.warning(f"âš ï¸ æœ¬åœ°æ¸¬è©¦ {scenario} çµæŸç¢¼: {proc.returncode}")
            return False
        else:
            self.logger.info(f"âœ… æœ¬åœ°æ¸¬è©¦ {scenario} å®Œæˆ")
            return True

    def run_continuous_loadtest(self, experiment_type: str, run_tag: str, seed: int, training_proc: subprocess.Popen = None) -> List[Path]:
        """æŒçºŒé‹è¡Œéš¨æ©Ÿ Locust æ¸¬è©¦ç›´åˆ°è¨“ç·´å®Œæˆ"""
        random.seed(seed)
        scenario_list = list(self.scenarios.keys())
        scenario_dirs = []
        scenario_count = 0
        
        # å‰µå»ºåŸºç¤è¼¸å‡ºç›®éŒ„
        base_output_dir = self.repo_root / "logs" / experiment_type / run_tag
        base_output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"ğŸ² ä½¿ç”¨éš¨æ©Ÿç¨®å­ {seed}ï¼Œå¯ç”¨æƒ…å¢ƒ: {', '.join(scenario_list)}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è¨“ç·´é€²ç¨‹éœ€è¦ç­‰å¾…
        has_training_proc = training_proc is not None
        
        # æŒçºŒéš¨æ©ŸåŸ·è¡Œå ´æ™¯ç›´åˆ°è¨“ç·´å®Œæˆæˆ–è‡³å°‘åŸ·è¡Œä¸€å€‹å ´æ™¯
        while True:
            # æª¢æŸ¥è¨“ç·´æ˜¯å¦å®Œæˆ
            if has_training_proc and training_proc.poll() is not None:
                self.logger.info("âœ… è¨“ç·´é€²ç¨‹å·²å®Œæˆ")
                break
            
            # éš¨æ©Ÿé¸æ“‡å ´æ™¯
            scenario = random.choice(scenario_list)
            scenario_count += 1
            
            # å‰µå»ºå”¯ä¸€çš„è¼¸å‡ºç›®éŒ„
            out_dir = base_output_dir / f"{scenario}_{scenario_count:03d}"
            self.logger.info(f"ğŸ“Š åŸ·è¡Œéš¨æ©Ÿæ¸¬è©¦æƒ…å¢ƒ [ç¬¬{scenario_count}å€‹]: {scenario}")
            
            # æ§‹å»ºé ç«¯æ¨™ç±¤
            remote_tag = f"{experiment_type}/{run_tag}" if self.m1_host else run_tag
            
            # åŸ·è¡Œ Locust æ¸¬è©¦
            success = self.run_distributed_locust(scenario, remote_tag, out_dir)
            if success:
                scenario_dirs.append(out_dir)
            
            # æƒ…å¢ƒé–“å†·å»æ™‚é–“
            if has_training_proc and training_proc.poll() is None:
                cooldown = int(os.getenv("COOLDOWN_BETWEEN_SCENARIOS", "60"))
                self.logger.info(f"â¸ï¸ æƒ…å¢ƒé–“å†·å» {cooldown} ç§’...")
                time.sleep(cooldown)
            elif not has_training_proc:
                # å¦‚æœæ²’æœ‰è¨“ç·´é€²ç¨‹ï¼ŒåŸ·è¡Œä¸€å€‹å ´æ™¯å¾ŒçµæŸ
                break
        
        # æœ€çµ‚ç­‰å¾…è¨“ç·´å®Œæˆ
        if has_training_proc and training_proc.poll() is None:
            self.logger.info("â³ æœ€çµ‚ç­‰å¾…è¨“ç·´é€²ç¨‹å®Œæˆ...")
            training_proc.wait()
        
        self.logger.info(f"ğŸ ç¸½å…±åŸ·è¡Œäº† {len(scenario_dirs)} å€‹éš¨æ©Ÿå ´æ™¯æ¸¬è©¦")
        return scenario_dirs

    def run_fixed_hpa_loadtest(self, experiment_type: str, run_tag: str, seed: int) -> List[Path]:
        """ç‚º HPA åŸºæº–æ¸¬è©¦é‹è¡Œå›ºå®šçš„ 4 å€‹å ´æ™¯åºåˆ—"""
        # ç”Ÿæˆå›ºå®šçš„å ´æ™¯åºåˆ—ï¼ˆåŸºæ–¼ seedï¼‰
        random.seed(seed)
        scenario_list = list(self.scenarios.keys())
        
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰ä¿å­˜çš„åºåˆ—
        sequence_file = self.repo_root / "logs" / "hpa_scenario_sequence.txt"
        
        if sequence_file.exists():
            # è®€å–å·²ä¿å­˜çš„åºåˆ—
            with open(sequence_file, 'r') as f:
                saved_sequences = {}
                for line in f:
                    if line.strip():
                        parts = line.strip().split(':')
                        if len(parts) == 2:
                            saved_seed, saved_sequence = parts
                            saved_sequences[int(saved_seed)] = saved_sequence.split(',')
            
            if seed in saved_sequences:
                fixed_sequence = saved_sequences[seed]
                self.logger.info(f"ğŸ“‹ ä½¿ç”¨å·²ä¿å­˜çš„ HPA æ¸¬è©¦åºåˆ— (seed {seed}): {', '.join(fixed_sequence)}")
            else:
                # ç”Ÿæˆæ–°åºåˆ—ä¸¦ä¿å­˜
                fixed_sequence = random.choices(scenario_list, k=4)
                saved_sequences[seed] = fixed_sequence
                
                # ä¿å­˜æ›´æ–°çš„åºåˆ—
                with open(sequence_file, 'w') as f:
                    for s, seq in saved_sequences.items():
                        f.write(f"{s}:{','.join(seq)}\n")
                
                self.logger.info(f"ğŸ“‹ ç”Ÿæˆä¸¦ä¿å­˜æ–°çš„ HPA æ¸¬è©¦åºåˆ— (seed {seed}): {', '.join(fixed_sequence)}")
        else:
            # é¦–æ¬¡é‹è¡Œï¼Œç”Ÿæˆä¸¦ä¿å­˜åºåˆ—
            fixed_sequence = random.choices(scenario_list, k=4)
            sequence_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(sequence_file, 'w') as f:
                f.write(f"{seed}:{','.join(fixed_sequence)}\n")
            
            self.logger.info(f"ğŸ“‹ é¦–æ¬¡ç”Ÿæˆ HPA æ¸¬è©¦åºåˆ— (seed {seed}): {', '.join(fixed_sequence)}")
        
        # å‰µå»ºåŸºç¤è¼¸å‡ºç›®éŒ„
        base_output_dir = self.repo_root / "logs" / experiment_type / run_tag
        base_output_dir.mkdir(parents=True, exist_ok=True)
        
        scenario_dirs = []
        
        # åŸ·è¡Œå›ºå®šåºåˆ—çš„ 4 å€‹å ´æ™¯
        for i, scenario in enumerate(fixed_sequence, 1):
            out_dir = base_output_dir / f"{scenario}_{i:03d}"
            self.logger.info(f"ğŸ“Š åŸ·è¡Œ HPA æ¸¬è©¦æƒ…å¢ƒ [{i}/4]: {scenario}")
            
            # æ§‹å»ºé ç«¯æ¨™ç±¤
            remote_tag = f"{experiment_type}/{run_tag}" if self.m1_host else run_tag
            
            # åŸ·è¡Œ Locust æ¸¬è©¦
            success = self.run_distributed_locust(scenario, remote_tag, out_dir)
            if success:
                scenario_dirs.append(out_dir)
            
            # å ´æ™¯é–“çŸ­æš«å†·å»
            if i < len(fixed_sequence):
                cooldown = 30  # HPA æ¸¬è©¦é–“è¼ƒçŸ­çš„å†·å»æ™‚é–“
                self.logger.info(f"â¸ï¸ HPA å ´æ™¯é–“å†·å» {cooldown} ç§’...")
                time.sleep(cooldown)
        
        self.logger.info(f"ğŸ HPA åŸºæº–æ¸¬è©¦å®Œæˆï¼ŒåŸ·è¡Œäº† {len(scenario_dirs)} å€‹å ´æ™¯")
        return scenario_dirs
    
    def run_multi_hpa_experiment(self, experiment_type: str, run_tag: str, seed: int, hpa_type: str = 'all') -> List[Path]:
        """åŸ·è¡Œå¤šé…ç½®HPAæ¸¬è©¦
        
        Args:
            experiment_type: å¯¦é©—é¡å‹
            run_tag: é‹è¡Œæ¨™ç±¤ 
            seed: éš¨æ©Ÿç¨®å­ï¼ˆç”¨æ–¼ç”Ÿæˆå›ºå®šå ´æ™¯åºåˆ—ï¼‰
            hpa_type: HPAé…ç½®é¡å‹ ('all', 'cpu', 'mem', 'hybrid')
        
        Returns:
            æ‰€æœ‰æ¸¬è©¦çµæœç›®éŒ„åˆ—è¡¨
        """
        
        # ç²å–è¦æ¸¬è©¦çš„HPAé…ç½®
        if hpa_type == 'all':
            configs_to_test = []
            for config_type in self.hpa_configs:
                configs_to_test.extend(self.hpa_configs[config_type])
        elif hpa_type in self.hpa_configs:
            configs_to_test = self.hpa_configs[hpa_type]
        else:
            self.logger.error(f"âŒ ä¸æ”¯æ´çš„HPAé¡å‹: {hpa_type}. å¯ç”¨é¡å‹: all, cpu, mem, hybrid")
            return []
        
        self.logger.info(f"ğŸ“ˆ æ¸¬è©¦HPAé¡å‹: {hpa_type}, å…± {len(configs_to_test)} ç¨®é…ç½®")
        self.logger.info(f"ğŸ“‹ é…ç½®åˆ—è¡¨: {', '.join(configs_to_test)}")
        
        # ç”Ÿæˆå›ºå®šçš„å ´æ™¯åºåˆ—ï¼ˆæ‰€æœ‰HPAé…ç½®éƒ½ç”¨ç›¸åŒåºåˆ—ï¼‰
        test_sequence = self._generate_hpa_test_sequence(seed)
        self.logger.info(f"ğŸ² ä½¿ç”¨å›ºå®šæ¸¬è©¦åºåˆ— (seed {seed}): {', '.join(test_sequence)}")
        
        all_results = []
        
        for i, config_name in enumerate(configs_to_test, 1):
            self.logger.info(f"\nğŸ”„ [{i}/{len(configs_to_test)}] æ¸¬è©¦HPAé…ç½®: {config_name}")
            
            try:
                # æ‡‰ç”¨HPAé…ç½®
                if self._apply_hpa_config(config_name):
                    # ç­‰å¾…HPAç”Ÿæ•ˆ
                    self.logger.info(f"â³ ç­‰å¾…HPAé…ç½®ç”Ÿæ•ˆ (30ç§’)...")
                    time.sleep(30)
                    
                    # åŸ·è¡Œå›ºå®šåºåˆ—æ¸¬è©¦
                    config_results = self._run_hpa_config_test(
                        config_name, test_sequence, run_tag, experiment_type
                    )
                    all_results.extend(config_results)
                    
                    self.logger.info(f"âœ… {config_name} æ¸¬è©¦å®Œæˆï¼Œç”¢ç”Ÿ {len(config_results)} å€‹çµæœ")
                else:
                    self.logger.error(f"âŒ {config_name} HPAé…ç½®æ‡‰ç”¨å¤±æ•—")
                    
            except Exception as e:
                self.logger.error(f"âŒ {config_name} æ¸¬è©¦ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        self.logger.info(f"\nğŸ† æ‰€æœ‰HPAæ¸¬è©¦å®Œæˆ! å…±ç”¢ç”Ÿ {len(all_results)} å€‹çµæœ")
        return all_results
    
    def _generate_hpa_test_sequence(self, seed: int) -> List[str]:
        """ç”ŸæˆHPAæ¸¬è©¦çš„å›ºå®šå ´æ™¯åºåˆ—"""
        # ç”Ÿæˆå›ºå®šçš„å ´æ™¯åºåˆ—ï¼ˆåŸºæ–¼ seedï¼‰
        random.seed(seed)
        scenario_list = list(self.scenarios.keys())
        
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰ä¿å­˜çš„åºåˆ—
        sequence_file = self.repo_root / "logs" / "hpa_scenario_sequence.txt"
        
        if sequence_file.exists():
            # è®€å–å·²ä¿å­˜çš„åºåˆ—
            with open(sequence_file, 'r') as f:
                saved_sequences = {}
                for line in f:
                    if line.strip():
                        parts = line.strip().split(':')
                        if len(parts) == 2:
                            saved_seed, saved_sequence = parts
                            saved_sequences[int(saved_seed)] = saved_sequence.split(',')
            
            if seed in saved_sequences:
                return saved_sequences[seed]
                
        # ç”Ÿæˆæ–°åºåˆ—
        fixed_sequence = random.choices(scenario_list, k=4)
        
        # ä¿å­˜åºåˆ—
        sequence_file.parent.mkdir(parents=True, exist_ok=True)
        saved_sequences = {}
        
        if sequence_file.exists():
            with open(sequence_file, 'r') as f:
                for line in f:
                    if line.strip():
                        parts = line.strip().split(':')
                        if len(parts) == 2:
                            saved_seed, saved_sequence = parts
                            saved_sequences[int(saved_seed)] = saved_sequence.split(',')
        
        saved_sequences[seed] = fixed_sequence
        
        with open(sequence_file, 'w') as f:
            for s, seq in saved_sequences.items():
                f.write(f"{s}:{','.join(seq)}\n")
                
        return fixed_sequence
    
    def _apply_hpa_config(self, config_name: str) -> bool:
        """æ‡‰ç”¨æŒ‡å®šHPAé…ç½®"""
        config_dir = self.hpa_root / config_name
        
        if not config_dir.exists():
            self.logger.error(f"âŒ HPAé…ç½®ç›®éŒ„ä¸å­˜åœ¨: {config_dir}")
            return False
        
        self.logger.info(f"ğŸ”§ æ‡‰ç”¨HPAé…ç½®: {config_name}")
        
        try:
            # å…ˆæ¸…é™¤æ‰€æœ‰ç¾æœ‰HPA
            result = subprocess.run(
                ["kubectl", "delete", "hpa", "--all", "-n", self.namespace],
                capture_output=True, text=True, timeout=30
            )
            
            # æ‡‰ç”¨æ–°çš„HPAé…ç½®
            for hpa_file in config_dir.glob("*.yaml"):
                result = subprocess.run(
                    ["kubectl", "apply", "-f", str(hpa_file)],
                    capture_output=True, text=True, timeout=30
                )
                
                if result.returncode != 0:
                    self.logger.error(f"âŒ æ‡‰ç”¨HPAæª”æ¡ˆå¤±æ•—: {hpa_file}")
                    self.logger.error(f"éŒ¯èª¤è¨Šæ¯: {result.stderr}")
                    return False
            
            self.logger.info(f"âœ… HPAé…ç½® {config_name} æ‡‰ç”¨æˆåŠŸ")
            return True
            
        except subprocess.TimeoutExpired:
            self.logger.error(f"âŒ HPAé…ç½®æ‡‰ç”¨è¶…æ™‚: {config_name}")
            return False
        except Exception as e:
            self.logger.error(f"âŒ HPAé…ç½®æ‡‰ç”¨ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def _run_hpa_config_test(self, config_name: str, test_sequence: List[str], 
                            run_tag: str, experiment_type: str) -> List[Path]:
        """åŸ·è¡Œå–®å€‹HPAé…ç½®çš„æ¸¬è©¦"""
        results = []
        
        # å‰µå»ºé…ç½®ç‰¹å®šçš„è¼¸å‡ºç›®éŒ„
        config_output_dir = self.repo_root / "logs" / experiment_type / run_tag / config_name
        config_output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"ğŸ“‹ åŸ·è¡Œ {config_name} æ¸¬è©¦åºåˆ—: {', '.join(test_sequence)}")
        
        for i, scenario in enumerate(test_sequence, 1):
            self.logger.info(f"\nğŸ“Š [{i}/4] åŸ·è¡Œå ´æ™¯: {scenario}")
            
            # ç‚ºæ¯å€‹å ´æ™¯å‰µå»ºç›®éŒ„
            scenario_dir = config_output_dir / f"{scenario}_{i:03d}"
            scenario_dir.mkdir(parents=True, exist_ok=True)
            
            # åŸ·è¡Œå–®å€‹å ´æ™¯æ¸¬è©¦
            remote_tag = f"{experiment_type}/{run_tag}/{config_name}" if self.m1_host else f"{run_tag}_{config_name}"
            if self.run_distributed_locust(scenario, remote_tag, scenario_dir):
                results.append(scenario_dir)
                self.logger.info(f"âœ… {scenario} æ¸¬è©¦å®Œæˆ")
            else:
                self.logger.error(f"âŒ {scenario} æ¸¬è©¦å¤±æ•—")
            
            # å ´æ™¯é–“é—œéš”æ™‚é–“
            if i < len(test_sequence):
                self.logger.info(f"â³ å ´æ™¯é–“é—œéš”æ™‚é–“ 5 åˆ†é˜...")
                time.sleep(300)  # 5åˆ†é˜é—œéš”
        
        return results
    
    def compare_experiments(self, result_paths: List[str]):
        """æ¯”è¼ƒå¯¦é©—çµæœ"""
        self.logger.info("ğŸ“Š æ¯”è¼ƒå¯¦é©—çµæœ...")
        
        # å¯¦ç¾å¯¦é©—çµæœæ¯”è¼ƒé‚è¼¯
        # é€™è£¡å¯ä»¥æ·»åŠ æ›´è©³ç´°çš„æ¯”è¼ƒåˆ†æ
        pass

def main():
    parser = argparse.ArgumentParser(description="çµ±ä¸€å¯¦é©—ç®¡ç†å™¨")
    
    # å¯¦é©—é¸æ“‡
    parser.add_argument('--experiment', choices=['gym_hpa', 'k8s_hpa', 'gnnrl'], 
                       help='åŸ·è¡ŒæŒ‡å®šå¯¦é©—')
    parser.add_argument('--batch-all', action='store_true',
                       help='æ‰¹æ¬¡åŸ·è¡Œæ‰€æœ‰å¯¦é©—')
    parser.add_argument('--experiments', nargs='+', 
                       choices=['gym_hpa', 'k8s_hpa', 'gnnrl'],
                       help='æ‰¹æ¬¡åŸ·è¡ŒæŒ‡å®šå¯¦é©—')
    
    # å¯¦é©—åƒæ•¸
    parser.add_argument('--steps', type=int, 
                       default=int(os.getenv('DEFAULT_STEPS', '5000')),
                       help='è¨“ç·´æ­¥æ•¸')
    parser.add_argument('--goal', choices=['latency', 'cost'], 
                       default=os.getenv('DEFAULT_GOAL', 'latency'),
                       help='å„ªåŒ–ç›®æ¨™')
    parser.add_argument('--use-case', choices=['redis', 'online_boutique'], 
                       default=os.getenv('DEFAULT_USE_CASE', 'online_boutique'), 
                       help='æ‡‰ç”¨å ´æ™¯')
    parser.add_argument('--alg', choices=['ppo', 'recurrent_ppo', 'a2c'], 
                       default='ppo',
                       help='å¼·åŒ–å­¸ç¿’ç®—æ³•')
    parser.add_argument('--model', choices=['gat', 'gcn'], 
                       default='gat',
                       help='GNN æ¨¡å‹é¡å‹ (åƒ…é©ç”¨æ–¼ gnnrl å¯¦é©—)')
    parser.add_argument('--seed', type=int, default=42,
                       help='éš¨æ©Ÿç¨®å­ (ç”¨æ–¼æ§åˆ¶ Locust æƒ…å¢ƒåŸ·è¡Œé †åº)')
    parser.add_argument('--env-step-interval', type=float, default=15.0,
                       help='ç’°å¢ƒæ­¥é©Ÿé–“éš”ç§’æ•¸ (æ¨¡å‹æ¥æ”¶æ–°æ•¸æ“šçš„é »ç‡)')
    parser.add_argument('--run-tag', help='é‹è¡Œæ¨™ç±¤')
    parser.add_argument('--hpa-type', choices=['all', 'cpu', 'mem', 'hybrid'], default='all',
                       help='K8s-HPA æ¸¬è©¦é…ç½®é¡å‹ (all=æ‰€æœ‰, cpu=åƒ…CPU, mem=åƒ…è¨˜æ†¶é«”, hybrid=æ··åˆ)')
    parser.add_argument('--k8s', action='store_true',
                       help='å•Ÿç”¨çœŸå¯¦ K8s é›†ç¾¤æ¨¡å¼ (é è¨­: æ¨¡æ“¬æ¨¡å¼)')
    parser.add_argument('--simulation', action='store_true',
                       help='å¼·åˆ¶ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼ (è¦†è“‹ --k8s)')
    
    # æ¸¬è©¦æ¨¡å¼åƒæ•¸
    parser.add_argument('--testing', action='store_true',
                       help='ä½¿ç”¨å·²è¨“ç·´æ¨¡å‹é€²è¡Œæ¸¬è©¦ (éœ€æ­é… --load-path)')
    parser.add_argument('--load-path', type=str,
                       help='å·²è¨“ç·´æ¨¡å‹çš„è·¯å¾‘ (ç”¨æ–¼æ¸¬è©¦æ¨¡å¼)')
    
    # å…¶ä»–åŠŸèƒ½
    parser.add_argument('--validate-only', action='store_true',
                       help='åƒ…é©—è­‰ç’°å¢ƒ')
    parser.add_argument('--loadtest-only', action='store_true',
                       help='åƒ…åŸ·è¡Œè² è¼‰æ¸¬è©¦')
    parser.add_argument('--enable-loadtest', action='store_true',
                       help='å¼·åˆ¶å•Ÿç”¨è² è¼‰æ¸¬è©¦ï¼ˆé©ç”¨æ–¼æ¸¬è©¦æ¨¡å¼ï¼‰')
    parser.add_argument('--compare', nargs='+',
                       help='æ¯”è¼ƒå¯¦é©—çµæœè·¯å¾‘')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    manager = UnifiedExperimentManager()
    
    # ç’°å¢ƒé©—è­‰
    if not manager.validate_environment(args.use_case):
        if not args.validate_only:
            sys.exit(1)
        else:
            return
    
    if args.validate_only:
        return
    
    # åŸ·è¡Œå¯¦é©—
    if args.experiment:
        success = manager.run_experiment(
            args.experiment,
            steps=args.steps,
            goal=args.goal,
            use_case=args.use_case,
            alg=args.alg,
            model=args.model,
            seed=args.seed,
            env_step_interval=args.env_step_interval,
            run_tag=args.run_tag,
            k8s=args.k8s and not args.simulation,
            testing=args.testing,
            load_path=args.load_path,
            hpa_type=args.hpa_type
        )
        sys.exit(0 if success else 1)
    
    elif args.batch_all:
        experiments = ['gym_hpa', 'k8s_hpa', 'gnnrl']
        results = manager.run_batch_experiments(
            experiments,
            steps=args.steps,
            goal=args.goal,
            use_case=args.use_case,
            alg=args.alg,
            model=args.model,
            seed=args.seed,
            env_step_interval=args.env_step_interval,
            k8s=args.k8s and not args.simulation,
            hpa_type=args.hpa_type
        )
        sys.exit(0 if all(results.values()) else 1)
    
    elif args.experiments:
        results = manager.run_batch_experiments(
            args.experiments,
            steps=args.steps,
            goal=args.goal,
            use_case=args.use_case,
            alg=args.alg,
            model=args.model,
            seed=args.seed,
            env_step_interval=args.env_step_interval,
            k8s=args.k8s and not args.simulation,
            hpa_type=args.hpa_type
        )
        sys.exit(0 if all(results.values()) else 1)
    
    elif args.compare:
        manager.compare_experiments(args.compare)
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main()