#!/usr/bin/env python3
"""
Graph Visualization Dashboard for GNNRL Training
==============================================

å‹•æ…‹å±•ç¤ºè¨“ç·´éç¨‹ä¸­çš„åœ–å½¢æ•¸æ“šè®ŠåŒ–ï¼ŒåŒ…æ‹¬ï¼š
- ç¶²çµ¡æ‹“æ’²æ¼”è®Š
- ç¯€é»ç‰¹å¾µè®ŠåŒ–å‹•ç•«
- é‚Šç‰¹å¾µè®ŠåŒ–è¶¨å‹¢
- è¨“ç·´æŒ‡æ¨™å¯¦æ™‚ç›£æ§

ä½¿ç”¨æ–¹å¼ï¼š
    python graph_visualization_dashboard.py --log-dir logs/gnnrl/gnnrl_train_seed42_20250711_120622/graph_visualizations
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from typing import Dict, List, Optional, Any
import webbrowser

try:
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    import plotly.express as px
    import plotly.offline as pyo
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

try:
    import networkx as nx
    HAS_NETWORKX = True
except ImportError:
    HAS_NETWORKX = False


class GraphVisualizationDashboard:
    """GNNRLè¨“ç·´åœ–å½¢å¯è¦–åŒ–å„€è¡¨æ¿"""
    
    def __init__(self, log_dir: str):
        self.log_dir = Path(log_dir)
        self.step_dirs = []
        self.data_timeline = []
        self.service_names = []
        
        # æƒææ‰€æœ‰æ­¥é©Ÿæ•¸æ“š
        self._scan_step_data()
        
        # è¨­ç½®è¼¸å‡ºç›®éŒ„
        self.output_dir = self.log_dir / "dashboard"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def _scan_step_data(self):
        """æƒææ‰€æœ‰æ­¥é©Ÿæ•¸æ“š"""
        if not self.log_dir.exists():
            print(f"âŒ æ—¥èªŒç›®éŒ„ä¸å­˜åœ¨: {self.log_dir}")
            return
            
        # æ‰¾åˆ°æ‰€æœ‰stepç›®éŒ„
        step_pattern = "step_*"
        self.step_dirs = sorted([d for d in self.log_dir.glob(step_pattern) if d.is_dir()])
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(self.step_dirs)} å€‹æ­¥é©Ÿæ•¸æ“šç›®éŒ„")
        
        # åŠ è¼‰æ¯å€‹æ­¥é©Ÿçš„æ•¸æ“š
        for step_dir in self.step_dirs:
            raw_data_file = step_dir / "raw_data_step_*.json"
            raw_data_files = list(step_dir.glob("raw_data_step_*.json"))
            
            if raw_data_files:
                try:
                    with open(raw_data_files[0], 'r') as f:
                        data = json.load(f)
                        self.data_timeline.append(data)
                        
                        # æå–æœå‹™åç¨±ï¼ˆç¬¬ä¸€æ¬¡ï¼‰
                        if not self.service_names and 'service_names' in data:
                            self.service_names = data['service_names']
                            
                except Exception as e:
                    print(f"âš ï¸ è®€å–æ•¸æ“šå¤±æ•—: {raw_data_files[0]}, {e}")
        
        print(f"âœ… æˆåŠŸåŠ è¼‰ {len(self.data_timeline)} å€‹æ­¥é©Ÿçš„æ•¸æ“š")
        
    def generate_interactive_dashboard(self):
        """ç”Ÿæˆäº¤äº’å¼HTMLå„€è¡¨æ¿"""
        if not HAS_PLOTLY:
            print("âŒ éœ€è¦å®‰è£ plotly ä¾†ç”Ÿæˆäº¤äº’å¼å„€è¡¨æ¿")
            print("è«‹åŸ·è¡Œ: pip install plotly")
            return
            
        if not self.data_timeline:
            print("âŒ æ²’æœ‰æ‰¾åˆ°å¯è¦–åŒ–æ•¸æ“š")
            return
            
        # å‰µå»ºå­åœ–
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('Training Reward Trend', 'Node Features Evolution', 
                          'CPU Usage Distribution', 'Memory Usage Distribution'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # æº–å‚™æ•¸æ“š
        steps = [data['step'] for data in self.data_timeline]
        rewards = [data['reward'] for data in self.data_timeline]
        
        # 1. è¨“ç·´çå‹µè¶¨å‹¢
        fig.add_trace(
            go.Scatter(
                x=steps, y=rewards,
                mode='lines+markers',
                name='Training Reward',
                line=dict(color='blue', width=2),
                marker=dict(size=6)
            ),
            row=1, col=1
        )
        
        # 2. ç¯€é»ç‰¹å¾µæ¼”åŒ–ï¼ˆä»¥ç¬¬ä¸€å€‹æœå‹™ç‚ºä¾‹ï¼‰
        if self.service_names:
            pod_counts = [data['node_features'][0][0] for data in self.data_timeline]
            cpu_usage = [data['node_features'][0][2] for data in self.data_timeline]
            
            fig.add_trace(
                go.Scatter(
                    x=steps, y=pod_counts,
                    mode='lines+markers',
                    name=f'{self.service_names[0]} Pod Count',
                    line=dict(color='green', width=2),
                    marker=dict(size=6)
                ),
                row=1, col=2
            )
            
            # 3. CPUä½¿ç”¨ç‡åˆ†ä½ˆ
            latest_cpu = [node[2] for node in self.data_timeline[-1]['node_features']]
            fig.add_trace(
                go.Bar(
                    x=self.service_names,
                    y=latest_cpu,
                    name='CPU Usage (%)',
                    marker_color='orange'
                ),
                row=2, col=1
            )
            
            # 4. è¨˜æ†¶é«”ä½¿ç”¨ç‡åˆ†ä½ˆ
            latest_mem = [node[3] for node in self.data_timeline[-1]['node_features']]
            fig.add_trace(
                go.Bar(
                    x=self.service_names,
                    y=latest_mem,
                    name='Memory Usage (MB)',
                    marker_color='red'
                ),
                row=2, col=2
            )
        
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title="GNNRL Training Dashboard",
            showlegend=True,
            height=800,
            font=dict(size=12)
        )
        
        # ä¿å­˜HTMLæ–‡ä»¶
        html_file = self.output_dir / "interactive_dashboard.html"
        pyo.plot(fig, filename=str(html_file), auto_open=False)
        
        print(f"âœ… äº¤äº’å¼å„€è¡¨æ¿å·²ç”Ÿæˆ: {html_file}")
        return html_file
        
    def generate_network_evolution_gif(self):
        """ç”Ÿæˆç¶²çµ¡æ¼”åŒ–å‹•ç•«GIF"""
        if not HAS_NETWORKX:
            print("âŒ éœ€è¦å®‰è£ networkx ä¾†ç”Ÿæˆç¶²çµ¡æ¼”åŒ–å‹•ç•«")
            print("è«‹åŸ·è¡Œ: pip install networkx")
            return
            
        if not self.data_timeline:
            print("âŒ æ²’æœ‰æ‰¾åˆ°å¯è¦–åŒ–æ•¸æ“š")
            return
            
        # å‰µå»ºå‹•ç•«
        fig, ax = plt.subplots(figsize=(12, 8))
        
        def update_graph(frame):
            ax.clear()
            
            if frame < len(self.data_timeline):
                data = self.data_timeline[frame]
                step = data['step']
                node_features = data['node_features']
                
                # å‰µå»ºç¶²çµ¡åœ–
                G = nx.DiGraph()
                
                # æ·»åŠ ç¯€é»
                for i, service_name in enumerate(self.service_names):
                    if i < len(node_features):
                        pod_count = node_features[i][0]
                        cpu_usage = node_features[i][2]
                        
                        G.add_node(service_name, 
                                  pod_count=pod_count,
                                  cpu_usage=cpu_usage,
                                  size=max(300, pod_count * 200))
                
                # ç°¡å–®çš„ç’°å½¢ä½ˆå±€
                pos = nx.circular_layout(G)
                
                # ç¹ªè£½ç¯€é»
                node_colors = []
                node_sizes = []
                
                for node in G.nodes():
                    cpu_usage = G.nodes[node]['cpu_usage']
                    
                    if cpu_usage > 80:
                        node_colors.append('red')
                    elif cpu_usage > 60:
                        node_colors.append('orange')
                    elif cpu_usage > 40:
                        node_colors.append('yellow')
                    else:
                        node_colors.append('lightgreen')
                    
                    node_sizes.append(G.nodes[node]['size'])
                
                nx.draw_networkx_nodes(G, pos, node_color=node_colors, 
                                     node_size=node_sizes, alpha=0.7, ax=ax)
                nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold', ax=ax)
                
                ax.set_title(f'Network Evolution - Step {step}', fontsize=14, fontweight='bold')
                ax.set_axis_off()
        
        # å‰µå»ºå‹•ç•«
        anim = animation.FuncAnimation(
            fig, update_graph, frames=len(self.data_timeline), 
            interval=1000, repeat=True, blit=False
        )
        
        # ä¿å­˜GIF
        gif_file = self.output_dir / "network_evolution.gif"
        try:
            anim.save(str(gif_file), writer='pillow', fps=1)
            print(f"âœ… ç¶²çµ¡æ¼”åŒ–å‹•ç•«å·²ç”Ÿæˆ: {gif_file}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜GIFå¤±æ•—: {e}")
            print("è«‹ç¢ºä¿å®‰è£äº† pillow: pip install pillow")
        
        plt.close()
        
    def generate_metrics_report(self):
        """ç”ŸæˆæŒ‡æ¨™å ±å‘Š"""
        if not self.data_timeline:
            print("âŒ æ²’æœ‰æ‰¾åˆ°å¯è¦–åŒ–æ•¸æ“š")
            return
            
        # å‰µå»ºå ±å‘Š
        report = {
            'training_summary': {
                'total_steps': len(self.data_timeline),
                'step_range': f"{self.data_timeline[0]['step']} - {self.data_timeline[-1]['step']}",
                'duration': self.data_timeline[-1]['timestamp'],
                'services_monitored': len(self.service_names)
            },
            'reward_statistics': {
                'initial_reward': self.data_timeline[0]['reward'],
                'final_reward': self.data_timeline[-1]['reward'],
                'max_reward': max(data['reward'] for data in self.data_timeline),
                'min_reward': min(data['reward'] for data in self.data_timeline),
                'avg_reward': np.mean([data['reward'] for data in self.data_timeline])
            },
            'service_statistics': {}
        }
        
        # è¨ˆç®—æœå‹™çµ±è¨ˆ
        for i, service_name in enumerate(self.service_names):
            initial_features = self.data_timeline[0]['node_features'][i]
            final_features = self.data_timeline[-1]['node_features'][i]
            
            report['service_statistics'][service_name] = {
                'pod_count_change': final_features[0] - initial_features[0],
                'cpu_usage_change': final_features[2] - initial_features[2],
                'memory_usage_change': final_features[3] - initial_features[3]
            }
        
        # ä¿å­˜å ±å‘Š
        report_file = self.output_dir / "training_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"âœ… è¨“ç·´å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
        
        # æ‰“å°æ‘˜è¦
        print("\nğŸ“Š è¨“ç·´æ‘˜è¦:")
        print(f"   ç¸½æ­¥æ•¸: {report['training_summary']['total_steps']}")
        print(f"   æ­¥é©Ÿç¯„åœ: {report['training_summary']['step_range']}")
        print(f"   ç›£æ§æœå‹™: {report['training_summary']['services_monitored']}")
        print(f"   åˆå§‹çå‹µ: {report['reward_statistics']['initial_reward']:.2f}")
        print(f"   æœ€çµ‚çå‹µ: {report['reward_statistics']['final_reward']:.2f}")
        print(f"   å¹³å‡çå‹µ: {report['reward_statistics']['avg_reward']:.2f}")
        
    def generate_all_visualizations(self):
        """ç”Ÿæˆæ‰€æœ‰å¯è¦–åŒ–"""
        print("ğŸ¨ é–‹å§‹ç”Ÿæˆæ‰€æœ‰å¯è¦–åŒ–...")
        
        # 1. äº¤äº’å¼å„€è¡¨æ¿
        html_file = self.generate_interactive_dashboard()
        
        # 2. ç¶²çµ¡æ¼”åŒ–å‹•ç•«
        self.generate_network_evolution_gif()
        
        # 3. æŒ‡æ¨™å ±å‘Š
        self.generate_metrics_report()
        
        print(f"\nâœ… æ‰€æœ‰å¯è¦–åŒ–å·²ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“‚ è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        print(f"ğŸŒ æŸ¥çœ‹å„€è¡¨æ¿: {html_file}")
        
        # å˜—è©¦æ‰“é–‹ç€è¦½å™¨
        if html_file and html_file.exists():
            try:
                webbrowser.open(f"file://{html_file.absolute()}")
                print("ğŸŒ å·²åœ¨ç€è¦½å™¨ä¸­æ‰“é–‹å„€è¡¨æ¿")
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•è‡ªå‹•æ‰“é–‹ç€è¦½å™¨: {e}")


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="GNNRLè¨“ç·´åœ–å½¢å¯è¦–åŒ–å„€è¡¨æ¿")
    parser.add_argument('--log-dir', required=True, help='åœ–å½¢å¯è¦–åŒ–æ—¥èªŒç›®éŒ„')
    parser.add_argument('--output-dir', help='è¼¸å‡ºç›®éŒ„ï¼ˆå¯é¸ï¼‰')
    parser.add_argument('--dashboard-only', action='store_true', help='åªç”Ÿæˆå„€è¡¨æ¿')
    parser.add_argument('--gif-only', action='store_true', help='åªç”ŸæˆGIFå‹•ç•«')
    parser.add_argument('--report-only', action='store_true', help='åªç”Ÿæˆå ±å‘Š')
    
    args = parser.parse_args()
    
    # å‰µå»ºå„€è¡¨æ¿
    dashboard = GraphVisualizationDashboard(args.log_dir)
    
    # è¨­ç½®è¼¸å‡ºç›®éŒ„
    if args.output_dir:
        dashboard.output_dir = Path(args.output_dir)
        dashboard.output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ ¹æ“šé¸é …ç”Ÿæˆå¯è¦–åŒ–
    if args.dashboard_only:
        dashboard.generate_interactive_dashboard()
    elif args.gif_only:
        dashboard.generate_network_evolution_gif()
    elif args.report_only:
        dashboard.generate_metrics_report()
    else:
        dashboard.generate_all_visualizations()


if __name__ == "__main__":
    main()