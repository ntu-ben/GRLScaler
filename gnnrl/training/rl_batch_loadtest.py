#!/usr/bin/env python3
"""
rl_batch_loadtest.py  v5.0  (2025-06-23)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
çµ±ä¸€å¯¦é©—ç®¡ç†å™¨ - æ”¯æŒåˆ†æ•£å¼ Locust æ¸¬è©¦ç’°å¢ƒ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
åŠŸèƒ½æ‘˜è¦ï¼š
â€¢ æ”¯æŒä¸‰ç¨®å¯¦é©—æ¨¡å¼ï¼šgym_hpa, k8s_hpa (baseline), gnnrl
â€¢ æ•´åˆåˆ†æ•£å¼ Locust æ¸¬è©¦ç’°å¢ƒ (M1_HOST é ç«¯ä»£ç†)
â€¢ è‡ªå‹•å”èª¿å¯¦é©—è¨“ç·´èˆ‡è² è¼‰æ¸¬è©¦çš„æ™‚åº
â€¢ çµ±ä¸€æ—¥èªŒç®¡ç†å’ŒçµæœåŒ¯ç¸½
â€¢ æ”¯æŒå¤šç¨®è² è¼‰æ¸¬è©¦æƒ…å¢ƒï¼šoffpeak, rushsale, peak, fluctuating

å¯¦é©—æ¶æ§‹ï¼š
â€¢ gym_hpa: åŸºç¤å¼·åŒ–å­¸ç¿’ + MLP ç­–ç•¥
â€¢ k8s_hpa: Kubernetes HPA åŸºæº–æ¸¬è©¦
â€¢ gnnrl: åœ–ç¥ç¶“ç¶²è·¯å¼·åŒ–å­¸ç¿’

åˆ†æ•£å¼æ¸¬è©¦ï¼š
â€¢ é ç«¯ Locust ä»£ç† (M1_HOST) ç”¨æ–¼åˆ†æ•£è² è¼‰
â€¢ æœ¬åœ° fallback æ©Ÿåˆ¶
â€¢ åŒæ­¥è¨“ç·´éç¨‹èˆ‡è² è¼‰æ¸¬è©¦
"""

from __future__ import annotations
import os, sys, logging, subprocess, time, datetime as dt, traceback, argparse, random
from datetime import datetime
from pathlib import Path
from typing import List, Dict

import pandas as pd, requests
from jinja2 import Template

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. è®€å– .envï¼ˆè‹¥è£äº† python-dotenvï¼‰
# --------------------------------------------------------------------------
REPO_ROOT = Path(__file__).resolve().parent.parent.parent
try:
    from dotenv import load_dotenv
    # `.env` å›ºå®šæ”¾åœ¨ repo æ ¹ç›®éŒ„
    load_dotenv(REPO_ROOT / ".env")
except ModuleNotFoundError:
    pass  # optional

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. å…¨åŸŸå¸¸æ•¸ï¼ˆèˆ‡èˆŠç‰ˆç›¸åŒï¼›ç¯€éŒ„å¿…è¦é …ï¼‰
# --------------------------------------------------------------------------
LOG_ROOT = Path(os.getenv("LOG_ROOT", "logs"))
MODEL_ROOT: Dict[str, Path] = {
    # default to paths relative to this script so the repo can be cloned
    # anywhere without manual edits
    "gym": REPO_ROOT / "gnn_rl/envs",  # Legacy path (if exists)
    "gym-hpa": REPO_ROOT / "gym-hpa",  # Standard RL with MLP policies
    "grl": REPO_ROOT / "gnnrl",  # Legacy GNN-RL (if exists)
    "gnnrl": REPO_ROOT / "gnnrl",  # New unified GNNRL path
    # gwydion submodule contains its own package under "gwydion" folder
    "gwydion": REPO_ROOT / "gwydion" / "gwydion",
    # k8s_hpa houses the baseline tests (no RL training)
    "hpa": REPO_ROOT / "k8s_hpa",
}

NAMESPACE_OB  = os.getenv("NAMESPACE_ONLINEBOUTIQUE", "onlineboutique")
NAMESPACE_REDIS = os.getenv("NAMESPACE_REDIS", "redis")
NAMESPACE     = NAMESPACE_OB
TARGET_HOST   = os.getenv("TARGET_HOST", "http://k8s.orb.local")
HEALTH_PATH   = os.getenv("HEALTH_PATH", "/")
HTTP_TIMEOUT  = int(os.getenv("HTTP_TIMEOUT", "600"))
RUN_TIME      = os.getenv("LOCUST_RUN_TIME", "15m")
SCENARIOS = {
    "offpeak":     "locust_offpeak.py",
    "rushsale":    "locust_rushsale.py",
    "peak":        "locust_peak.py",
    "fluctuating": "locust_fluctuating.py",
}
_MULT = {"s": 1, "m": 60, "h": 3600}
_match = __import__("re").match
_rt = _match(r"(\d+)([smh])", RUN_TIME)
RUN_TIME_SEC = int(_rt.group(1)) * _MULT[_rt.group(2)] if _rt else 900
HALF_RUN_SEC = RUN_TIME_SEC // 2
MAX_STATUS_CHECKS = int(os.getenv("MAX_STATUS_CHECKS", "720"))  # stop polling after 1h (720 * 5s)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. å°å·¥å…·
# --------------------------------------------------------------------------
def panic(msg: str, exc: Exception | None = None) -> None:
    """åŒæ­¥æŠŠéŒ¯èª¤å°åˆ° console èˆ‡ batch.logï¼Œå†çµæŸé€²ç¨‹"""
    logging.error(msg)
    if exc:
        _tb = "".join(traceback.format_exception(type(exc), exc, exc.__traceback__))
        logging.error(_tb)
        print(_tb, file=sys.stderr)
    sys.exit(1)


def sh(cmd: List[str]) -> None:
    """åˆ—å°ä¸¦åŸ·è¡Œ shell æŒ‡ä»¤ï¼›å¤±æ•— raise"""
    logging.info("$ %s", " ".join(map(str, cmd)))
    subprocess.run(cmd, check=True)


def record_kiali_graph(stage: str) -> None:
    """Dump Kiali service graph for the namespace."""
    logging.info("kiali graph (%s)", stage)
    kiali_base = os.getenv('KIALI_URL', 'http://localhost:20001/kiali')
    # ä½¿ç”¨æ­£ç¡®çš„ Kiali v1.7x+ å¤šå‘½åç©ºé—´ API æ ¼å¼
    url = f"{kiali_base}/api/namespaces/graph?namespaces={NAMESPACE}&duration=600s&graphType=workload"
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        # ç¢ºä¿ kiali ç›®éŒ„å­˜åœ¨
        kiali_dir = Path("logs/kiali")
        kiali_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        kiali_file = kiali_dir / f"kiali_{stage}_{timestamp}.json"
        kiali_file.write_text(resp.text, encoding="utf-8")
        logging.info("âœ… Kiali graph saved: %s", kiali_file)
    except Exception as err:
        logging.warning("kiali graph failed: %s", err)


def get_kiali_rps(namespace: str = NAMESPACE) -> float | None:
    """Query Kiali metrics and return average RPS for all workloads."""
    kiali_base = os.getenv('KIALI_URL', 'http://localhost:20001/kiali')
    url = f"{kiali_base}/api/namespaces/{namespace}/metrics?metrics=request_count"
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
    except Exception as exc:
        logging.warning("kiali metrics failed: %s", exc)
        return None
    series = resp.json().get("metrics", {}).get("request_count", [])
    total = 0.0
    count = 0
    for item in series:
        for _, val in item.get("values", []):
            try:
                total += float(val)
                count += 1
            except (TypeError, ValueError):
                continue
    if count == 0:
        return None
    return total / count


def wait_frontend_ready() -> None:
    url = TARGET_HOST.rstrip("/") + HEALTH_PATH
    deadline = time.time() + HTTP_TIMEOUT
    while time.time() < deadline:
        try:
            if requests.get(url, timeout=5).status_code == 200:
                return
        except requests.RequestException:
            pass
        time.sleep(5)
    raise RuntimeError("frontend never became ready")


def run_distributed_locust(scenario: str, tag: str, remote: bool, out_dir: Path, experiment_sync: dict = None) -> None:
    """é‹è¡Œåˆ†æ•£å¼ Locust æ¸¬è©¦ï¼Œæ”¯æŒèˆ‡å¯¦é©—è¨“ç·´åŒæ­¥ã€‚
    
    Args:
        scenario: æ¸¬è©¦æƒ…å¢ƒåç¨±
        tag: é‹è¡Œæ¨™ç±¤
        remote: æ˜¯å¦ä½¿ç”¨é ç«¯ä»£ç†
        out_dir: è¼¸å‡ºç›®éŒ„
        experiment_sync: å¯¦é©—åŒæ­¥ä¿¡æ¯ {"training_proc": subprocess, "sync_points": [...]}
    """
    out_dir.mkdir(parents=True, exist_ok=True)
    
    # æª¢æŸ¥å¯¦é©—è¨“ç·´é€²ç¨‹ç‹€æ…‹
    training_proc = experiment_sync.get("training_proc") if experiment_sync else None
    if training_proc and training_proc.poll() is not None:
        logging.warning("Training process terminated before loadtest %s", scenario)
    
    if remote:
        host = os.environ["M1_HOST"].rstrip("/")
        logging.info("ğŸ”— åˆ†æ•£å¼æ¸¬è©¦: M1_HOST=%s", host)
        logging.info("ğŸš€ è§¸ç™¼é ç«¯ Locust %s åœ¨ %s", scenario, host)
        payload = {
            "tag": tag,
            "scenario": scenario,
            "target_host": TARGET_HOST,
            "run_time": RUN_TIME,
        }
        logging.debug("POST %s/start %s", host, payload)
        try:
            r = requests.post(f"{host}/start", json=payload, timeout=10)
            r.raise_for_status()
            job_id = r.json()["job_id"]
            logging.info("ğŸ“‹ é ç«¯ä»»å‹™ ID: %s", job_id)
            
            # è¨˜éŒ„é–‹å§‹ç‹€æ…‹
            record_kiali_graph("start")
            
            # ä¸­é€”æª¢æŸ¥é»
            time.sleep(HALF_RUN_SEC)
            record_kiali_graph("mid")
            
            # ç­‰å¾…å®Œæˆä¸¦ç›£æ§è¨“ç·´é€²ç¨‹
            for check_count in range(MAX_STATUS_CHECKS):
                time.sleep(5)
                
                # æª¢æŸ¥é ç«¯æ¸¬è©¦ç‹€æ…‹
                st = requests.get(f"{host}/status/{job_id}", timeout=10)
                st.raise_for_status()
                data = st.json()
                
                if data.get("finished"):
                    logging.info("âœ… é ç«¯æ¸¬è©¦ %s å®Œæˆ", scenario)
                    break
                    
                # æ¯ 10 æ¬¡æª¢æŸ¥ä¸€æ¬¡è¨“ç·´é€²ç¨‹
                if check_count % 10 == 0 and training_proc:
                    if training_proc.poll() is not None:
                        logging.warning("âš ï¸  è¨“ç·´é€²ç¨‹åœ¨æ¸¬è©¦æœŸé–“çµ‚æ­¢")
                        
                logging.debug("â³ é ç«¯æ¸¬è©¦ç‹€æ…‹ [%d/%d]: %s", check_count+1, MAX_STATUS_CHECKS, 
                            "running" if not data.get("finished") else "finished")
            else:
                logging.warning("â° é ç«¯æ¸¬è©¦è¶…æ™‚ï¼Œå¯èƒ½ä»åœ¨é‹è¡Œ")
                return
                
            record_kiali_graph("end")
            
            # ä¸‹è¼‰çµæœæª”æ¡ˆ
            downloaded_files = []
            for fname in [f"{scenario}_stats.csv", f"{scenario}_stats_history.csv", f"{scenario}.html"]:
                resp = requests.get(f"{host}/download/{tag}/{fname}", timeout=10)
                if resp.status_code == 200:
                    (out_dir / fname).write_bytes(resp.content)
                    downloaded_files.append(fname)
                    logging.debug("ğŸ“ å·²ä¸‹è¼‰: %s", fname)
                else:
                    logging.warning("âŒ ä¸‹è¼‰å¤±æ•—: %s (status: %d)", fname, resp.status_code)
            
            logging.info("ğŸ“Š é ç«¯æ¸¬è©¦çµæœ: å·²ä¸‹è¼‰ %d/%d æª”æ¡ˆ", len(downloaded_files), 3)
            return
            
        except requests.RequestException as exc:
            logging.error("âŒ é ç«¯æ¸¬è©¦å¤±æ•—: %s", exc)
            logging.info("ğŸ”„ åˆ‡æ›åˆ°æœ¬åœ°æ¸¬è©¦")

    # æœ¬åœ°æ¸¬è©¦ fallback
    script_path = REPO_ROOT / "loadtest" / "onlineboutique" / f"locust_{scenario}.py"
    if not script_path.exists():
        logging.error("âŒ æ¸¬è©¦è…³æœ¬ä¸å­˜åœ¨: %s", script_path)
        return
        
    logging.info("ğŸ  é‹è¡Œæœ¬åœ° Locust %s", scenario)
    cmd = [
        "locust", "-f", str(script_path), "--headless", "--run-time", RUN_TIME,
        "--host", TARGET_HOST,
        "--csv", str(out_dir / scenario), "--csv-full-history",
        "--html", str(out_dir / f"{scenario}.html"),
    ]
    
    logging.debug("$ %s", " ".join(cmd))
    proc = subprocess.Popen(cmd)
    
    record_kiali_graph("start")
    time.sleep(HALF_RUN_SEC)
    record_kiali_graph("mid")
    
    # ç­‰å¾…æœ¬åœ°æ¸¬è©¦å®Œæˆï¼ŒåŒæ™‚ç›£æ§è¨“ç·´é€²ç¨‹
    while proc.poll() is None:
        time.sleep(5)
        if training_proc and training_proc.poll() is not None:
            logging.info("â„¹ï¸  è¨“ç·´é€²ç¨‹å·²å®Œæˆï¼Œç¹¼çºŒç­‰å¾…æ¸¬è©¦")
            training_proc = None  # é¿å…é‡è¤‡è¨˜éŒ„
    
    record_kiali_graph("end")
    
    if proc.returncode:
        logging.warning("âš ï¸  æœ¬åœ°æ¸¬è©¦ %s çµæŸç¢¼: %s", scenario, proc.returncode)
    else:
        logging.info("âœ… æœ¬åœ°æ¸¬è©¦ %s å®Œæˆ", scenario)


def summarise(run_tag: str, scenario_dirs: list[Path], namespace: str) -> pd.DataFrame:
    rows = []
    for d in scenario_dirs:
        try:
            stat_csv = next(d.glob("*_stats.csv"))
        except StopIteration:
            logging.warning("No stats CSV for %s", d)
            continue
        df = pd.read_csv(stat_csv)
        total = df[df["Name"] == "Total"]
        if total.empty:
            logging.warning("No 'Total' row in %s", stat_csv)
            continue
        tot = total.iloc[0]
        rps = get_kiali_rps(namespace)
        rows.append({
            "Run": run_tag,
            "Scenario": d.name,
            "Requests": tot.get("Request Count", 0),
            "Failures": tot.get("Failure Count", 0),
            "Avg RPS": tot.get("Requests/s", 0),
            "Kiali RPS": rps if rps is not None else "",
            "P95 ms": tot.get("95%", 0),
        })
    return pd.DataFrame(rows)


def render_dashboard(df: pd.DataFrame, out_dir: Path) -> None:
    html = "<html><body>" + df.to_html(index=False) + "</body></html>"
    (out_dir / "aggregate.html").write_text(html, encoding="utf-8")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ä¸»ç¨‹å¼
# --------------------------------------------------------------------------
def main() -> None:
    try:
        # 3-1 argparseï¼ˆå…ˆæŠŠé«’ token æ¸…æ‰ï¼‰
        ap = argparse.ArgumentParser()
        ap.add_argument("--model", choices=["gym", "gym-hpa", "grl", "gnnrl", "gwydion", "hpa"], required=True)
        ap.add_argument("--rl-path")          # å¯æ‰‹å‹•è¦†è“‹ repo
        ap.add_argument("--run-tag")
        ap.add_argument("--alg", choices=["ppo", "recurrent_ppo", "a2c"], default="ppo")
        ap.add_argument("--gnn-model", choices=["gat", "gcn"], default="gat", help="GNN model type for gnnrl experiments")
        ap.add_argument("--k8s", action="store_true")
        ap.add_argument("--use-case", default="redis")
        ap.add_argument("--goal", default="cost")
        ap.add_argument("--training", action="store_true")
        ap.add_argument("--testing", action="store_true")
        ap.add_argument("--loading", action="store_true")
        ap.add_argument("--load-path")
        ap.add_argument("--steps", type=int, default=500)
        ap.add_argument("--total-steps", type=int, default=5000)
        ap.add_argument("--seed", type=int, default=42, help="Random seed for scenario order")
        ap.add_argument("--env-step-interval", type=float, default=15.0, help="Environment step interval in seconds")
        ap.add_argument("--tensorboard-log")
        ap.add_argument("--device", choices=["auto", "cpu", "cuda", "mps"])
        args = ap.parse_args(
            [a for a in sys.argv[1:] if a not in {"\\", "\\n", "\n"}]
        )

        # 3-2 æ±ºå®š RL repo è·¯å¾‘
        rl_cwd = Path(args.rl_path) if args.rl_path else MODEL_ROOT[args.model]
        if args.model == "gwydion":
            run_file = rl_cwd / "run.py"
        elif args.model == "gym-hpa":
            run_file = rl_cwd / "policies" / "run" / "run.py"
        elif args.model == "gnnrl":
            run_file = rl_cwd / "training" / "run_gnnrl_experiment.py"
        elif args.model == "hpa":
            run_file = rl_cwd / "HPABaseLineTest.py"
        else:
            run_file = rl_cwd / "gnn_rl/run/run.py"
        if not run_file.exists():
            panic(f"{run_file} ä¸å­˜åœ¨")

        # 3-3 run-tag & log ç›®éŒ„ - ä½¿ç”¨æ–°çš„è·¯å¾‘ç®¡ç†å™¨
        default_tag = f"{args.alg}_{args.model}_{args.total_steps}"
        run_tag = args.run_tag or default_tag
        
        # å˜—è©¦ä½¿ç”¨æ–°çš„çµ±ä¸€è·¯å¾‘çµæ§‹
        try:
            sys.path.append(str(REPO_ROOT))
            from experiment_path_manager import get_path_manager
            
            path_manager = get_path_manager()
            
            # å¦‚æœ run_tag æ˜¯æ–°æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦å‰‡å‰µå»ºæ–°çš„å¯¦é©—ç›®éŒ„
            if '_' in run_tag and len(run_tag.split('_')) >= 6:
                # æ–°æ ¼å¼çš„ run_tagï¼Œç›´æ¥ä½¿ç”¨
                run_root = path_manager.base_dir / run_tag
                run_root.mkdir(exist_ok=True)
                (run_root / "loadtest_scenarios").mkdir(exist_ok=True)
            else:
                # èˆŠæ ¼å¼ï¼Œå‰µå»ºæ–°çš„å¯¦é©—ç›®éŒ„ä½†ä¿æŒå‘å¾Œå…¼å®¹
                run_root = LOG_ROOT / args.model / run_tag
                run_root.mkdir(parents=True, exist_ok=True)
                
        except ImportError:
            # å¦‚æœè·¯å¾‘ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨èˆŠæ–¹å¼
            run_root = LOG_ROOT / args.model / run_tag
            run_root.mkdir(parents=True, exist_ok=True)
            
        (run_root / "batch.log").touch(exist_ok=True)   # ç¢ºä¿æª”æ¡ˆå­˜åœ¨

        logging.basicConfig(
            level=logging.DEBUG,
            format="%(asctime)s %(levelname)s %(message)s",
            handlers=[
                logging.FileHandler(run_root / "batch.log", encoding="utf-8"),
                logging.StreamHandler(sys.stdout),
            ],
        )
        logging.debug("ğŸš€ rl_batch_loadtest startingâ€¦")

        # 3-4 çµ„åˆ RL å­è¡Œç¨‹å‘½ä»¤
        if args.model == "gwydion":
            rl_cmd = ["python", "run.py"]
        elif args.model == "hpa":
            rl_cmd = ["python", "HPABaseLineTest.py"]
        elif args.model == "gnnrl":
            # Use new GNNRL experiment runner
            rl_cmd = ["python", "training/run_gnnrl_experiment.py"]
        elif args.model == "gym-hpa":
            # Use gym-hpa run script with module import
            rl_cmd = ["python", "policies/run/run.py"]
        else:
            # Legacy gnn_rl path
            rl_cmd = ["python", "-m", "gnn_rl.run.run"]
            
        if args.model == "gnnrl":
            # GNNRL uses different parameter names
            if args.k8s: rl_cmd += ["--k8s"]
            rl_cmd += ["--steps", str(args.total_steps)]  # gnnrl uses --steps for total steps
            if args.goal: rl_cmd += ["--goal", args.goal]
            if args.gnn_model: rl_cmd += ["--model", args.gnn_model]  # Pass GNN model type
            if args.alg: rl_cmd += ["--alg", args.alg]  # Pass RL algorithm
            if args.env_step_interval: rl_cmd += ["--env-step-interval", str(args.env_step_interval)]  # Pass step interval
            if args.tensorboard_log: rl_cmd += ["--tensorboard-log", args.tensorboard_log]
        elif args.model != "hpa":
            rl_cmd += [
                "--alg", args.alg,
                "--use_case", args.use_case,
                "--goal", args.goal,
                "--steps", str(args.steps),
                "--total_steps", str(args.total_steps),
            ]
            if args.k8s:      rl_cmd += ["--k8s"]
            if args.training: rl_cmd += ["--training"]
            if args.testing:
                if not args.load_path:
                    panic("--testing éœ€æ­é… --load-path")
                # Convert path relative to gym-hpa directory
                from pathlib import Path
                load_path = Path(args.load_path)
                if not load_path.is_absolute():
                    # Make path relative to gym-hpa directory
                    relative_load_path = "../" + str(load_path)
                else:
                    relative_load_path = str(load_path)
                rl_cmd += ["--testing", "--test_path", relative_load_path]
            if args.loading:
                if not args.load_path:
                    panic("--loading éœ€æ­é… --load-path")
                rl_cmd += ["--loading", "--load_path", args.load_path]
            if args.device: rl_cmd += ["--device", args.device]
            if args.tensorboard_log:
                rl_cmd += ["--tensorboard_log", args.tensorboard_log]
            if args.model == "grl":
                rl_cmd += ["--gnn_mode"]

        logging.debug("â–¶ Command: %s", " ".join(rl_cmd))
        if args.model == "hpa":
            subprocess.run(rl_cmd, cwd=rl_cwd, check=True)
            logging.info("âœ… å®Œæˆ â†’ logs/hpa")
            return
        elif args.model == "gnnrl":
            # GNNRL experiment handles its own training loop
            rl = subprocess.Popen(rl_cmd, cwd=rl_cwd)
            logging.info("ğŸ”„ GNNRL experiment started, continuing with loadtest...")
        else:
            rl = subprocess.Popen(rl_cmd, cwd=rl_cwd)

        # 3-5 çµ±ä¸€å¯¦é©—èˆ‡åˆ†æ•£å¼æ¸¬è©¦å”èª¿
        from_locust_remote = bool(os.getenv("M1_HOST"))
        logging.info("ğŸ”§ æ¸¬è©¦æ¨¡å¼: %s", 
                    f"åˆ†æ•£å¼ (ä»£ç†: {os.getenv('M1_HOST')})" if from_locust_remote else "æœ¬åœ°")
        
        # ç‚ºä¸åŒå¯¦é©—é¡å‹è¨­å®šåŒæ­¥ç­–ç•¥
        experiment_sync = {"training_proc": rl} if 'rl' in locals() else None
        
        # ä½¿ç”¨ seed è¨­å®šéš¨æ©Ÿç¨®å­
        random.seed(args.seed)
        scenario_list = list(SCENARIOS.keys())
        
        logging.info("ğŸ² ä½¿ç”¨éš¨æ©Ÿç¨®å­ %dï¼Œå¯ç”¨æƒ…å¢ƒ: %s", args.seed, ", ".join(scenario_list))
        
        scenario_dirs = []
        scenario_count = 0
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ RL è¨“ç·´é€²ç¨‹éœ€è¦ç­‰å¾…
        has_training_proc = 'rl' in locals() and rl is not None
        
        # æŒçºŒéš¨æ©ŸåŸ·è¡Œå ´æ™¯ç›´åˆ°è¨“ç·´å®Œæˆ (å¦‚æœæœ‰è¨“ç·´é€²ç¨‹) æˆ–è‡³å°‘åŸ·è¡Œä¸€å€‹å ´æ™¯
        while True:
            # æª¢æŸ¥è¨“ç·´æ˜¯å¦å®Œæˆ
            if has_training_proc and rl.poll() is not None:
                logging.info("âœ… RL è¨“ç·´é€²ç¨‹å·²å®Œæˆ")
                break
            
            # å®Œå…¨éš¨æ©Ÿé¸æ“‡å ´æ™¯
            scn = random.choice(scenario_list)
            scenario_count += 1
            
            # å‰µå»ºå”¯ä¸€çš„è¼¸å‡ºç›®éŒ„ (ä½¿ç”¨è¨ˆæ•¸å™¨é¿å…é‡è¤‡)
            out_dir = run_root / f"{scn}_{scenario_count:03d}"
            logging.info("ğŸ“Š åŸ·è¡Œéš¨æ©Ÿæ¸¬è©¦æƒ…å¢ƒ [ç¬¬%då€‹]: %s", scenario_count, scn)
            
            remote_tag = f"{args.model}/{run_tag}"
            
            # åˆ†æ•£å¼æ¸¬è©¦ï¼ŒåŒ…å«å¯¦é©—åŒæ­¥
            run_distributed_locust(
                scn, 
                remote_tag if from_locust_remote else run_tag, 
                from_locust_remote, 
                out_dir,
                experiment_sync
            )
            scenario_dirs.append(out_dir)
            
            # æƒ…å¢ƒé–“å†·å»æ™‚é–“
            if has_training_proc and rl.poll() is None:
                cooldown = int(os.getenv("COOLDOWN_BETWEEN_SCENARIOS", "60"))  # é è¨­1åˆ†é˜
                logging.info("â¸ï¸  æƒ…å¢ƒé–“å†·å» %d ç§’...", cooldown)
                time.sleep(cooldown)
            elif not has_training_proc:
                # å¦‚æœæ²’æœ‰è¨“ç·´é€²ç¨‹ï¼ŒåŸ·è¡Œä¸€å€‹å ´æ™¯å¾ŒçµæŸ
                break

        # æœ€çµ‚ç­‰å¾…è¨“ç·´å®Œæˆ (é›™é‡ä¿éšª)
        if has_training_proc and rl.poll() is None:
            logging.info("â³ æœ€çµ‚ç­‰å¾…è¨“ç·´é€²ç¨‹å®Œæˆ...")
            rl.wait()
        
        logging.info("ğŸ ç¸½å…±åŸ·è¡Œäº† %d å€‹éš¨æ©Ÿå ´æ™¯æ¸¬è©¦", len(scenario_dirs))
            
        # ç”Ÿæˆçµ±ä¸€å ±å‘Š
        ns = NAMESPACE_REDIS if args.use_case == "redis" else NAMESPACE_OB
        
        # èˆŠç‰ˆå ±å‘Šï¼ˆä¿æŒå‘å¾Œå…¼å®¹ï¼‰
        df = summarise(run_tag, scenario_dirs, ns)
        df.to_csv(run_root / "summary.csv", index=False)
        render_dashboard(df, run_root)
        
        # æ–°ç‰ˆçµ±ä¸€å ±å‘Š
        try:
            from unified_report_generator import process_experiment_results
            
            # æº–å‚™å¯¦é©—é…ç½®
            experiment_config = {
                "id": run_tag,
                "type": args.model,
                "algorithm": args.alg,
                "model": getattr(args, 'gnn_model', 'default'),
                "goal": args.goal,
                "steps": args.total_steps,
                "seed": args.seed,
                "start_time": dt.datetime.now().isoformat()
            }
            
            # ç”Ÿæˆçµ±ä¸€å ±å‘Š
            process_experiment_results(run_root, scenario_dirs, experiment_config)
            logging.info("âœ… çµ±ä¸€å¯¦é©—å ±å‘Šå·²ç”Ÿæˆ")
            
        except Exception as e:
            logging.warning(f"âš ï¸ çµ±ä¸€å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")

        logging.info("ğŸ‰ å¯¦é©—å®Œæˆ â†’ %s", run_root)
        logging.info("ğŸ“ˆ çµæœæ‘˜è¦: %s", run_root / "summary.csv")
        logging.info("ğŸŒ å„€è¡¨æ¿: %s", run_root / "aggregate.html")
        logging.info("ğŸ”„ çµ±ä¸€å ±å‘Š: experiments/ ç›®éŒ„ä¸‹")

    except Exception as e:
        panic("â€¼ï¸  rl_batch_loadtest æœªé æœŸéŒ¯èª¤", e)


if __name__ == "__main__":
    main()

